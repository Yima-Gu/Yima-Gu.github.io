<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>DL Note-1 Intro</title>
    <link href="/2025/09/21/Deep%20Learning/DL%20Note-1%20Intro/"/>
    <url>/2025/09/21/Deep%20Learning/DL%20Note-1%20Intro/</url>
    
    <content type="html"><![CDATA[<p><strong>人工智能 (<em>ArtificialIntelligence</em>)</strong>：宏观的目标，即创造出能够模拟、延伸和扩展人类智能的机器。</p><p><strong>机器学习 (<em>MachineLearning</em>)</strong>：实现人工智能的一种核心方法。它的特点是<strong>不通过显式编程来解决问题，而是让算法从数据中自动学习规律</strong>。</p><p><strong>深度学习(<em>DeepLearning</em>)</strong>：它主要<strong>使用一种叫做“神经网络”的复杂结构</strong>，从海量数据中<strong>获取高度抽象的特征</strong>。</p><p>深度学习的魅力在于，它能从海量数据中<strong>自动提取高度抽象的特征</strong>，这主要通过深度神经网络来实现。我们可以将这个过程类比为<strong>对数据进行坐标系变换</strong>，通过不同的变换方式，我们能用新的视角来处理同一个问题。尽管深度学习取得了巨大成功，但传统的规则系统在许多机器学习任务中依然扮演着不可或缺的角色。</p><div class="note note-info">            <ol type="1"><li><strong>想象一个问题</strong>：假设你有一张纸，上面混杂地撒着红色和蓝色的豆子，它们混在一起，你无法用一把直尺就将它们完美分开。</li><li><strong>一次“变换”</strong>：现在，你抓住这张纸（坐标系），将它进行拉伸、弯曲、折叠。经过这次操作，神奇的事情发生了：所有的红豆子都跑到了纸的左边，蓝豆子都跑到了右边。现在，你只需要用一把直尺就能轻松地将它们分开了。</li><li><strong>深度学习在做什么</strong>：深度学习中的每一个“层”（layer）都在做一次类似上面那样的“坐标系变换”。它将原始的、线性不可分的数据，通过一系列复杂的空间变换，转换到一个新的、高维的空间中，在这个新空间里，数据变得更容易被分类。</li></ol><p>所以，深度学习的“深度”就体现在它执行了一连串（成百上千次）这样的变换，从而能够解开那些缠绕得极其复杂的数据模式。</p>          </div><div class="note note-info">            <p>在机器学习出现之前，我们实现AI的方式主要是“规则系统”。想象一下编写一个识别猫的程序，你可能需要写下成千上万条规则：</p><ul><li><code>如果</code> 有毛茸茸的耳朵 <code>并且</code> 有胡须<code>并且</code> 会“喵”叫，<code>那么</code> 它可能是一只猫。</li></ul><p>这种方式非常脆弱且复杂。而机器学习则完全不同，你不需要告诉计算机“猫有什么特征”，你只需要给它看成千上万张猫的图片，它会<strong>自己总结</strong>出什么是猫。这就是“不显式编程”的含义。</p>          </div><h3 id="framework">Framework</h3><p>在学习算法中，我们首先要指定一个<strong>函数族 (family offunctions)</strong>，然后用数据来从这个族中找到最匹配的那个函数。这个过程的目标就是找出<strong>最优的函数</strong>。</p><div class="note note-info">            <ul><li><strong>假设空间 (HypothesisSpace)</strong>：也叫“函数族”，你可以把它想象成一个“工具箱”。</li><li>一个只包含直尺的工具箱，它能画出所有的直线。这就是“线性模型”的假设空间。</li><li>一个包含各种曲线尺的工具箱，它能画出各种平滑的曲线。这就是“多项式模型”的假设空间。</li><li>一个拥有橡皮泥的工具箱，理论上可以捏出任何形状。这就是“神经网络”的假设空间，它非常强大。</li><li><strong>最优函数族</strong>：指为你的特定问题<strong>选择最合适的那个“工具箱”</strong>。如果你的数据点本身就大致在一条直线上，那么“直尺工具箱”（线性模型）就是最优的，用“橡皮泥”反而可能因为过于灵活而把问题搞砸（这叫<strong>过拟合</strong>）。</li></ul>          </div><p>过拟合在你选择函数族（工具箱）的时候，其风险就已经被决定了。</p><p><mark>泛化误差公式(<em>Generalization Error</em>)</mark>：</p><p><span class="math display">$$\varepsilon_{test} \leq \hat{\varepsilon}_{train} +\sqrt{\frac{\text{complexity}}{n}}$$</span></p><p>这个公式是机器学习的基石，它告诉我们如何让模型在“真实世界”中表现良好。</p><ul><li><spanclass="math inline"><em>ε</em><sub><em>t</em><em>e</em><em>s</em><em>t</em></sub></span>(<strong>泛化误差</strong>)：模型的“期末考试”成绩。它衡量模型在从未见过的新数据上的表现，这是我们最关心的指标。</li><li><spanclass="math inline"><em>ε</em><sub><em>t</em><em>r</em><em>a</em><em>i</em><em>n</em></sub></span>​(<strong>训练误差</strong>)：模型的“平时作业”成绩。它衡量模型在训练数据上的表现。</li><li><spanclass="math inline">$\sqrt{\frac{\text{complexity}}{n}}$</span>(<strong>过拟合惩罚项</strong>)：可以理解为“作业”和“考试”成绩之间的差距。<ul><li><spanclass="math inline"><em>c</em><em>o</em><em>m</em><em>p</em><em>l</em><em>e</em><em>x</em><em>i</em><em>t</em><em>y</em></span>(<strong>模型复杂度</strong>)：模型的“难度系数”。复杂度越高，模型越容易过拟合训练数据，但在新数据上表现可能会很差。</li><li><spanclass="math inline"><em>n</em></span>(数据量)：你做的“练习题”数量。练习题越多，你越能总结出通用规律，而不是记住个别题的答案。</li></ul></li></ul><p><strong>核心思想</strong>：要想在期末考试中取得好成绩，你需要：</p><ol type="1"><li><strong>平时作业分高</strong> (训练误差小)</li><li><strong>不依赖死记硬背</strong>(模型复杂度不能太高，或者数据量<code>n</code>要足够大来约束它)</li></ol><p>这也引出了一个重要原则：<strong>当且仅当需要的时候，才增加模型的复杂度。</strong></p><h3 id="model">Model</h3><p><span class="math display">$$\arg \min O(D;\theta) = \sum_{i=1}^{N} L(y_i, f(x_i);\theta) +\Omega(\theta)$$</span></p><p>这是机器学习的“指导思想”，它告诉模型如何学习。</p><ul><li><spanclass="math inline">arg min<sub><em>θ</em></sub></span>：意思是“找到一组参数，使得后面的表达式结果最小”。<ul><li>参数 就是模型需要学习的东西（比如一条直线的斜率和截距）。</li><li><spanclass="math inline"><em>O</em>(<em>D</em>;<em>θ</em>)</span>：总目标，我们希望它越小越好。</li></ul></li><li><spanclass="math inline">∑<em>L</em>(<em>y</em><sub><em>i</em></sub>,<em>f</em>(<em>x</em><sub><em>i</em></sub>);<em>θ</em>)</span>：<strong>损失项(Loss Term)</strong>。<ul><li>这部分计算的是模型预测值 <spanclass="math inline"><em>f</em>(<em>x</em><sub><em>i</em></sub>)</span>与真实值 <spanclass="math inline"><em>y</em><sub><em>i</em></sub></span>之间的“差距”或“错误”。它的目标是：<strong>让模型在训练数据上尽可能地预测准确</strong>。对于分类问题而言，经常使用的是交叉熵损失函数（logistic）和hinge损失函数。</li></ul></li><li><strong>正则化项 (Regularization Term)</strong>，也叫<strong>惩罚项(Penalty Term)</strong>。<ul><li>这部分是用来限制模型复杂度的。它会惩罚那些过于复杂的模型（即参数<span class="math inline"><em>θ</em></span> 的值过大）。</li><li>它的目标是：<strong>在拟合数据的同时，让模型本身尽可能地简单</strong>。</li></ul></li><li><strong>总结</strong>：整个公式描述了一个<strong>权衡(Trade-off)</strong>。机器学习的目标是找到一组完美的参数 <spanclass="math inline"><em>θ</em></span>，这组参数既能让模型很好地拟合训练数据（损失项小），又能保证模型自身不至于过分复杂（惩罚项小），从而在未来的新数据上也能表现良好。</li></ul><p><strong>Linear Regression</strong></p><p><span class="math display">$$O(D;\theta) = \sum_{i=1}^{N} (y_i - \theta^T x_i)^2 + \lambda \theta^T\theta = (Y - X\theta)^T (Y - X\theta) + \lambda \theta^T \theta$$</span></p><p>上述公式是关于<spanclass="math inline"><em>θ</em></span>的二次函数，可以通过求导得到最优解。</p><p><span class="math display">$$\frac{\partial O(D;\theta)}{\partial \theta} = -2 X^T (Y - X\theta) + 2\lambda \theta = 0$$</span></p><p><spanclass="math display"><em>θ̂</em> = (<em>X</em><sup><em>T</em></sup><em>X</em>+<em>λ</em><em>I</em>)<sup>−1</sup><em>X</em><sup><em>T</em></sup><em>Y</em></span></p><p>但是上述算法的复杂性为<spanclass="math inline"><em>O</em>(<em>n</em><sup>3</sup>)</span>，不适用于大数据集。在软件工程中，通常使用梯度下降法。</p><p><strong>Logistic Regression</strong></p><p><span class="math display">$$O(D;\theta) = \sum_{i=1}^{n} \log(1 + \exp(-y_i \theta^T x_i)) + \lambda||\theta||_{1} = F(D;\theta) + \lambda ||\theta||_{1}$$</span></p><p>这里使用的是近端梯度下降法 <em>proximal gradientdescent</em>。其中的1-范数是各个分量的绝对值之和。<ahref="https://www.zhihu.com/tardis/zm/art/82622940?source_id=1005">机器学习| 近端梯度下降法 (proximal gradient descent)</a>在一些不可导的情况下如hinge损失函数，可以使用次梯度。</p><p><strong>Softmax Regression</strong></p><p>实现多分类问题，计算每个类别的概率即可，对于某个样本进行多次打分，取最高分对应的类别。</p><p>Softmax Function:</p><p><span class="math display">$$P(y|x,\theta) = \frac{\exp(\theta_y^T x)}{\sum_{r=1}^{C}\exp(\theta_{r}^T x)}$$</span></p><p>线性模型，用超平面对样本进行打分，然后使用softmax函数进行归一化。</p><p><span class="math display">$$O(D;\theta) = -\sum_{i=1}^{n} \log P(y_i|x_i;\theta) + \lambda||\theta||_{1}$$</span></p><p>上述式子其实是对数似然函数，最大化对数似然函数等价于最小化交叉熵损失函数。</p><h4 id="aproximation-and-estimation">Aproximation and Estimation</h4><p>假设空间只能表现一个有限的函数集合，有时候真值函数不一定在假设空间中。这时候假设空间中最好的函数与真值函数之间的差距称为<strong>近似误差</strong><em>ApproximationError</em>。学习得到的函数与空间中最好的函数的误差为<strong>估计误差</strong><em>Estimation Error</em>。</p><div class="note note-warning">            <p>让我们继续用“雕刻”来打比方。你的目标是完美复刻一座罗丹的《思想者》雕像，这就是“真理”（真值函数）。</p><ol type="1"><li><strong>你的工具箱 = 假设空间 (Hypothesis Space)</strong>。</li><li><strong>工具不行，神仙难救 = 近似误差 (ApproximationError)</strong></li></ol><ul><li>这个误差衡量的是你<strong>“工具箱”本身的局限性</strong>。假设你选择的工具箱里只有一把直尺和几块乐高积木。无论你多么努力，用这些工具也永远无法完美复刻出《思想者》流畅的人体曲线。</li><li>你用乐高能拼出的、最接近《思想者》的那个方块人，和真正的《思想者》雕像之间的巨大差距，就是<strong>近似误差</strong>。这个错误在你选择工具箱的那一刻就注定了，是<strong>设计上</strong>的误差。</li></ul><ol start="3" type="1"><li><strong>工具有了，手艺差点 = 估计误差 (EstimationError)</strong></li></ol><ul><li>现在，假设你得到了一个顶级的雕刻工具箱，里面有凿子、刻刀，还有一大块完美的“橡皮泥”（神经网络）。这个工具箱足够强大，理论上完全可以复刻出《思想者》。</li><li>但因为你是初学者，你的<strong>雕刻技术（训练过程）还不够娴熟</strong>，或者你只有很少的时间（数据量不足）去雕刻。最终，你做出的雕像虽然有了人形，但细节粗糙，比例也有些失调。</li><li>你最终做出的这个“走样”的雕像，和一位大师用同样的工具能做出的完美雕像之间的差距，就是<strong>估计误差</strong>。这不是工具的错，而是你<strong>使用过程中</strong>的误差。</li></ul>          </div><h3 id="model-selection">Model Selection</h3><div class="note note-info">            <p><em>All models are wrong but some are useful.</em></p>          </div><p>CASH (Combined Algorithm Selection and Hyperparameter optimization)所解决的是应用机器学习中的一个核心且复杂的挑战：<strong>如何在一个包含多种算法及其各自超参数配置的巨大搜索空间中，自动地、系统性地找到最优的模型配置。</strong></p><p><spanclass="math display"><em>A</em><sub><em>λ</em><sup>*</sup></sub><sup>*</sup> = arg min<sub><em>A</em> ∈ 𝒜</sub>min<sub><em>λ</em> ∈ <em>Λ</em><sup>(<em>i</em>)</sup></sub>ℒ(<em>A</em><sub><em>λ</em></sub><sup>(<em>i</em>)</sup>,<em>D</em><sub><em>t</em><em>r</em><em>a</em><em>i</em><em>n</em></sub>,<em>D</em><sub><em>v</em><em>a</em><em>l</em><em>i</em><em>d</em></sub>)</span></p><p>下面，我们对该公式的各个组成部分进行严谨的拆解：</p><ol type="1"><li><strong>目标 (<spanclass="math inline"><em>A</em><sub><em>λ</em><sup>*</sup></sub><sup>*</sup></span>)</strong><ul><li>这代表了我们寻求的最优解。它不是一个单一的模型，而是一个<strong>配置（Configuration）</strong>，由两部分组成：<ul><li><spanclass="math inline"><em>A</em><sup>*</sup></span>：从候选算法集合中选出的<strong>最优算法</strong>。</li><li><span class="math inline"><em>λ</em><sup>*</sup></span>：与最优算法<span class="math inline"><em>A</em><sup>*</sup></span>相对应的<strong>最优超参数组合</strong>。</li></ul></li></ul></li><li><strong>搜索空间 (Search Space)</strong><ul><li>这是一个分层的、结构化的空间，由两部分构成：<ul><li><strong>算法空间 (<spanclass="math inline">𝒜</span>)</strong>：一个离散的、预定义的机器学习算法集合。例如：<spanclass="math inline">𝒜 = {支持向量机, 随机森林, 多层感知机}</span>。</li><li><strong>超参数空间 (<spanclass="math inline"><em>Λ</em><sub><em>A</em></sub></span>)</strong>：对于算法空间<span class="math inline">𝒜</span> 中的每一个算法 <spanclass="math inline"><em>A</em></span>，都存在一个与之关联的超参数空间<spanclass="math inline"><em>Λ</em><sub><em>A</em></sub></span>。这个空间定义了该算法所有可调超参数的类型和取值范围。例如，对于支持向量机，<spanclass="math inline"><em>Λ</em><sub><em>S</em><em>V</em><em>M</em></sub></span>可能包含核函数类型 (<code>kernel</code>)、惩罚系数 <code>C</code> 的范围<code>[0.1, 100]</code>等。这个空间可以是多维的，并且包含连续、离散和条件参数，结构非常复杂。</li></ul></li></ul></li><li><strong>优化过程 (<spanclass="math inline">arg min<sub><em>A</em> ∈ 𝒜</sub>min<sub><em>λ</em> ∈ <em>Λ</em><sub><em>A</em></sub></sub></span>)</strong><ul><li>这描述了一个嵌套的最小化过程。外层循环遍历算法空间 <spanclass="math inline">𝒜</span>中的每一个算法，内层循环则在该算法的超参数空间 <spanclass="math inline"><em>Λ</em><sub><em>A</em></sub></span>中进行搜索。其目标是找到能使目标函数 <span class="math inline">ℒ</span>最小化的那一对 <span class="math inline">(<em>A</em>,<em>λ</em>)</span>组合。</li></ul></li><li><strong>评估协议 (<spanclass="math inline">ℒ(<em>A</em><sub><em>λ</em></sub>,<em>D</em><sub>train</sub>,<em>D</em><sub>valid</sub>)</span>)</strong><ul><li>这是整个优化过程的核心，定义了如何评估任意一个给定配置的好坏。它包含以下标准流程：<ul><li><strong>实例化 (Instantiation)</strong>：从算法库中选择一个算法<span class="math inline"><em>A</em></span>，并使用一组具体的超参数<span class="math inline"><em>λ</em></span> 来实例化一个待训练的模型<span class="math inline"><em>A</em><sub><em>λ</em></sub></span>。</li><li><strong>训练 (Training)</strong>：使用训练数据集 <spanclass="math inline"><em>D</em><sub>train</sub></span> 对实例化的模型<span class="math inline"><em>A</em><sub><em>λ</em></sub></span>进行训练。在这个过程中，模型学习其内部参数（例如，神经网络的权重）。</li><li><strong>验证 (Validation)</strong>：训练完成后，在独立的验证数据集<span class="math inline"><em>D</em><sub>valid</sub></span>上评估模型的性能。<spanclass="math inline"><em>D</em><sub>valid</sub></span>中的数据是模型在训练过程中从未见过的，因此可以提供对模型<strong>泛化能力(Generalization Performance)</strong> 的无偏估计。</li><li><strong>损失函数 (<spanclass="math inline">ℒ</span>)</strong>：这是一个量化指标，用于计算模型在验证集上的性能。例如，对于分类问题，它可以是交叉熵损失或错误率；对于回归问题，可以是均方误差（MSE）。</li></ul></li></ul></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>DeepLearning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DL Note-2 MLP</title>
    <link href="/2025/09/21/Deep%20Learning/DL%20Note-2%20MLP/"/>
    <url>/2025/09/21/Deep%20Learning/DL%20Note-2%20MLP/</url>
    
    <content type="html"><![CDATA[<h1 id="brain-and-neuron">Brain and Neuron</h1><p>感知机<em>Perceptron</em>是神经元的一个相当简单的数学模型，包括：输入、权重、<strong>激活函数</strong>、输出。其实是在空间超平面上嵌入了一个非线性函数。</p><p><span class="math display">$$\hat{y} = g(\sum_{i=1}^{n}  x_i \theta_i +\theta_0)$$</span></p><p>感知机在神经网络中也叫单元<em>unit</em>，是神经网络的基本组成单元。但是这样的单元会比人的神经元简单很多。</p><h2 id="pla">PLA</h2><p>最早的感知机模型使用的是<strong>符号函数（SignFunction）</strong>，作为激活函数。由于该函数是<strong>非光滑、不可导的</strong>，因此<strong>无法应用基于梯度的优化方法</strong>（如梯度下降）。为此，研究者们专门设计了一套非梯度的训练算法，即<strong>感知机学习算法（PLA）</strong>。</p><p><img src="{5ABA24F6-F5A5-48C8-AE9F-1E8524E35979}.png" alt="" width="900"></p><p>在理论推导中，可以计算PLA的<strong>收敛率</strong>：（在线性可分的情况下）<span class="math inline"><em>γ</em></span>是最优间隔<em>the best-casemargin</em>，计算的是训练样本与超平面的距离之间的最小值。</p><p><span class="math display">$$\exists v \in \mathbb{R}^d \quad \text{s.t.}\,\gamma \leq\frac{y_i(v\cdot x_i)}{||v||}$$</span></p><p><spanclass="math inline"><em>R</em></span>是数据集的半径，即样本数据向量模的最大值，<spanclass="math inline"><em>d</em></span>是数据集的维度。那么PLA的收敛率为：最多经过<spanclass="math inline">$\frac{R^2}{\gamma^2}$</span>次迭代就可以收敛。 -<span class="math inline"><em>γ</em></span>越大，收敛越快 - <spanclass="math inline"><em>R</em></span>越大，收敛越慢</p><h3 id="expresiveness-of-perceptron">Expresiveness of Perceptron</h3><p>感知机是一个线性分类器，只能解决<strong>线性可分</strong>的问题。如果数据不是线性可分的，那么感知机就无法解决（例如异或问题）。</p><h2 id="multi-layer-perceptron">Multi-layer Perceptron</h2><p>多层感知机（MLP）是<strong>单一感知机</strong>的有力扩展，使其能够处理<strong>线性不可分问题</strong>。其核心结构包括一个输入层、一个或多个隐藏层以及一个输出层。值得一提的是，MLP的连接方式与人脑的突触连接相比，显得更为简单，通常不是全连接，而是<strong>稀疏连接</strong>。尽管如此，MLP依然具备强大的表达能力，通常通过增加隐藏层来提升其处理复杂问题的能力。</p><h3 id="comention">Comention</h3><p><img src="{9A215F21-185B-4C55-B872-413D388E5321}.png" alt="" width="900"></p><p><img src="{E178BAD1-DE9C-44E5-A665-D550AE3A9558}.png" alt="" width="900"></p><ul><li>用上标表示层数，用下标表示感知机的编号</li><li><spanclass="math inline"><em>θ</em><sub><em>i</em><em>j</em></sub><sup>(<em>l</em>)</sup></span>表示第<spanclass="math inline"><em>l</em></span>层的第<spanclass="math inline"><em>i</em></span>个感知机的第<spanclass="math inline"><em>j</em></span>个输入的权重</li><li><spanclass="math inline"><em>b</em><sub><em>j</em></sub><sup>(<em>l</em>)</sup></span>表示第<spanclass="math inline"><em>l</em></span>层的第<spanclass="math inline"><em>j</em></span>个感知机的偏置</li><li><spanclass="math inline"><em>a</em><sub><em>j</em></sub><sup>(<em>l</em>)</sup></span>表示第<spanclass="math inline"><em>l</em></span>层的第<spanclass="math inline"><em>j</em></span>个感知机的输出（在激活之后的数值）</li><li><spanclass="math inline"><em>z</em><sub><em>j</em></sub><sup>(<em>l</em>)</sup></span>表示第<spanclass="math inline"><em>l</em></span>层的第<spanclass="math inline"><em>j</em></span>个感知机的输入（经过线性变换之后的数值）</li><li><spanclass="math inline"><em>J</em>(<em>θ</em>)</span>表示损失函数<em>LossFunction</em></li></ul><p>在上面的图中，边的个数就是参数的个数。</p><h3 id="activation-function">Activation Function</h3><ul><li><p><strong>Sigmoid函数</strong>：<span class="math inline">$g(z) =\sigma(z)= \frac{1}{1+e^{-z}}$</span>采用有界的函数，可以将输出限制在0-1之间，避免数值爆炸。但是在基于梯度的计算中，会出现梯度消失（梯度饱和），在两侧的范围内梯度会接近于0。</p></li><li><p><strong>ReLU函数</strong>：<spanclass="math inline"><em>g</em>(<em>z</em>) = <em>m</em><em>a</em><em>x</em>(0,<em>z</em>)</span>ReLU函数是一个分段函数，可以避免<strong>梯度消失</strong>的问题。但是在训练时，会出现<strong>神经元死亡</strong>的问题，即神经元的输出一直为0。</p></li><li><p><strong>GeLu函数</strong>：<span class="math inline">$g(z) = z\cdot \Phi(z) = z \cdot \frac{1}{2} (1 +\text{erf}(\frac{z}{\sqrt{2}}))$</span>用Guass分布的累计函数对上述进行加权。<spanclass="math inline"><em>Φ</em>(<em>z</em>)</span>是标准正态分布的累计分布函数<em>CDF</em>。在一些较为复杂的模型中（GPT-3、Bert）都有使用。</p></li></ul><p>在网络的输出层，使用的激活函数由问题决定。如果是回归问题，可以使用线性函数；在有界的输出情况下，可以使用Sigmoid函数；在多分类问题中，可以使用Softmax函数。</p><ul><li><strong>Softmax函数</strong>：<span class="math inline">$g(z)_i =\frac{e^{z_i}}{\sum_{j=1}^{k} e^{z_j}}$</span>Softmax函数是一个多分类的激活函数，可以将输出的值转化为概率值。分类问题是随机实验中的伯努利实验<em>CategoricalDistribution</em>。缺点为：“赢者通吃”，即最大的值会被放大，其他的值会被压缩，有<em>overconfidence</em>的问题（即某个分类的概率过大）。同时有数值稳定性问题，即数值计算时可能会出现数值爆炸的问题。改进为： <span class="math display">$$g(z)_i = \frac{e^{z_i - \max(z)}}{\sum_{j=1}^{k} e^{z_j - \max(z)}}$$</span> 上述改进能解决数值稳定性问题，但是对于<em>overconfidence</em>问题还是存在。 ^b5bcbb</li></ul><h3 id="cost-function">Cost Function</h3><p>任何一个衡量预测与实际值之间的差异的函数都可以称为损失函数。在这里使用的是交叉熵损失函数<em>CrossEntropy Loss</em>：</p><p><span class="math display">$$J(y,\hat{y}) = - \sum_{i=1}^{n} y_i \log(\hat{y}_i)$$</span></p><p>作代入得到：</p><p><span class="math display">$$J(\theta)= -\frac{1}{m} \sum_{i=1}^{m} \sum_{j=1}^{k}\mathbf{1}\{y^{(i)}=j\} \log\frac{\exp{ z_j^{(n_l)}}}{\sum_{j'=1}^{k}\exp{ z_{j'}^{(n_l)}}} \quad (*)$$</span></p><p><em>*上述公式中的m为样本数目，k为类别数目，<spanclass="math inline"><em>z</em><sub><em>j</em></sub><sup>(<em>n</em><sub><em>l</em></sub>)</sup></span>为最后一层的第j个感知机的输入。对于实际类别采用独热编码，即只有在对应类别取值为1。</em></p><h3 id="statistical-view-of-softmax">Statistical View of Softmax</h3><p>考虑投掷m次骰子，其中第<spanclass="math inline"><em>i</em></span>个得到<spanclass="math inline"><em>j</em></span>的概率为<spanclass="math inline"><em>q</em><sub><em>i</em><em>j</em></sub></span>。在<em>Softmax</em>中对于概率进行建模（用数据进行估计，对于分类估计的参数进行逼近）：</p><p><spanclass="math display"><em>q</em><sub><em>i</em><em>j</em></sub> = <em>P</em>(<em>y</em><sub><em>i</em></sub>=<em>j</em> |<strong>x</strong><sub><strong>i</strong></sub>;<strong>W</strong>)</span></p><p>在给定的结果<spanclass="math inline">{<em>y</em><sub>1</sub>, ..., <em>y</em><sub><em>m</em></sub>}</span>下，概率值（似然函数）为：</p><p><span class="math display">$$\mathcal{L}(\mathbf{W};\mathcal{D})=\prod_{i=1}^{m} \prod_{j=1}^{k}P(y_i=j|q_{ij})^{\mathbf{1}\{y_i = j\}} = \prod_{i=1}^{m}\prod_{j=1}^{k}P(y_i = j\,| \mathbf{x_i} ; \mathbf{W} )^{\mathbf{1}\{y_i = j\}}$$</span></p><p><em><spanclass="math inline"><strong>W</strong></span>是模型的参数，上面的式子是在这样的建模和数据下得到结果的可能性，也就是统计中的似然函数。这样的过程类似于统计中的参数估计。</em></p><p>做极大似然估计：</p><p><span class="math display">$$\mathcal{L}(\mathbf{W};\mathcal{D}) =\max_{w_1 \dots w_k}\prod_{i=1}^{m} \prod_{j=1}^{k} P(y_i = j\,| \mathbf{x_i} ; \mathbf{W} )^{\mathbf{1}\{y_i = j\}}$$</span></p><p>取负对数：</p><p><span class="math display">$$J(\mathbf{W}) = \min_{w_1 \dots w_k}- \log\mathcal{L}(\mathbf{W};\mathcal{D}) = - \sum_{i=1}^{m} \sum_{j=1}^{k}\mathbf{1}\{y_i = j\} \log P(y_i = j\,| \mathbf{x_i} ; \mathbf{W} )$$</span> z上述的式子就是交叉熵损失函数。上面的过程其实是在认为分类是<spanclass="math inline"><em>i</em>.<em>i</em>.<em>d</em>.</span>的伯努利分布的极大似然估计。</p><blockquote><p>从统计学角度看，<strong>最小化交叉熵损失函数</strong>等价于<strong>最大化分类结果服从多项分布时的对数似然</strong>。这为我们常用的损失函数提供了坚实的理论依据。</p></blockquote><h1 id="gradient-descent">Gradient Descent</h1><p>对于不是直接依赖的导数的计算较为复杂，对于最后一层的导数计算较为简单（是直接依赖）。对于前面层的参数的导数在这里使用<strong>链式法则</strong>来进行计算。</p><p>对于最后一层的参数的导数计算： <span class="math display">$$\frac{\partial J(\theta ,b)}{\partial z_j^{(n_l)}} = -(\mathbf{1}\{y^{(i)}=j\} -P(y^{(i)}=j|\mathbf{x}^{(i)};\theta,b)))$$</span> 可以发现梯度是真是的概率减去预测的概率。</p><h2 id="step-1-forward-propagation">Step 1: Forward Propagation</h2><p>输入样本计算得到的输出值，这个过程是一个前向传播的过程。</p><h2 id="step-2-backward-propagation">Step 2: Backward Propagation</h2><p>将损失函数带有的错误信息向前传播 <span class="math display">$$\frac{J(\theta)}{\theta_1}= \frac{\partial J(\theta)}{\partial \hat{y}}\frac{\partial \hat{y}}{\partial z} \frac{\partial z}{\partial \theta_1}$$</span>除了需要求解的导数的参数，其他的都是计算的中间值。BP是一个动态规划算法。</p><h2 id="computing-the-residual">Computing the Residual</h2><p>第<span class="math inline"><em>l</em></span>层的第<spanclass="math inline"><em>i</em></span>个结点的残差<em>Residual</em>的定义为：<span class="math display">$$\delta_i^{(l)} = \frac{\partial J(\theta)}{\partial z_i^{(l)}}$$</span> 对于最后一层的残差，计算较为简单： <spanclass="math display">$$\delta_i^{(n_l)} = \frac{\partial}{\partial z_i^{(n_l)} } J(\theta) =\frac{\partial }{\partial \hat{y}_i}J(\theta) g'(z_i^{(n_l)})$$</span> 利用链式法则对激活函数求导即可。 对于隐藏层的导数计算： <spanclass="math display">$$\delta_i^{(l)} = \frac{\partial J(\theta)}{\partial z_i^{(l)}} =\sum_{j=1}^{n_{l+1}} \frac{\partial J(\theta)}{\partial z_j^{(l+1)}}\frac{\partial z_j^{(l+1)}}{\partial z_i^{(l)}} = \sum_{j=1}^{n_{l+1}}\delta_j^{(l+1)} \theta_{ij}^{(l)} g'(z_i^{(l)})$$</span> <span class="math display">$$\delta_i^{(l)}= \sum_{j=1}^{n_{l+1}} \delta_j^{(l+1)} \theta_{ji}^{(l)}g'(z_j^{(l)})$$</span> 上述公式实现了<strong>传递</strong>的过程。</p><h2 id="step-3-update-parameters">Step 3: Update Parameters</h2><p>对于参数更新的过程： <span class="math display">$$\frac{\partial J(\theta)}{\partial \theta_{ij}^{(l)}} = \frac{\partialJ(\theta)}{\partial z_j^{(l+1)}} \frac{\partial z_j^{(l+1)}}{\partial\theta_{ij}^{(l)}} = \delta_j^{(l+1)} a_i^{(l)}$$</span> <span class="math display">$$\frac{\partial J(\theta)}{\partial b_j^{(l)}} = \delta_j^{(l+1)}$$</span></p><h3 id="automatic-differentiation">Automatic Differentiation</h3><p>在实际的计算中，可以使用自动微分的方法来进行计算。自动微分是一种计算导数的方法，可以分为两种：</p><ul><li><strong>SymbolicDifferentiation</strong>：通过符号的方式来计算导数，这种方法计算的精确度较高，但是计算的速度较慢。</li><li><strong>NumericalDifferentiation</strong>：通过数值的方式来计算导数，这种方法计算的速度较快，但是计算的精确度较低。</li></ul><p>在计算图中，将每一个计算层的反向传播的导数保存在软件包中，这样可以减少计算的时间。实际的应用中，对于计算图进行拓扑排序，然后进行反向传播的计算。</p><h2 id="optimization-in-practice">Optimization in Practice</h2><h3 id="dropout"><strong>Dropout</strong></h3><p>在训练的过程中，随机的将一些神经元的权重置为0（丢弃），这样可以减少过拟合的问题。在操作的过程中，按照一定的概率<spanclass="math inline"><em>p</em></span>对神经元进行丢弃。在某一层未被丢弃的神经元的激活值值乘以<spanclass="math inline">$\frac{1}{1-p}$</span>，这样可以保持期望值不变。</p><h3 id="weight-initialization">Weight Initialization</h3><p>对于权重的初始化，一般使用Guass分布可以使用一些方法来进行初始化，例如：<strong>Xavier Initialization</strong> ( linear activations )： <spanclass="math display">$$Var(W)= \frac{1}{n_{in}}$$</span></p><p>假设输入的数据<spanclass="math inline"><em>x</em><sub><em>j</em></sub></span>满足均值为0，方差为<spanclass="math inline"><em>γ</em></span>，<spanclass="math inline"><em>n</em><sub><em>i</em><em>n</em></sub></span>是这一个神经元对应的输入的神经元的个数。在线性组合之后，可以得到： <span class="math display">$$h_i=\sum_{j=1}^{n_{in}} w_{ij} x_j$$</span> 可以认为<spanclass="math inline"><em>w</em><sub><em>i</em><em>j</em></sub></span>是独立同分布的并且均值为0方差为<spanclass="math inline"><em>σ</em><sup>2</sup></span>那么计算得到： <spanclass="math display">𝔼[<em>h</em><sub><em>i</em></sub>] = 0  𝔼[<em>h</em><sub><em>i</em></sub><sup>2</sup>] = <em>n</em><sub><em>i</em><em>n</em></sub><em>σ</em><sup>2</sup><em>γ</em></span>这样在经过一个层之后数据的方差会改变，为了保持方差不变，可以使用上述的初始化方法。</p><p><strong>He Initialization</strong>：(ReLU activations) <spanclass="math display">$$Var(W)= \frac{2}{n_{in}}$$</span> 其中<spanclass="math inline"><em>n</em><sub><em>i</em><em>n</em></sub></span>是这一个神经元对应的输入的神经元的个数。</p><h3 id="baby-sitting-learning">Baby Sitting Learning</h3><p>在训练的过程中，首先在较小的数据集上进行过拟和（在这个训练集上的损失函数接近0）</p><p><strong>学习率</strong></p><ul><li>如果训练过程中损失函数<strong>停滞不前甚至变大</strong>，很可能是<strong>学习率过高</strong>，导致模型参数在最优解附近震荡或发散。这时应适当<strong>减小学习率</strong>。<br /></li><li>相反，如果<strong>学习率过低</strong>，模型参数更新会非常缓慢，导致训练过程<strong>效率低下</strong>。这时可以尝试<strong>增大</strong>学习率来加速训练。</li></ul><p><strong>数值爆炸</strong>：</p><ul><li>为了避免神经元进入<strong>饱和区</strong>（梯度接近于零，导致更新停滞），可以采用合适的<strong>权重初始化方法</strong>来缓解。</li><li>对输入数据进行<strong>归一化</strong>处理，可以有效地防止数值爆炸问题。</li></ul><p>当<strong>验证损失</strong>与<strong>训练损失</strong>之间存在较大差距时，通常表明模型出现了<strong>过拟合</strong>。这意味着模型在训练集上表现良好，但在未见过的新数据（验证集）上表现不佳。</p><p>为了解决这个问题，可以采用<strong>早停</strong>策略。即在训练过程中，当验证损失不再下降，反而开始上升时，就停止训练。这能让模型在验证误差曲线<strong>趋近渐近线</strong>时达到最佳性能，从而防止过拟合。</p><h3 id="batch-normalization">Batch Normalization</h3><p>其核心目标是解决一个问题：在深度神经网络中，数据经过一层又一层的变换，每一层接收到的输入的分布都在剧烈变化，这使得训练变得困难、缓慢且不稳定。归一化层就是用来<strong>稳定和规范化每一层输入的“中间件”</strong>，从而让整个训练过程更顺畅。</p><p>对于输入的数据进行归一化处理，可以加快训练的速度，同时可以减少梯度消失的问题。在训练的过程中，对于每一个batch的数据进行归一化处理，可以使得数据的分布更加稳定。其中<spanclass="math inline"><em>μ</em></span>和<spanclass="math inline"><em>σ</em></span>是对于每一个mini-batch的均值和方差。<span class="math display">$$\hat{x} = \frac{x - \mu}{\sigma}$$</span>这是一个非参数化方法。可以加入可学习的参数.这相当于给了网络一个“反悔”的机会。如果网络发现原始的、未被归一化的特征分布就是最优的，它可以通过学习让<spanclass="math inline"><em>γ</em></span>等于原始标准差<spanclass="math inline"><em>σ</em></span>，<spanclass="math inline"><em>β</em></span>等于原始均值<spanclass="math inline"><em>μ</em></span>，从而将数据恢复回去。： <spanclass="math display"><em>y</em> = <em>γ</em><em>x̂</em> + <em>β</em></span></p><p>在CNN中，对每一个batch中的<spanclass="math inline"><em>n</em></span>个<spanclass="math inline"><em>w</em> × <em>h</em></span>的特征图进行归一化处理，可以使得数据的分布更加稳定。</p><p>上述是在训练的过程中使用的，在测试过程中使用不了称为<strong>训练推理失配</strong><em>traininferencemismatch</em>。可以使用EMA（指数滑动平均）的方法来进行替代。</p><p>上述要求n大概是16，在比较大的模型中，可能显存不够。上述方法有一个替代的方法<em>LayerNormalization</em>，对于每一个样本进行归一化处理。</p><p>在使用了<em>BatchNormalization</em>之后，仍然有协变量偏移<em>covariateshift</em>的问题。但是在使用<em>BatchNormalization</em>之后，<em>Lipchitz</em>系数变化更加平稳，海森矩阵也更加稳定。上述可以用数学严格证明。<strong>上述操作并不是简单的归一化，而是使得表示的函数族更加光滑，一个光滑的、凸的函数更容易优化。</strong></p><ul><li>Lipchitz: <span class="math display">$$\left\|\nabla_{y_j} \hat{\mathcal{L}}\right\|^2 \leq\frac{\gamma^2}{\sigma_j^2}\left(\left\|\nabla_{y_j}\right\|^2-\frac{1}{m}\left(1,\nabla_{y_j} \mathcal{L}\right)^2-\frac{1}{m}\left(\nabla_{y_j}\mathcal{L}, \hat{y}_j\right)^2\right)$$</span></li><li>Smoothness: <span class="math display"><em>γ</em> &lt; <em>σ</em> inexperiments </span></li><li>Hessian matrix</li></ul><p><span class="math display">$$\left(\nabla_{y_j} \hat{\mathcal{L}}\right)^T \frac{\partial\hat{\mathcal{L}}}{\partial y_j \partial y_j}\left(\nabla_{y_j}\hat{\mathcal{L}}\right) \leq\frac{\gamma^2}{\sigma_j^2}\left(\left(\nabla_{y_j} \mathcal{L}\right)^T\frac{\partial \mathcal{L}}{\partial y_j \partial y_j}\left(\nabla_{y_j}\mathcal{L}\right)-\frac{\gamma}{m \sigma^2}\left(\nabla_{y_j}\mathcal{L}, \hat{y}_j\right)\left\|\nabla_{y_j}\hat{\mathcal{L}}\right\|^2\right)$$</span></p><h3 id="group-normalization">Group Normalization</h3><figure><img src="%7B139D48AB-F664-4CE8-AC05-97B772908A85%7D.png"alt="{139D48AB-F664-4CE8-AC05-97B772908A85}" /><figcaptionaria-hidden="true">{139D48AB-F664-4CE8-AC05-97B772908A85}</figcaption></figure><p>在<em>GroupNormalization</em>中，对于每一个通道的特征图进行归一化处理，这样可以减少计算的复杂度。是轻量化CNN的方法。在一定数据量较大的情况下可以达到和<em>BatchNormalization</em>差不多的结果。因此，GN非常适用于那些因为模型太大或图片太大而只能使用小batchsize的场景，比如目标检测、实例分割和视频理解等。</p><h1 id="generalization-and-capacity">Generalization and Capacity</h1><ul><li>CNN之所以能用更少的参数达到和FCN（全连接网络）相当甚至更好的效果，是因为它的结构（局部连接、权值共享）非常适合处理图像数据，这是一种“聪明”的设计，用更高效的方式利用了模型容量。这说明<strong>容量不只与参数数量有关，还与参数的组织方式有关</strong>。</li><li>在结构固定的情况下，增加参数量通常会提升模型的容量，使其能够拟合更复杂的数据模式，因此在训练数据上表现更好。但这也会增加<strong>过拟合</strong>的风险，即模型可能会“死记硬背”训练数据而丧失了<strong>泛化</strong>到新数据的能力。</li></ul><h2id="theorem-arbitrarily-large-neural-networks-can-approximate-any-function">Theorem(Arbitrarily large neural networks can approximate any function)</h2><p>理论可以表述为：对于任意的连续函数，存在一个足够大的神经网络可以近似这个函数。<img src="{79D51D58-D7B7-485E-9A0F-5F615FE27545}.png" alt="" width="500">上面表示两层神经网络可以逼近任意的连续函数，要求这个函数<spanclass="math inline"><em>σ</em></span>不是多项式函数。</p><p><img src="{862689B6-2775-4822-8FAC-B0450B360BA0}.png" alt="" width="500">上面的定理表示神经网络的宽度也很重要，可以通过增加神经元的数量来逼近函数。</p><p>在空间折叠的问题中，表明<strong>深度比宽度更加重要</strong>。</p>]]></content>
    
    
    
    <tags>
      
      <tag>DeepLearning</tag>
      
      <tag>MLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI Agent Notes</title>
    <link href="/2025/07/20/ML_Lee/AI%20Agent/"/>
    <url>/2025/07/20/ML_Lee/AI%20Agent/</url>
    
    <content type="html"><![CDATA[<p><strong>AIAgent</strong>：人类<mark>只给AI目标</mark>，AI自己想办法完成某个研究问题。</p><p><img src="{281D8726-4976-4970-BCA0-4A9C9D175927}.png" alt="" width="450"></p><p>整个图示清晰地展现了强化学习的核心循环：智能体观察环境的<strong>状态</strong>(棋盘布局)，基于其策略和<strong>目标</strong> (赢棋)来选择一个<strong>行动</strong>(下一步棋)，该行动改变了环境的<strong>状态</strong>，然后智能体又观察到新的状态，如此循环往复，直到游戏结束分出胜负。通过这种方式，AI的目标（图中的“赢棋”）被转化成了一个数学问题：<strong>如何选择一系列的行动（下棋），来最大化未来能获得的累积奖励（最终得到那个+1）</strong>。</p><p>强化学习 (<em>RL</em>) 就是一个让智能体 (<em>Agent</em>) 在与环境(<em>Environment</em>) 的互动中，通过“试错” (<em>Trial-and-Error</em>)的方式来自主学习的过程。它的学习目标是找到一个最优策略(<em>Policy</em>)，也就是一套决策方法，使得它从长远来看能够获得的累积奖励(<em>Cumulative Reward</em>) 最多。</p><blockquote><p>但是上面的问题在于<strong>需要为每一个任务训练特定的模型</strong>，而且需要大量的计算资源。<mark>能不能使用一个模型来完成所有的任务？</mark></p></blockquote><p><img src="{FC397F83-D2DE-4C4E-9F05-5329C2558432}.png" alt="" width="450"></p><p>上面的过程就是LLM擅长的文字接龙功能。</p><h3 id="ai-agent-llm">AI Agent&amp; LLM</h3><p><strong>优势</strong>：能够理解和利用“丰富的、人类可读的”反馈信息，而不仅仅是“稀疏的、数字化的”奖励信号，从而极大地提升了学习和纠错的效率。<mark>在下面过程中都不涉及AI的训练过程</mark>。</p><h4 id="computer-use-operator">Computer Use Operator</h4><p><strong>Mind2Web</strong>是一个从超过100个真实网站上收集的大规模、多样化的<strong>数据集</strong>。它的核心贡献是提供了高质量的训练材料，用于教导一个通用的AI智能体如何遵循指令，在任何网站上执行任务，而不仅仅是在简化的或模拟的网站上。<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2306.06070] Mind2Web: Towards a Generalist Agent for the Web](https://arxiv.org/abs/2306.06070)">[1]</span></a></sup></p><p><strong>WebArena</strong>是一个充满挑战的<strong>基准测试（Benchmark）</strong>，其包含功能齐全的网站和复杂的任务，旨在公平地评估和比较不同的智能体。<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2307.13854] WebArena: A Realistic Web Environment for Building Autonomous Agents](https://arxiv.org/abs/2307.13854)">[2]</span></a></sup></p><p>WebArena主要测试基于文本的能力。<strong>VisualWebArena</strong>是一个专门测试智能体<strong>多模态能力</strong>的高级基准测试。这个环境中的任务要求智能体不仅要阅读文本，还要<strong>理解视觉信息</strong>（如图片、图标和布局）才能成功。<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2401.13649] VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks](https://arxiv.org/abs/2401.13649)">[3]</span></a></sup></p><h4 id="ai-agent-for-model-training-scientific-research">AI Agent forModel Training &amp; Scientific Research</h4><p><strong>AIDE</strong>，是一个<strong>单一、自主的AI智能体</strong>，它的目标是接管人类工程师繁琐、耗时的“试错”工作。将整个机器学习开发过程视为一个<strong>代码优化问题</strong>，并运用<strong>树状搜索<em>TreeSearch</em></strong>等策略，独立地在众多可能性中寻找最佳解决方案。<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2502.13138] AIDE: AI-Driven Exploration in the Space of Code](https://arxiv.org/abs/2502.13138)">[4]</span></a></sup></p><p><strong>AutoKaggle</strong>：将复杂的任务分解，由一个<strong>多智能体系统<em>Multi-AgentSystem</em></strong>协作完成，团队里可能有负责数据清洗、特征工程、模型训练等不同角色的“专家”。最关键的是，它强调与<strong>人类用户的协作</strong>，允许人类在各个环节介入和指导。<sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[[2410.20424] AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions](https://arxiv.org/abs/2410.20424)">[5]</span></a></sup></p><p><strong>GoogleCoscientist</strong>：是一个<strong>多智能体系统<em>Multi-agentsystem</em></strong>，不同的“AI智能体”扮演不同角色（比如有的负责生成假设，有的负责验证，有的负责寻找证据），它们协同工作。能主动使用外部工具，例如调用<strong>谷歌搜索</strong>来查阅最新的网络信息。<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[Accelerating scientific breakthroughs with an AI co-scientist](https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/)">[6]</span></a></sup></p><h3 id="ai-agent如何根据经验调整行为">AI Agent如何根据经验调整行为</h3><p><img src="{22EECDE5-9FA4-41A9-A3AA-02B15F268B9A}.png" alt="" width="450"></p><p>当AI行动时，现实世界会发生变化（上图中的<em>obs</em>），在AI下一次行动时会根据以前的经验来作出更好的决策。</p><h4 id="rag">RAG</h4><p><strong>RAG</strong>（<em>Retrieval-AugmentedGeneration</em>）通过检索相关信息来增强生成模型的能力，使得生成的内容更加准确和有针对性。</p><ul><li><strong>检索 (<em>Retrieval</em>)</strong>:当收到用户提问时，系统不会直接让大模型回答。而是先用提问的关键词，去一个外部的知识库（比如公司的内部文档、最新的网络新闻、或者像这张幻灯片里的“智能体记忆库”）中，搜索最相关的信息片段。</li><li><strong>增强 (<em>Augmented</em>)</strong>:将上一步检索到的相关信息，连同用户原始的提问，一起“打包”成一个新的、内容更丰富的提示（Prompt）。</li><li><strong>生成 (<em>Generation</em>)</strong>:将这个被增强后的提示（Prompt）发送给大模型，让它基于这些新鲜、准确的参考资料来生成最终的回答。<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2312.10997] Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997)">[7]</span></a></sup></li></ul><h4 id="streambench">Streambench</h4><p><strong>StreamBench</strong>是<strong>第一个专门为评估LLM智能体持续改进能力而设计的基准测试</strong>。它模拟了一个在线学习环境，让智能体不断接收新的任务和反馈流，从而可以衡量其性能是否能随着时间的推移而不断增强。</p><h4 id="write-reflection-read">Write &amp; Reflection &amp; Read</h4><p><img src="{D54BA4B1-ACDF-404C-968F-018E57CD0D26}.png" alt="" width="450"></p><ul><li><strong>Write</strong>:主要是<strong>数据存储</strong>，基本不用Prompt。但在<strong>执行<code>Write</code>操作之前</strong>，可以增加一个“<strong>重要性评估</strong>”的环节。这个环节的核心就是一个精心设计的Prompt。</li><li><strong>Reflection</strong>:核心是<strong>Prompt工程</strong>，通过Prompt引导LLM从原始数据中提炼智慧。</li><li><strong>Read</strong>: 核心是<strong>RAG</strong>，通过“检索算法 +Prompt工程”的组合，利用历史智慧指导当前决策</li></ul><p><strong>GraphRAG</strong>：标准的<strong>RAG (检索增强生成)</strong>方法擅长回答“具体问题”，因为它可以直接从知识库中检索到包含答案的一小部分文档。但是，当面对需要理解和总结<strong>整个文档集合</strong>的“全局性问题”时，标准RAG会失效，因为它不知道该检索哪一小块信息来回答这种开放式的问题。<sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2404.16130] From Local to Global: A Graph RAG Approach to Query-Focused Summarization](https://arxiv.org/abs/2404.16130)">[8]</span></a></sup></p><ul><li><strong>构建实体知识图谱</strong>:首先，用一个大型语言模型（LLM）通读所有源文档，提取出关键的实体（如人物、地点、概念），并建立它们之间的关系，形成一个网络状的知识图谱。</li><li><strong>预生成社群摘要</strong>:接着，在图谱中自动识别出那些关联非常紧密的“实体社群”（可以理解为主题簇），然后再次使用LLM为<strong>每一个社群</strong>都预先生成一份高质量的摘要</li></ul><p><strong>HippoRAG</strong>：传统RAG回答复杂问题时，往往需要反复提问、多次检索（这被称为迭代式检索），就像一个新手管理员跑好几趟书架。而HippoRAG凭借其图算法，<strong>一次检索</strong>就能理清复杂的关系链，性能因此<strong>提升高达20%</strong>。<sup id="fnref:9" class="footnote-ref"><a href="#fn:9" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2405.14831] HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models](https://arxiv.org/abs/2405.14831)">[9]</span></a></sup>将RAG的“检索”从一个简单的“文本相似度匹配”任务，升级为了一个更深刻的“知识关系图遍历”任务，通过模仿人脑高效的索引机制。</p><h3 id="ai如何使用工具">AI如何使用工具</h3><p><strong>Tool Use</strong>：AIAgent使用工具的能力是其核心特征之一。通过调用外部工具，AI可以扩展其能力，完成更复杂的任务。</p><p><img src="Pasted%20image%2020250720102659.png" alt="" width="450"></p><p><strong>语言模型本身并不“执行”工具，而是“生成”一段代表工具调用的文本</strong>。</p><p>它生成的这串<code>&lt;tool&gt;...&lt;/tool&gt;</code>文本，只是一个结构化的“意图表达”。需要一个<strong>外部的控制程序<em>Orchestrator</em></strong>来解析这个文本，并实际执行相应的工具调用。<strong>控制程序</strong>再去<strong>真正地调用</strong>一个天气API，并将参数传递过去。天气API返回结果后，控制程序再将结果封装成<code>&lt;output&gt;...&lt;/output&gt;</code>格式，发回给语言模型，让它以自然语言的形式呈现给用户。</p><p><strong>Search Engine</strong>：AIAgent可以通过调用搜索引擎来获取最新的信息和数据。这种能力使得AI能够在动态变化的环境中保持更新。可以使用搜索到的内容运行RAG后输出。</p><p>除了上述使用的搜索引擎、API等工具使用方法外，AI也可以使用更大或者有专门功能的模型（math、code）来实现更复杂的任务。</p><h4 id="tool-selection">Tool Selection</h4><p><strong>Tool Selection</strong>是指AIAgent在多个可用工具中选择最适合当前任务的工具。这个过程通常涉及以下几个步骤：</p><p><strong>MetaTool基准</strong><sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2310.03128] MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use](https://arxiv.org/abs/2310.03128)">[10]</span></a></sup></p><ul><li><strong>核心构成</strong>：MetaTool包含一个名为 <code>ToolE</code>的数据集，里面有各种各样能够触发LLM使用工具的用户查询（Prompt），覆盖了单工具和多工具使用的场景。</li><li><strong>评测任务</strong>：它专门评估LLM的两种核心能力：<ul><li><strong>工具使用意识</strong>：判断当前问题是否真的需要使用工具。</li><li><strong>工具选择</strong>：从众多工具中选出最合适的一个或多个。这个任务还被细分为四个更具挑战性的子任务，例如：从功能相似的工具中做选择、在特定场景下做选择、考虑工具的可靠性问题，以及选择多个工具进行组合。</li></ul></li></ul><p><strong>OctoTools</strong>引入了三个关键组件来协同工作：<sup id="fnref:11" class="footnote-ref"><a href="#fn:11" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2502.11271] OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning](https://arxiv.org/abs/2502.11271)">[11]</span></a></sup></p><ol type="1"><li><strong>标准化工具卡片 (<em>Standardized ToolCards</em>)</strong>：这是一个核心创新。它用一种标准化的格式来封装和描述任何工具的功能，使得添加新工具就像插拔模块一样简单。</li><li><strong>规划器(<em>Planner</em>)</strong>：负责进行任务规划。它既能做宏观的“高层规划”（将复杂任务拆解成小步骤），也能做微观的“低层规划”（为每个小步骤决定具体使用哪个工具）。</li><li><strong>执行器<em>(Executor</em>)</strong>：负责实际执行由“规划器”定下的工具调用指令。</li></ol><p>更进一步的，AI还可以自己打造工具</p><p>TROVE的核心思想是让一个擅长编程的语言模型（CodeLM）来扮演“工具开发者”的角色。它采用一个动态的、自我完善的流程来构建工具箱：<sup id="fnref:12" class="footnote-ref"><a href="#fn:12" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2401.12869] TroVE: Inducing Verifiable and Efficient Toolboxes for Solving Programmatic Tasks](https://arxiv.org/abs/2401.12869)">[12]</span></a></sup></p><ol type="1"><li><strong>在使用中生成 (Generate viaUsing)</strong>：在解决实际问题的过程中，AI会识别出那些频繁被组合使用的基础操作，并尝试将它们打包成一个更高级、可复用的新函数。</li><li><strong>成长(Grow)</strong>：将新创建的、被证明有用的高级函数加入到“工具箱”中，供后续解决其他问题时直接调用。</li><li><strong>定期修剪(Trim)</strong>：为了防止工具箱变得臃肿，系统会定期清理，移除那些不常用、冗余或效果不佳的函数，始终保持工具箱小而精悍。</li></ol><p>但是使用工具带来的问题是：Agent可能会因为<strong>过度相信工具而犯错</strong>。尤其是当外部知识用冲突，或者与LLM训练时获得的知识冲突时，Agent可能会错误地依赖工具的输出，而不是自己的判断。即使所有找到的资料都是正确的，不代表AI就不会犯错。</p><p><img src="{BBAE77B9-5B82-4103-88B0-BEB5D20B0FA6}.png" alt="" width="450"><em>研究什么样的外部知识比较容易说服AI</em></p><h3 id="ai能不能做计划">AI能不能做计划</h3><p>AIAgent的计划能力是其智能化的重要体现。通过制定计划，AI可以更有效地组织和执行任务。但是现实世界是一直<strong>变化的</strong>，AI是否有能力根据环境的变化来调整自己的计划呢？</p><p>在开发Benchmark时，有可能一些较为常见的计划任务已经被用于训练，导致模型的泛化能力不足。新的Benchmark会构建一个新的情境用于测试AI的计划能力。<sup id="fnref:13" class="footnote-ref"><a href="#fn:13" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2305.15771] On the Planning Abilities of Large Language Models : A Critical Investigation](https://arxiv.org/abs/2305.15771)">[13]</span></a></sup></p><p>对于优化Agent的计划能力，自然的想法是利用试探回溯的搜索方法实现：当智能体需要做决策时，它不再是只选择一个“最好”的下一步行动。相反，它会在真实的环境中<strong>探索多个不同的行动分支</strong>，构建一个“决策树”。它会评估这些不同路径的潜在价值，然后优先沿着最有希望成功的路径继续深入探索，从而实现多步规划。<sup id="fnref:14" class="footnote-ref"><a href="#fn:14" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2407.01476] Tree Search for Language Model Agents](https://arxiv.org/abs/2407.01476)">[14]</span></a></sup></p><p>但是显示世界中很多操作是<strong>无法回溯</strong>的，一种想法是构建<strong>世界模型</strong>来模拟现实世界的变化。通过这种方式，AIAgent可以在虚拟环境中进行试验和调整，然后再将这些经验应用到现实世界中。<sup id="fnref:15" class="footnote-ref"><a href="#fn:15" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[[2411.06559] Is Your LLM Secretly a World Model of the Internet? Model-Based Planning for Web Agents](https://arxiv.org/abs/2411.06559)">[15]</span></a></sup></p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1"class="footnote-text"><span><a href="https://arxiv.org/abs/2306.06070">[2306.06070]Mind2Web: Towards a Generalist Agent for the Web</a><a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:2"class="footnote-text"><span><a href="https://arxiv.org/abs/2307.13854">[2307.13854]WebArena: A Realistic Web Environment for Building Autonomous Agents</a><a href="#fnref:2" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:3"class="footnote-text"><span><a href="https://arxiv.org/abs/2401.13649">[2401.13649]VisualWebArena: Evaluating Multimodal Agents on Realistic Visual WebTasks</a> <a href="#fnref:3" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:4"class="footnote-text"><span><a href="https://arxiv.org/abs/2502.13138">[2502.13138]AIDE: AI-Driven Exploration in the Space of Code</a><a href="#fnref:4" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:5"class="footnote-text"><span>[<a href="https://arxiv.org/abs/2410.20424">[2410.20424]AutoKaggle: A Multi-Agent Framework for Autonomous Data ScienceCompetitions</a><a href="#fnref:5" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:6" class="footnote-text"><span><ahref="https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/">Acceleratingscientific breakthroughs with an AI co-scientist</a><a href="#fnref:6" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:7"class="footnote-text"><span><a href="https://arxiv.org/abs/2312.10997">[2312.10997]Retrieval-Augmented Generation for Large Language Models: A Survey</a><a href="#fnref:7" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:8"class="footnote-text"><span><a href="https://arxiv.org/abs/2404.16130">[2404.16130]From Local to Global: A Graph RAG Approach to Query-FocusedSummarization</a><a href="#fnref:8" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:9"class="footnote-text"><span><a href="https://arxiv.org/abs/2405.14831">[2405.14831]HippoRAG: Neurobiologically Inspired Long-Term Memory for Large LanguageModels</a> <a href="#fnref:9" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:10"class="footnote-text"><span><a href="https://arxiv.org/abs/2310.03128">[2310.03128]MetaTool Benchmark for Large Language Models: Deciding Whether to UseTools and Which to Use</a><a href="#fnref:10" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:11"class="footnote-text"><span><a href="https://arxiv.org/abs/2502.11271">[2502.11271]OctoTools: An Agentic Framework with Extensible Tools for ComplexReasoning</a><a href="#fnref:11" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:12"class="footnote-text"><span><a href="https://arxiv.org/abs/2401.12869">[2401.12869]TroVE: Inducing Verifiable and Efficient Toolboxes for SolvingProgrammatic Tasks</a><a href="#fnref:12" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:13"class="footnote-text"><span><a href="https://arxiv.org/abs/2305.15771">[2305.15771]On the Planning Abilities of Large Language Models : A CriticalInvestigation</a><a href="#fnref:13" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:14"class="footnote-text"><span><a href="https://arxiv.org/abs/2407.01476">[2407.01476]Tree Search for Language Model Agents</a><a href="#fnref:14" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:15"class="footnote-text"><span><a href="https://arxiv.org/abs/2411.06559">[2411.06559]Is Your LLM Secretly a World Model of the Internet? Model-Based Planningfor Web Agents</a><a href="#fnref:15" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    
    <tags>
      
      <tag>DeepLearning</tag>
      
      <tag>AI</tag>
      
      <tag>李宏毅机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从 Obsidian 到 Hexo：打造完美的数学公式与图片发布流</title>
    <link href="/2025/06/24/blog/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/"/>
    <url>/2025/06/24/blog/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<p>对于许多技术爱好者和研究者来说，Obsidian是无与伦比的个人知识管理（PKM）神器，而 Hexo则是搭建静态博客的绝佳选择。然而，当我们试图将两者结合，打造一个从“笔记”到“发布”的流畅工作流时，常常会遇到一个巨大的障碍：Obsidian中便捷的语法（尤其是数学公式和图片链接）与 Hexo 的标准渲染流### 结语</p><p>通过结合 Hexo 的 Fluid 主题配置、Pandoc 渲染器、一个智能的 Python图片转换脚本和一个自动化的发布脚本，我们最终打通了 Obsidian 和 Hexo之间的”任督二脉”。这套工作流将所有复杂性都封装在了工具背后，让我们可以重新专注于最重要的事——思考与创作。</p><p>主要技术栈： - <strong>主题</strong>：Fluid 主题，内置 MathJax 支持 -<strong>渲染器</strong>：hexo-renderer-pandoc，对数学公式友好 -<strong>转换脚本</strong>：convert_obsidian_to_hexo.py，专门处理图片链接转换-<strong>发布脚本</strong>：publish.sh，一键完成转换、清理、生成、部署</p><p>本文将记录一次完整的“踩坑”与“填坑”过程，最终形成一套强大、可靠的自动化解决方案，让你只需一条命令，即可将Obsidian 笔记完美发布到 Hexo 博客。</p><p>对于网站的搭建可以参考<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="https://zhuanlan.zhihu.com/p/392994381">[1]</span></a></sup></p><h3id="问题所在便利性与标准化的冲突">问题所在：便利性与标准化的冲突</h3><p>我们的核心痛点在于，Obsidian 为了用户体验，使用了许多非标准的Markdown 语法，而 Hexo 依赖于标准的渲染器。</p><table><thead><tr class="header"><th style="text-align: left;">功能</th><th style="text-align: left;">你在 Obsidian 中的写法</th><th style="text-align: left;">标准 Markdown / HTML</th><th style="text-align: left;">冲突点</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>下标</strong></td><td style="text-align: left;"><code>$x\_i$</code></td><td style="text-align: left;"><code>&lt;em&gt;</code> 标签</td><td style="text-align: left;"><code>_</code> 被 Markdown错误地解析为斜体。</td></tr><tr class="even"><td style="text-align: left;"><strong>图片嵌入</strong></td><tdstyle="text-align: left;"><code>![my_image.png](my_image.png)</code></td><td style="text-align: left;"><code>![alt](image.png)</code></td><td style="text-align: left;">Hexo 完全不认识 <code>![...](...)</code>这种 Wikilink 语法。</td></tr><tr class="odd"><td style="text-align: left;"><strong>图片粘贴</strong></td><td style="text-align: left;"><code>![](image.png)</code></td><td style="text-align: left;"><code>![](image.png)</code></td><td style="text-align: left;">Obsidian可能会生成指向你本地硬盘的绝对路径，这在网站上无效。</td></tr><tr class="even"><td style="text-align: left;"><strong>LaTeX 命令</strong></td><td style="text-align: left;"><code>\frac</code>,<code>\begin&#123;aligned&#125;</code></td><td style="text-align: left;"><code>\</code></td><td style="text-align: left;"><code>\</code>是特殊转义符，在处理中可能被“吃掉”。</td></tr><tr class="odd"><td style="text-align: left;"><strong>公式换行</strong></td><td style="text-align: left;"><code>\\</code></td><td style="text-align: left;"><code>\</code></td><td style="text-align: left;">两个 <code>\</code>可能在处理后只剩一个，导致换行失败。</td></tr></tbody></table><p>手动去修改每一篇文章中的这些问题，无疑是一场灾难。我们的目标是：<strong>在Obsidian 中自由写作，用一个自动化工具处理所有兼容性问题。</strong></p><h3 id="第一步配置-hexo为数学公式提供最佳渲染环境">第一步：配置Hexo，为数学公式提供最佳渲染环境</h3><p>在解决兼容性问题之前，我们首先要确保 Hexo本身具备渲染高质量数学公式的能力。我们采用现代化的 Fluid主题，它内置了对数学公式的完美支持。</p><ol type="1"><li><p><strong>安装 Fluid 主题</strong> Fluid 是一个现代化的 Hexo主题，内置了对数学公式的完美支持： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install hexo-theme-fluid<br></code></pre></td></tr></table></figure></p></li><li><p><strong>更换 Markdown 渲染器</strong> 由于 Hexo 默认的 Markdown渲染器不支持复杂公式，我们需要更换为 Pandoc 渲染器： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm uninstall hexo-renderer-marked --save<br>npm install hexo-renderer-pandoc --save<br></code></pre></td></tr></table></figure></p><p><strong>重要</strong>：还需要<ahref="https://github.com/jgm/pandoc/blob/master/INSTALL.md">安装Pandoc</a> 到你的系统中。</p></li><li><p><strong>配置 <code>_config.yml</code></strong>在你的博客根目录下的 <code>_config.yml</code> 文件中，设置主题为 fluid：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">theme:</span> <span class="hljs-string">fluid</span><br></code></pre></td></tr></table></figure></p></li><li><p><strong>配置 <code>_config.fluid.yml</code></strong>在你的博客根目录下创建 <code>_config.fluid.yml</code>文件，配置数学公式支持： <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">post:</span><br>  <span class="hljs-attr">math:</span><br>    <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br>    <span class="hljs-attr">specific:</span> <span class="hljs-literal">true</span> <span class="hljs-comment"># 强烈建议设为 true，只在有数学公式的页面加载</span><br>    <span class="hljs-attr">engine:</span> <span class="hljs-string">&#x27;mathjax&#x27;</span> <span class="hljs-comment"># 使用 MathJax 引擎</span><br></code></pre></td></tr></table></figure></p></li><li><p><strong>在文章中启用数学公式</strong>对于需要使用数学公式的文章，在 front-matter 中添加<code>math: true</code>： <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">文章标题</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2025-01-01</span><br><span class="hljs-attr">math:</span> <span class="hljs-literal">true</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure></p></li><li><p><strong>清除缓存</strong> 安装完成后执行： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo clean<br></code></pre></td></tr></table></figure></p></li></ol><p>完成这一步，你的 Hexo 博客就已经拥有了渲染任何标准 LaTeX公式的能力。</p><p><strong>数学公式书写格式：</strong></p><p>行内公式：<code>$E=mc^2$</code></p><p>块级公式： <figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-built_in">$</span><span class="hljs-built_in">$</span><br><span class="hljs-keyword">\frac</span>&#123;<span class="hljs-keyword">\partial</span> f&#125;&#123;<span class="hljs-keyword">\partial</span> x&#125; = 2<span class="hljs-keyword">\rho</span> <span class="hljs-keyword">\frac</span>&#123;<span class="hljs-keyword">\partial</span> f&#125;&#123;<span class="hljs-keyword">\partial</span> <span class="hljs-keyword">\rho</span>&#125;<br><span class="hljs-built_in">$</span><span class="hljs-built_in">$</span><br></code></pre></td></tr></table></figure></p><p>现在，我们来解决如何将 Obsidian 的”方言”转换成”标准普通话”。</p><h3id="第二步打造你的专属智能翻译官-python-自动化脚本">第二步：打造你的专属”智能翻译官”——Python 自动化脚本</h3><p>我们将编写一个 Python脚本，它将作为我们工作流的核心。它的任务是读取我们从 Obsidian 写好的Markdown 文件，并自动完成所有必需的修复和转义。</p><p>在你的博客根目录下，创建一个名为<code>convert_obsidian_to_hexo.py</code>的文件，并将以下代码粘贴进去。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># convert_obsidian_to_hexo.py</span><br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> shutil<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> urllib.parse<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_image_links</span>(<span class="hljs-params">content, image_prefix</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    将本地图片路径和 wikilinks 转换为新的 URL 前缀。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># --- 用于修复绝对本地路径 (例如 file:///C:/...) 的函数 ---</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fix_local_path</span>(<span class="hljs-params"><span class="hljs-keyword">match</span></span>):<br>        alt_text = <span class="hljs-keyword">match</span>.group(<span class="hljs-number">1</span>)<br>        local_path_raw = <span class="hljs-keyword">match</span>.group(<span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># 解码 URL 编码的字符，例如 %20 (空格)</span><br>        local_path = urllib.parse.unquote(local_path_raw)<br>        <span class="hljs-comment"># 从路径中仅获取文件名</span><br>        filename = os.path.basename(local_path)<br>        <span class="hljs-comment"># 重新编码文件名以使其对 URL 安全</span><br>        encoded_filename = urllib.parse.quote(filename)<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;![<span class="hljs-subst">&#123;alt_text&#125;</span>](<span class="hljs-subst">&#123;image_prefix&#125;</span><span class="hljs-subst">&#123;encoded_filename&#125;</span>)&quot;</span><br><br>    <span class="hljs-comment"># 用于查找带有绝对本地路径的图片链接的正则表达式</span><br>    local_path_regex = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r&#x27;!\[(.*?)\]\(((?:[a-zA-Z]:|file:)[\\/].*?)\)&#x27;</span>)<br>    content = local_path_regex.sub(fix_local_path, content)<br><br>    <span class="hljs-comment"># --- 用于替换 wikilinks (例如 ![image.png](image.png)) 的函数 ---</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">replace_wikilink</span>(<span class="hljs-params"><span class="hljs-keyword">match</span></span>):<br>        filename = <span class="hljs-keyword">match</span>.group(<span class="hljs-number">1</span>).strip()<br>        encoded_filename = urllib.parse.quote(filename)<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;![<span class="hljs-subst">&#123;filename&#125;</span>](<span class="hljs-subst">&#123;image_prefix&#125;</span><span class="hljs-subst">&#123;encoded_filename&#125;</span>)&quot;</span><br><br>    <span class="hljs-comment"># 用于查找 wikilink 样式的图片嵌入的正则表达式</span><br>    wikilink_regex = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r&#x27;!\[\[(.*?)\]\]&#x27;</span>)<br>    content = wikilink_regex.sub(replace_wikilink, content)<br><br>    <span class="hljs-keyword">return</span> content<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_single_file</span>(<span class="hljs-params">filepath, create_backup, image_prefix</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    处理单个 markdown 文件以进行图片链接转换。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;正在检查: <span class="hljs-subst">&#123;filepath&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            original_content = f.read()<br><br>        <span class="hljs-comment"># 检查文件是否已被转换</span><br>        fm_match = re.<span class="hljs-keyword">match</span>(<span class="hljs-string">r&#x27;---\s*?\n(.*?)\n---\s*?\n&#x27;</span>, original_content, re.DOTALL)<br>        <span class="hljs-keyword">if</span> fm_match <span class="hljs-keyword">and</span> <span class="hljs-string">&#x27;images_converted: true&#x27;</span> <span class="hljs-keyword">in</span> fm_match.group(<span class="hljs-number">1</span>):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;  -&gt; 跳过: 文件已被标记为已转换。&quot;</span>)<br>            <span class="hljs-keyword">return</span><br><br>        <span class="hljs-comment"># 如果启用，则创建备份</span><br>        <span class="hljs-keyword">if</span> create_backup:<br>            backup_path = filepath + <span class="hljs-string">&quot;.bak&quot;</span><br>            shutil.copy2(filepath, backup_path)<br><br>        <span class="hljs-comment"># 转换图片链接</span><br>        converted_content = convert_image_links(original_content, image_prefix)<br><br>        <span class="hljs-comment"># 如果内容已更改，则将其写回文件</span><br>        <span class="hljs-keyword">if</span> original_content != converted_content:<br>            <span class="hljs-comment"># 更新或添加 front matter 以标记为已转换</span><br>            <span class="hljs-keyword">if</span> fm_match:<br>                front_matter_content = fm_match.group(<span class="hljs-number">1</span>)<br>                new_front_matter = front_matter_content.strip() + <span class="hljs-string">&quot;\nimages_converted: true\n&quot;</span><br>                main_content_start_index = fm_match.end()<br>                final_content = original_content[:main_content_start_index].replace(front_matter_content, new_front_matter) + converted_content[main_content_start_index:]<br>            <span class="hljs-keyword">else</span>:<br>                new_front_matter = <span class="hljs-string">&quot;images_converted: true\n&quot;</span><br>                final_content = <span class="hljs-string">f&quot;---\n<span class="hljs-subst">&#123;new_front_matter&#125;</span>---\n\n<span class="hljs-subst">&#123;converted_content&#125;</span>&quot;</span><br>            <br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                f.write(final_content)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;  -&gt; 图片链接已转换并已标记文件。&quot;</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;  -&gt; 无需转换任何图片链接。&quot;</span>)<br><br>    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;  -&gt; 处理文件 <span class="hljs-subst">&#123;filepath&#125;</span> 时出错: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>, file=sys.stderr)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_path</span>(<span class="hljs-params">path, create_backup, image_prefix</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    递归处理给定路径（文件或目录）中的文件。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> os.path.isfile(path):<br>        <span class="hljs-keyword">if</span> path.endswith(<span class="hljs-string">&quot;.md&quot;</span>):<br>            process_single_file(path, create_backup, image_prefix)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;跳过非 markdown 文件: <span class="hljs-subst">&#123;path&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">elif</span> os.path.isdir(path):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;正在处理目录: <span class="hljs-subst">&#123;path&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">for</span> root, _, files <span class="hljs-keyword">in</span> os.walk(path):<br>            <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> files:<br>                <span class="hljs-keyword">if</span> file.endswith(<span class="hljs-string">&quot;.md&quot;</span>):<br>                    file_path = os.path.join(root, file)<br>                    process_single_file(file_path, create_backup, image_prefix)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;错误: 路径不存在: <span class="hljs-subst">&#123;path&#125;</span>&quot;</span>, file=sys.stderr)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    parser = argparse.ArgumentParser(description=<span class="hljs-string">&quot;转换 Markdown 文件中的图片链接。&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;paths&quot;</span>, metavar=<span class="hljs-string">&quot;PATH&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, nargs=<span class="hljs-string">&#x27;+&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;一个或多个要处理的 markdown 文件或目录的路径。&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--image-prefix&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;|images|&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;图片链接的伪装绝对路径前缀 (例如, &#x27;|images|&#x27; 会变成 &#x27;/images/&#x27;)。&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--no-backup&quot;</span>, action=<span class="hljs-string">&quot;store_false&quot;</span>, dest=<span class="hljs-string">&quot;create_backup&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;禁用创建 .bak 备份文件。&quot;</span>)<br>    <br>    args = parser.parse_args()<br>    <br>    <span class="hljs-comment"># 从其伪装形式恢复前缀</span><br>    disguised_prefix = args.image_prefix<br>    image_prefix = disguised_prefix.replace(<span class="hljs-string">&#x27;|&#x27;</span>, <span class="hljs-string">&#x27;/&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;--- 接收到伪装前缀: &#x27;<span class="hljs-subst">&#123;disguised_prefix&#125;</span>&#x27;, 已恢复为: &#x27;<span class="hljs-subst">&#123;image_prefix&#125;</span>&#x27; ---&quot;</span>)<br><br>    <span class="hljs-keyword">for</span> path <span class="hljs-keyword">in</span> args.paths:<br>        process_path(path, args.create_backup, image_prefix)<br>        <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n转换过程完成。&quot;</span>)<br></code></pre></td></tr></table></figure><h3 id="第三步封装一切的总指挥-shell-脚本">第三步：封装一切的“总指挥”——Shell 脚本</h3><p>为了实现“一键发布”，我们编写一个 shell 脚本来调用 Python脚本，并执行所有 Hexo 命令。</p><p>在你的博客根目录下，创建一个名为 <code>publish.sh</code>的文件，并粘贴以下代码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-comment"># publish.sh - Final workaround version using parameter disguise.</span><br><br><span class="hljs-built_in">set</span> -e<br><br><span class="hljs-comment"># --- Default Configuration ---</span><br>PYTHON_SCRIPT=<span class="hljs-string">&quot;convert_obsidian_to_hexo.py&quot;</span> <span class="hljs-comment"># 确保这个文件名和你的Python脚本文件名一致</span><br>SOURCE_DIR=<span class="hljs-string">&quot;source/_posts/&quot;</span><br><span class="hljs-comment"># This is the REAL prefix we want.</span><br>IMAGE_PREFIX=<span class="hljs-string">&quot;/images/&quot;</span> <br><br><span class="hljs-comment"># --- ANSI Color Codes ---</span><br>GREEN=<span class="hljs-string">&#x27;\033[0;32m&#x27;</span><br>YELLOW=<span class="hljs-string">&#x27;\033[1;33m&#x27;</span><br>CYAN=<span class="hljs-string">&#x27;\033[0;36m&#x27;</span><br>NC=<span class="hljs-string">&#x27;\033[0m&#x27;</span><br><br><span class="hljs-comment"># --- Argument Parsing ---</span><br><span class="hljs-keyword">while</span> [[ <span class="hljs-variable">$#</span> -gt 0 ]]; <span class="hljs-keyword">do</span><br>    key=<span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span><br>    <span class="hljs-keyword">case</span> <span class="hljs-variable">$key</span> <span class="hljs-keyword">in</span><br>        -s|--<span class="hljs-built_in">source</span>) SOURCE_DIR=<span class="hljs-string">&quot;<span class="hljs-variable">$2</span>&quot;</span>; <span class="hljs-built_in">shift</span>; <span class="hljs-built_in">shift</span> ;;<br>        -i|--image-prefix) IMAGE_PREFIX=<span class="hljs-string">&quot;<span class="hljs-variable">$2</span>&quot;</span>; <span class="hljs-built_in">shift</span>; <span class="hljs-built_in">shift</span> ;;<br>        *) <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Unknown option: <span class="hljs-variable">$1</span>&quot;</span>; <span class="hljs-built_in">exit</span> 1 ;;<br>    <span class="hljs-keyword">esac</span><br><span class="hljs-keyword">done</span><br><br><span class="hljs-comment"># --- Main Script Logic ---</span><br><br><span class="hljs-comment"># Step 1: Disguise the parameter and convert Markdown files</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;YELLOW&#125;</span>&gt;&gt;&gt; Step 1: Converting Markdown files...<span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CYAN&#125;</span>Source:           <span class="hljs-variable">$&#123;SOURCE_DIR&#125;</span><span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CYAN&#125;</span>Original Prefix:  <span class="hljs-variable">$&#123;IMAGE_PREFIX&#125;</span><span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br><br><span class="hljs-comment"># 将斜杠替换为不会触发路径扩展的字符，比如管道符 |</span><br><span class="hljs-comment"># 例如：&quot;/images/&quot; 变成 &quot;|images|&quot;</span><br>DISGUISED_PREFIX=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$IMAGE_PREFIX</span>&quot;</span> | sed <span class="hljs-string">&#x27;s#/#|#g&#x27;</span>)<br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CYAN&#125;</span>Disguised Prefix: <span class="hljs-variable">$&#123;DISGUISED_PREFIX&#125;</span><span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br><br><span class="hljs-keyword">if</span> [ ! -f <span class="hljs-string">&quot;<span class="hljs-variable">$PYTHON_SCRIPT</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;Error: Python script &#x27;<span class="hljs-variable">$PYTHON_SCRIPT</span>&#x27; not found.&quot;</span><br>    <span class="hljs-built_in">exit</span> 1<br><span class="hljs-keyword">fi</span><br><br><span class="hljs-comment"># 将伪装的前缀传递给 Python 脚本</span><br>python <span class="hljs-string">&quot;<span class="hljs-variable">$PYTHON_SCRIPT</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$SOURCE_DIR</span>&quot;</span> --image-prefix <span class="hljs-string">&quot;<span class="hljs-variable">$DISGUISED_PREFIX</span>&quot;</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;GREEN&#125;</span>--- Markdown conversion complete.<span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br><br><span class="hljs-comment"># Step 2: Clean old files</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\n<span class="hljs-variable">$&#123;YELLOW&#125;</span>&gt;&gt;&gt; Step 2: Cleaning old Hexo files...<span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br>hexo clean<br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;GREEN&#125;</span>--- Clean complete.<span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br><br><span class="hljs-comment"># Step 3: Generate new site</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\n<span class="hljs-variable">$&#123;YELLOW&#125;</span>&gt;&gt;&gt; Step 3: Generating new site files...<span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br>hexo g<br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;GREEN&#125;</span>--- Generation complete.<span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br><br><span class="hljs-comment"># Step 4: Deploy to GitHub</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\n<span class="hljs-variable">$&#123;YELLOW&#125;</span>&gt;&gt;&gt; Step 4: Deploying to GitHub Pages...<span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br>hexo d<br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;GREEN&#125;</span>--- Deployment complete.<span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\n<span class="hljs-variable">$&#123;GREEN&#125;</span>✅ All steps completed successfully! Your blog has been published.<span class="hljs-variable">$&#123;NC&#125;</span>&quot;</span><br></code></pre></td></tr></table></figure><p><strong>在 Windows 上使用 PowerShell</strong>： <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 在 PowerShell 中运行</span><br>.\publish.sh<br></code></pre></td></tr></table></figure></p><p><strong>或者直接在 PowerShell 中运行</strong>： <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 直接在 PowerShell 中运行完整的发布流程</span><br>python convert_obsidian_to_hexo.py source/_posts/ <span class="hljs-literal">--image-prefix</span> <span class="hljs-string">&quot;|images|&quot;</span><br>hexo clean<br>hexo g<br>hexo d<br></code></pre></td></tr></table></figure></p><h3 id="你的终极工作流">你的终极工作流</h3><p>现在，从写作到发布的完整流程被简化为了三个简单步骤：</p><ol type="1"><li><strong>写作</strong>：在 Obsidian 中自由地写作，使用你最喜欢的<code>![image.png](image.png)</code> 语法插入图片，用标准 LaTeX书写公式。</li><li><strong>同步</strong>：将写好的 <code>.md</code>文件和相关图片分别放入你 Hexo 项目的 <code>source/_posts/</code> 和<code>source/images/</code> 目录。</li><li><strong>发布</strong>：在你的博客根目录下，打开 PowerShell终端，运行： <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">.\publish.sh<br></code></pre></td></tr></table></figure></li></ol><p>一切都将自动完成。如果你有特殊需求，比如处理草稿箱或使用不同的图片目录，还可以使用参数：<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">.\publish.sh <span class="hljs-literal">-s</span> source/_drafts/ <span class="hljs-literal">-i</span> /assets/<br></code></pre></td></tr></table></figure></p><h3 id="结语">结语</h3><p>通过结合 Hexo 的正确配置、一个智能的 Python 转换脚本和一个自动化的Shell 发布脚本，我们最终打通了 Obsidian 和 Hexo之间的“任督二脉”。这套工作流将所有复杂性都封装在了工具背后，让我们可以重新专注于最重要的事——思考与创作。</p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1"class="footnote-text"><span><a href="https://zhuanlan.zhihu.com/p/392994381"class="uri">https://zhuanlan.zhihu.com/p/392994381</a>冲突。<a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:1"class="footnote-text"><span>https://zhuanlan.zhihu.com/p/392994381<a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Obsidian</tag>
      
      <tag>MathJax</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Learning Lecture-3</title>
    <link href="/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-3/"/>
    <url>/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-3/</url>
    
    <content type="html"><![CDATA[<h2 id="convolutional-neural-networks">Convolutional NeuralNetworks</h2><p>卷积网络最早是用来处理图像的问题。目前较为成功的研究是物体识别问题，对于物体之间的关系推断依然是计算机视觉的前沿领域。</p><p>在生物的研究中，存在<strong>感受野</strong><em>receptivefield</em>的概念，这是指神经元对于输入的局部区域的敏感程度。在卷积网络中，我们也引入了这个概念。相邻的神经元处理的是相邻的图像区域，这样的设计使得网络能够捕捉到图像的空间结构。在模拟人类的视觉系统中，重要的是<strong>提取不同程度的特征</strong>，这就是卷积网络的核心思想。</p><p>在MLP中，由于对于原图像像素进行展开，会损失部分的空间信息。在处理视角、光照的变化时，MLP的效果会变差。</p><figure><img src="%7B71895E3A-0EFA-438D-8E6C-EDBD4A337F5A%7D.png"alt="{71895E3A-0EFA-438D-8E6C-EDBD4A337F5A}" /><figcaptionaria-hidden="true">{71895E3A-0EFA-438D-8E6C-EDBD4A337F5A}</figcaption></figure><p>从左到右，逐步提取的是从较低到较高的层次特征。在不同的任务中使用不同的特征。在识别人物中，应该使用较高层次的特征。</p><h5 id="local-connectivity">Local Connectivity</h5><p>每一层的神经元只连接到上一层的局部区域。具体的连接方式为：每一个神经元只关注上一层对应区域的部分神经元。</p><h5 id="parameter-sharing">Parameter Sharing</h5><p>一个神经元对应的某组参数代表的是某种特征，我们认为提取的特征的在不同的位置是一样的。是一种<strong>平移不变性</strong>。</p><h4 id="convolution">Convolution</h4><p><span class="math inline"><em>f</em></span>是输入的图像，<spanclass="math inline"><em>g</em></span>是卷积核，卷积操作定义为：<em>Continuous function</em> : <spanclass="math display">(<em>f</em>*<em>g</em>)(<em>t</em>) = ∫<sub>−∞</sub><sup>∞</sup><em>f</em>(<em>τ</em>)<em>g</em>(<em>t</em>−<em>τ</em>)<em>d</em><em>τ</em></span><em>Discrete function</em> : <span class="math display">$$(f*g)[n] = \sum_{m=-\infty}^{\infty} f[m]g[n-m]$$</span> 上述操作的目的为对于输入函数</p><h5 id="cross-correlation">Cross Correlation</h5><p>互相关用来分析两个信号的相似性，定义为： <em>Continous function</em>: <span class="math display">$$(f\star g)(t) = \int_{-\infty}^{\infty} \overline{f(\tau)}g(t+\tau)d\tau$$</span> <em>Discrete function</em> : <span class="math display">$$(f\star g)[n] = \sum_{m=-\infty}^{\infty} \overline {f[m]}g[n+m]$$</span> 对于卷积和互相关的关系为： <span class="math display">$$[f(t) \star g(t)] (t) = [\overline{f(-t)} * g(t)](t)$$</span> 事实上，在卷积网络中使用的是互相关操作。</p><h5 id="notation">Notation</h5><ul><li>输入的图片一般为三层，分别为RGB。这个<em>Volume</em>是一个张量<em>Tensor</em>。</li><li>卷积核的大小为<spanclass="math inline">5 × 5 × 3</span>（举例），即3个通道，每个通道大小为<spanclass="math inline">5 × 5</span>。然后在整个图片上进行平移，计算卷积操作。（类似于卷积的定义）</li><li>卷积的计算操作为：卷积核在图片上平移，计算对应位置的乘积和。 <imgsrc="%7B7AC9125F-FA2D-42F9-B0CF-085ABFFB668F%7D.png"alt="{7AC9125F-FA2D-42F9-B0CF-085ABFFB668F}" />上面的公式是在移动到某个位置<spanclass="math inline">(<em>w</em>,<em>h</em>)</span>的时候，计算对应位置的乘积和。然后将结果存储在一个新的矩阵中。</li></ul><p><em>在实际操作的过程中，并不要将卷积核在图片上“滑动”（这是一个串行算法），可以为每一个为每一个局域来分配一个神经元，这样的操作是并行的，可以加速计算。</em></p><p>得到的是一个Feature Map，这个FeatureMap是一个新的张量，使用6个卷积核得到的图片的特征图的大小为<spanclass="math inline">28 × 28 × 6</span>。<em>如何计算的？参数量是多少？</em>使用的卷积核数量是一个超参数，可以调整。</p><p>对于一个<spanclass="math inline"><em>w</em> * <em>h</em> * <em>c</em></span>的输入，使用<spanclass="math inline"><em>k</em> * <em>k</em> * <em>c</em> * <em>d</em></span>个卷积核，得到的输出的特征图的大小为<spanclass="math inline">(<em>w</em>−<em>k</em>+1) * (<em>h</em>−<em>k</em>+1) * <em>d</em></span>，参数量为<spanclass="math inline">(<em>k</em>*<em>k</em>*<em>c</em>+1) * <em>d</em></span>。但是CNN在实践过程中的显存占用是较大的，因为需要存储特征图。</p><p><img src="%7B7202EECA-CD25-4EE1-A5C9-02F0263C968C%7D.png"alt="{7202EECA-CD25-4EE1-A5C9-02F0263C968C}" /> #### Dilated&amp; StrideConvolution</p><p>在卷积操作中，我们可以使用不同的步长来进行卷积操作，这样的操作会改变输出的大小。在DilatedConvolution中，我们可以使用不同的扩张率来进行卷积操作。扩张率为1的时候<em>1-dilated</em>是正常的卷积操作，扩张率为2的时候，卷积核的间隔为2<em>2-dilated</em>。这样的操作可以<strong>增加卷积核的感受野</strong>，但是减少了输出的大小。</p><p><em>Stride</em>是卷积核的步长，可以让输出的特征图迅速变小。可能出现不匹配的情况，这样可以进行<em>Padding</em>是在边缘填充0，这样的操作可以保持输出的大小。</p><h5 id="activation-functions">Activation Functions</h5><p>在卷积网络中，激活函数可以使用ReLU函数，这样的操作可以避免梯度消失的问题。有时候使用的是LeakyReLU函数，这样的操作在某些模型中可以减少神经元死亡的问题。 <spanclass="math display">$$LeakyReLU(x) = \begin{cases} x &amp; x&gt;0 \\ 0.01x &amp; x \leq 0\end{cases}$$</span></p><figure><img src="%7BCFAAFBDA-A81C-4931-9C2C-CBD64F40E29C%7D.png"alt="{CFAAFBDA-A81C-4931-9C2C-CBD64F40E29C}" /><figcaptionaria-hidden="true">{CFAAFBDA-A81C-4931-9C2C-CBD64F40E29C}</figcaption></figure><h5 id="pooling">Pooling</h5><p>池化操作一般是用来减少空间尺寸，这样的操作可以减少参数量，减少过拟合的问题。</p><ul><li>Max Pooling：取局部区域的最大值</li><li>Average Pooling：取局部区域的平均值 <imgsrc="%7B01688551-C69C-4B62-8660-637A51409678%7D.png"alt="{01688551-C69C-4B62-8660-637A51409678}" /></li></ul><p><strong>Spatial PyramidPooling</strong>：对于不同的通道进行池化操作，这样的操作可以增加特征的多样性。这是用来减少多尺度问题的。在现实生活中，多尺度是一个基本的特征，例如在大气系统、气候系统中，有较大的气流和较小部分的湍流。</p><h3 id="back-propagation">Back Propagation</h3><p><ahref="https://www.youtube.com/watch?v=Ilg3gGewQ5U">Backpropagation,step-by-step | DL3</a></p><figure><img src="%7B1197B7EA-3F5B-40C9-8ADF-861B8AACBDC2%7D.png"alt="{1197B7EA-3F5B-40C9-8ADF-861B8AACBDC2}" /><figcaptionaria-hidden="true">{1197B7EA-3F5B-40C9-8ADF-861B8AACBDC2}</figcaption></figure><p>在卷积网络的前向传播中每一层的计算公式如下： <spanclass="math display"><em>z</em><sub><em>d</em></sub><sup>(<em>l</em>+1)</sup> = <em>a</em><sup>(<em>l</em>)</sup> ⋆ <em>θ</em><sub><em>d</em></sub><sup>(<em>l</em>)</sup> + <em>b</em><sub><em>d</em></sub><sup>(<em>l</em>)</sup></span></p><p>在一个具体的例子中，可以计算一个<spanclass="math inline">3 × 3 × 1</span>的图像在经过一个<spanclass="math inline">2 × 2 × 1</span>的卷积核得到的<spanclass="math inline">2 × 2 × 1</span>的特征图的计算过程。</p><ul><li>Consider single input channel <spanclass="math inline"><em>c</em> = 1</span> : <spanclass="math display">$$\left[\begin{array}{ll}z_{11}^{(l+1)} &amp; z_{12}^{(l+1)} \\z_{21}^{(l+1)} &amp; z_{22}^{(l+1)}\end{array}\right]=\left[\begin{array}{lll}a_{11}^{(l)} &amp; a_{12}^{(l)} &amp; a_{13}^{(l)} \\a_{21}^{(l)} &amp; a_{22}^{(l)} &amp; a_{23}^{(l)} \\a_{31}^{(l)} &amp; a_{32}^{(l)} &amp; a_{33}^{(l)}\end{array}\right] \star\left[\begin{array}{ll}\theta_{11}^{(l)} &amp; \theta_{12}^{(l)} \\\theta_{21}^{(l)} &amp; \theta_{22}^{(l)}\end{array}\right]$$</span></li><li>Expand above to be clearer: <span class="math display">$$\left\{\begin{array}{l}z_{11}^{(l+1)}=a_{11}^{(l)} \theta_{11}^{(l)}+a_{12}^{(l)}\theta_{12}^{(l)}+a_{21}^{(l)} \theta_{21}^{(l)}+a_{22}^{(l)}\theta_{22}^{(l)} \\z_{12}^{(l+1)}=a_{12}^{(l)} \theta_{11}^{(l)}+a_{13}^{(l)}\theta_{12}^{(l)}+a_{22}^{(l)} \theta_{21}^{(l)}+a_{23}^{(l)}\theta_{22}^{(l)} \\z_{21}^{(l+1)}=a_{21}^{(l)} \theta_{11}^{(l)}+a_{22}^{(l)}\theta_{12}^{(l)}+a_{31}^{(l)} \theta_{21}^{(l)}+a_{32}^{(l)}\theta_{22}^{(l)} \\z_{22}^{(l+1)}=a_{22}^{(l)} \theta_{11}^{(l)}+a_{23}^{(l)}\theta_{12}^{(l)}+a_{32}^{(l)} \theta_{21}^{(l)}+a_{33}^{(l)}\theta_{22}^{(l)}\end{array}\right.$$</span></li></ul>对于上述的例子计算残差网络的过程为： $$<p>$$</p><p>与全连接层的计算公式的不同在于，CNN是一个局部的计算过程，即每一个神经元的输出值并不会对后一层的所有神经元产生影响。</p><p>对于上述计算得到的残差，可以写成一个矩阵： <spanclass="math display">$$\delta^{(l)} = \left[\begin{array}{lll}\delta_{11}^{(l)} &amp; \cdots &amp; \delta_{1n}^{(l)} \\\vdots &amp; \ddots &amp; \vdots \\\delta_{m1}^{(l)} &amp; \cdots &amp; \delta_{mn}^{(l)}\end{array}\right]$$</span> 在上面的例子中，我们可以计算得到： <spanclass="math display">$$\left[\begin{array}{lll}\delta_{11}^{(l)} &amp; \delta_{12}^{(l)} &amp; \delta_{13}^{(l)} \\\delta_{21}^{(l)} &amp; \delta_{22}^{(l)} &amp; \delta_{23}^{(l)} \\\delta_{31}^{(l)} &amp; \delta_{32}^{(l)} &amp; \delta_{33}^{(l)}\end{array}\right]=\left[\begin{array}{cccc}0 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; \delta_{11}^{(l+1)} &amp; \delta_{12}^{(l+1)} &amp; 0 \\0 &amp; \delta_{21}^{(l+1)} &amp; \delta_{22}^{(l+1)} &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 0\end{array}\right] \star\left[\begin{array}{cc}\theta_{22}^{(l)} &amp; \theta_{21}^{(l)} \\\theta_{12}^{(l)} &amp; \theta_{11}^{(l)}\end{array}\right] \odot g^{\prime}\left(z^{(l)}\right)$$</span> 比较紧凑地写出： <spanclass="math display"><em>δ</em><sup>(<em>l</em>)</sup> = <em>δ</em><sup>(<em>l</em>+1)</sup> ⋆ <em>r</em><em>o</em><em>t</em>180(<em>θ</em><sup>(<em>l</em>)</sup>) ⊙ <em>g</em><sup>′</sup>(<em>z</em><sup>(<em>l</em>)</sup>)</span>其中<spanclass="math inline"><em>r</em><em>o</em><em>t</em>180</span>是对卷积核进行旋转180度的操作。<span class="math inline">⊙</span>对应的是两个矩阵的逐个元素乘</p><p>在有多张特征图的情况下（输出有<spanclass="math inline"><em>d</em></span>个通道），输入的图像有<spanclass="math inline"><em>c</em></span>通道，我们可以将上述的计算过程进行扩展，得到：<spanclass="math display"><em>δ</em><sup>(<em>l</em>)</sup> = ∑<sub><em>d</em></sub><em>δ</em><sub><em>d</em></sub><sup>(<em>l</em>+1)</sup> ⋆ <em>r</em><em>o</em><em>t</em>180(<em>θ</em><sup>(<em>l</em>)</sup>) ⊙ <em>g</em><sup>′</sup>(<em>z</em><sup>(<em>l</em>)</sup>)</span>在计算目标函数对于参数的导数的过程中，我们可以得到： <spanclass="math display">$$\frac{\partial J(\theta,b)}{\partial \theta_d^{(l)}} = \frac{\partialJ(\theta,b)}{\partial z_d^{(l+1)}} \frac{\partial z_d^{(l+1)}}{\partial\theta_d^{(l)}}= \delta_d^{(l+1)} \star a^{(l)}_d$$</span> 可以更加详细地计算： <span class="math display">$$\begin{aligned}\frac{\partial J(\theta,b)}{\partial \theta_{i,j,k,d}^{(l)}} &amp;=\sum_{m,n} \frac{\partial J(\theta,b)}{\partial z_{m,n}^{(l+1)}}\frac{\partial z_{m,n}^{(l+1)}}{\partial \theta_{i,j,k,d}^{(l)}} \\&amp;= \sum_{m,n} \delta_{m,n}^{(l+1)} a_{m+i-1,n+j-1,k}^{(l)} \\&amp;= \delta_d^{(l+1)} \star a^{(l)}_d\end{aligned}$$</span> 对于偏置项的计算过程为 <span class="math display">$$\frac{\partial J(\theta,b) }{\partial b_d^{(l)}} = \sum_{m,n}\frac{\partial J(\theta,b)}{\partial z_{m,n}^{(l+1)}} \frac{\partialz_{m,n}^{(l+1)}}{\partial b_d^{(l)}} = \sum_{m,n} \delta_{m,n}^{(l+1)}$$</span></p><p>从而可以使用<strong>动量的梯度</strong>下降的方法来进行参数的更新。</p><h3 id="invariance-and-equivariance">Invariance and Equivariance</h3><p>对于不同的任务，有时候需要不变性和等变性。在图像处理中，对于图像的旋转、平移、缩放等操作，神经网络的输出应该是不变的。在神经网络中，可以通过数据增强的方法来进行处理。对于等变性，可以通过卷积神经网络来进行处理。CNN在设计的过程中，引入池化层<em>pooling</em>希望获得不变性。但是并没有获得很好的效果。- <strong>Invariance</strong>：对于输入的变化，输出不变 <spanclass="math display"><em>f</em>(<em>T</em>(<em>X</em>)) = <em>f</em>(<em>x</em>)</span>- <strong>Equivariance</strong>：对于输入的变化，输出也会发生相应的变化<spanclass="math display"><em>f</em>(<em>T</em>(<em>X</em>)) = <em>T</em>(<em>f</em>(<em>x</em>))</span>在实践中，有时候会有噪声、形变、翻转、光照条件、视角变化、遮挡、尺度变化、类内类间差距、奇异等问题。</p><h4 id="data-augmentation">Data Augmentation</h4><p>在实践中，可以通过数据增强的方法来进行处理。对于图像的旋转、平移、缩放、翻转等操作，可以增加数据的多样性。在训练的过程中，可以使用不同的数据增强的方法来进行训练。用这样的方法期望获得一种不变性。</p><p>常用的方法有：裁剪、旋转、翻转、缩放、平移、仿射变换、弹性变换、颜色变换等。CNN识别主要使的是纹理的识别方法，希望将人类的对于形状识别的能力融入到CNN中。可以使用的数据集为<em>Augmentationby Stylization</em>，希望获得模型对于纹理的不变性。CNN对上下文是敏感的，对于经常出现在一起的事物，CNN可以很好地进行识别，但是对于不常见的事物，CNN的效果会变差。一种极端的方式是将不经常出现的东西组合在一起。目前的深度网络一定程度上利用了<em>spuriouscorrelation</em>，从而进行bench mark在数据集上过拟和。</p><h4 id="architecture-revolution">Architecture Revolution</h4><h5 id="maga-making-convolutional-networks-shift-invariant-again">MAGAMaking convolutional networks shift-invariant again</h5><p>在CNN中，在平移过程中，网络很难获得平移不变性。在采用模糊之后的<em>pooling</em>可以获得一定程度上的平移不变性。</p><h5 id="capsule-network">Capsule Network</h5><p>CNN的缺点还有：不能保持物体之间的相对关系。在分类任务中，一般情况下强调的是不变性，而在一些细粒度识别任务中，强调的是等变性。在CapsuleNetwork中，引入了胶囊的概念，这样的操作可以保持物体之间的相对关系。</p><h2 id="cnn-architectures">CNN Architectures</h2><h3 id="alexnet">AlexNet</h3><figure><img src="%7B382F2347-B42F-46CB-83DB-F25DDE49A91E%7D.png"alt="{382F2347-B42F-46CB-83DB-F25DDE49A91E}" /><figcaptionaria-hidden="true">{382F2347-B42F-46CB-83DB-F25DDE49A91E}</figcaption></figure><ul><li>一般会在输入层使用较大的卷积核，然后在后面的层使用较小的卷积核</li><li>通道数随着网络逐渐增加然后减少</li><li>第一次使用ReLU激活函数</li><li>使用了大量的数据增强<em>Data Augmentation</em></li><li>使用GPU进行训练</li><li>采用SGD with momentum 0.9进行训练</li><li>使用dropout 0.5，一般在MLP层都需要使用dropout</li><li>使用0.01的学习率，然后在训练的过程中逐渐减小学习率，当loss不再下降的时使用学习率的0.1倍#### ZFNet</li></ul><p>在输入层使用了更小的卷积核，一般不要使用小的卷积核（更大的stride）会导致信息的丢失。在中间层数使用了更多的通道数。</p><h3 id="vggnet">VGGNet</h3><p>用更小的卷积核来代替较大的卷积核，这样的操作可以减少参数量，增加网络的深度。在VGGNet中，使用了3个<spanclass="math inline">3 × 3</span>的卷积核来代替一个<spanclass="math inline">7 × 7</span>的卷积核。这样的操作可以增加网络的深度，减少参数量。<strong>一个较大的感受野可以通过多个较小的感受野来代替</strong>。但是现在又发现事实上没有这么好的效果，所以现在又开始使用较大的卷积核。</p><p>采用了预训练的方法。在训练的过程中，首先在较小的数据集上进行过拟和（在这个训练集上的损失函数接近0），然后在较大的数据集上进行训练。</p><p>在早期的网络中，池化层的使用是较多的，现在已经很少使用。 ### NINNetwork in Network</p><p>在使用全连接层时，会有较多的参数，基于这样的思路提出<spanclass="math inline">1 × 1</span>卷积这个操作。这样的操作只改变通道数，不改变空间尺寸，通常在不希望改变空间尺寸而增大通道数的时候可以使用。</p><p>在使用卷积增加步长、使用<em>pooling</em>层时候，会导致信息的丢失。在NIN中希望获得一个尺寸小但是通道数多的特征图。在NIN中使用了<spanclass="math inline">1 × 1</span>的卷积核来增加通道数，这样可以使用空间全局池化。例如一个<spanclass="math inline">256 × 6 × 6</span>的特征图，使用<spanclass="math inline">6 × 6</span>的全局池化，可以得到一个<spanclass="math inline">256 × 1 × 1</span>的特征图。</p><blockquote><p>[!NOTE] -传统CNN末尾通常使用全连接层（FC）进行分类，但全连接层参数量大，易过拟合。- 全局池化可直接将特征图转换为通道维度的向量（如<spanclass="math inline">1 × 1 × 1024</span> <spanclass="math inline">→</span>1024维向量），再接一个分类层，大幅减少参数。</p></blockquote><h4 id="googlenet">GoogLeNet</h4><p><img src="%7B43BF44F4-D211-4165-AE84-257E702582A0%7D.png"alt="{43BF44F4-D211-4165-AE84-257E702582A0}" />这是一个较为深的网络，删去了全连接层，参数量是较小的。 -引入Multi-passway，使用多路的卷积核来提取特征。采用了特征增广<em>FeatureAugmentation</em>的方法。 -在特征图通道数目不一样的情况下，使用padding的方法。</p><figure><img src="%7B6F8AFF72-4C3D-4FAD-8FC9-90F7FED6E8B2%7D.png"alt="{6F8AFF72-4C3D-4FAD-8FC9-90F7FED6E8B2}" /><figcaptionaria-hidden="true">{6F8AFF72-4C3D-4FAD-8FC9-90F7FED6E8B2}</figcaption></figure><figure><img src="%7B39D210C3-7C1B-4913-AC78-12E71A8FD13B%7D.png"alt="{39D210C3-7C1B-4913-AC78-12E71A8FD13B}" /><figcaptionaria-hidden="true">{39D210C3-7C1B-4913-AC78-12E71A8FD13B}</figcaption></figure><figure><img src="%7BE3B121C1-5782-4762-A983-042799DA4ED9%7D.png"alt="{E3B121C1-5782-4762-A983-042799DA4ED9}" /><figcaptionaria-hidden="true">{E3B121C1-5782-4762-A983-042799DA4ED9}</figcaption></figure><p>使用计算量越来越小的卷积核，使用计算量越来越小的卷积核，使用越来越多的层数，使用越来越多的通道数。</p><h4 id="highway-network">Highway Network</h4><p>在平坦的网络通路中，可能有信息通路瓶颈问题。在HighwayNetwork中，引入了门控机制，这样的操作可以使得信息的流动更加顺畅。 <spanclass="math display"><em>y</em> = <em>H</em>(<em>x</em>,<em>W</em><sub><em>H</em></sub>)<em>T</em>(<em>x</em>,<em>W</em><sub><em>T</em></sub>) + <em>x</em>(1−<em>T</em>(<em>x</em>,<em>W</em><sub><em>T</em></sub>))</span>其中<spanclass="math inline"><em>H</em>(<em>x</em>,<em>W</em><sub><em>H</em></sub>)</span>是一个MLP，<spanclass="math inline"><em>T</em>(<em>x</em>,<em>W</em><sub><em>T</em></sub>)</span>是一个门控函数，这样的操作可以使得信息的流动更加顺畅。</p><ul><li><p><span class="math inline"><em>x</em></span>: 输入向量。</p></li><li><p><spanclass="math inline"><em>H</em>(<em>x</em>,<em>W</em><sub><em>H</em></sub>)</span>:非线性变换（如全连接层或卷积层）。</p></li><li><p><spanclass="math inline"><em>T</em>(<em>x</em>,<em>W</em><sub><em>T</em></sub>)</span>:TransformGate（变换门），控制非线性变换的权重，通常用Sigmoid激活（输出值在0到1之间）。</p></li><li><p><spanclass="math inline"><em>C</em>(<em>x</em>,<em>W</em><sub><em>C</em></sub>)</span>:Carry Gate（携带门），控制原始输入 x 的权重。通常设定为 <spanclass="math inline"><em>C</em> = 1 − <em>T</em></span>，以减少参数量。</p></li><li><p>当 <spanclass="math inline"><em>T</em>(<em>x</em>) → 0</span> 时，输出<spanclass="math inline"><em>y</em> ≈ <em>x</em></span>，即当前层几乎不进行变换（信息直接跳过该层）。</p></li><li><p>当 <span class="math inline"><em>T</em>(<em>x</em>) → 1</span>时，输出<spanclass="math inline"><em>y</em> ≈ <em>H</em>(<em>x</em>)</span>，即信息完全经过当前层的非线性变换。</p></li><li><p>通过这种方式，网络可以自适应地选择浅层或深层的特征。</p></li></ul><p><spanclass="math display"><em>T</em>(<em>x</em>,<em>W</em><sub><em>T</em></sub>) = <em>σ</em>(<em>W</em><sub><em>T</em></sub><sup><em>T</em></sup><em>x</em>+<em>b</em><sub><em>T</em></sub>)</span>动机是在网络中<strong>提高信息的流动性</strong></p><ul><li><strong>ResNet</strong>：使用恒等跳跃连接<em>Identity SkipConnection</em>，公式为 <spanclass="math inline"><em>y</em> = <em>H</em>(<em>x</em>) + <em>x</em></span>，无门控机制。</li><li><strong>HighwayNetwork</strong>：通过门控动态调节跳跃连接的权重，更灵活地控制信息流。#### ResNet</li></ul><figure><img src="%7B6767A6D4-59B6-4B62-9FE9-427D009BB837%7D.png"alt="{6767A6D4-59B6-4B62-9FE9-427D009BB837}" /><figcaptionaria-hidden="true">{6767A6D4-59B6-4B62-9FE9-427D009BB837}</figcaption></figure><ul><li>56层的模型比20层的模型效果更差，既然如此，先将20层的模型训练好，然后再增加36层的<em>identity</em>网络，之后再训练整个网络。发现这样的操作的效果反而更差。得出的结论是56层的网络更加难以训练，网络的拟和能力不足。<strong>平坦的网络很难拟和</strong></li><li>残差是更加容易拟和的。</li><li>继续将这些残差网络堆叠在一起，可以得到一个更深的网络。</li><li>卷积、池化是算子<em>operator</em>，残差是一个块<em>block</em>，网络是一个层<em>layer</em></li></ul><figure><img src="%7B8F67BE27-E8CA-4921-99B2-C57FFFAE5E7B%7D.png"alt="{8F67BE27-E8CA-4921-99B2-C57FFFAE5E7B}" /><figcaptionaria-hidden="true">{8F67BE27-E8CA-4921-99B2-C57FFFAE5E7B}</figcaption></figure><figure><img src="%7B681C5361-F2ED-427F-86C2-48C9EC68AADF%7D.png"alt="{681C5361-F2ED-427F-86C2-48C9EC68AADF}" /><figcaptionaria-hidden="true">{681C5361-F2ED-427F-86C2-48C9EC68AADF}</figcaption></figure><p><img src="%7B5DE8620F-D5FB-4E82-96D7-0E03CCCCAF82%7D.png"alt="{5DE8620F-D5FB-4E82-96D7-0E03CCCCAF82}" />对于网络会有多个维度进行评价： - 准确率top-1、top-5准确率 -VGG网络参数量很大，但是由于是平坦的网络，所以有一定的计算整齐度。在网络有较多的分叉时，计算整齐度会变差。较为整齐的网络计算是较快的。- 目前的显卡对于<spanclass="math inline">3 × 3</span>的卷积核是有硬件加速的</p><h3 id="landscape-visualization">LandScape Visualization</h3><p><a href="https://arxiv.org/abs/1712.09913">[1712.09913] Visualizingthe Loss Landscape of Neural Nets</a></p><h2 id="lightweight-for-deployment">Lightweight for Deployment</h2><h3 id="pruning">Pruning</h3><p>卷积神经网络是一个很适合做剪枝的网络。说明神经网络的有很多的参数是冗余的。剪枝配合上重训练可以减少网络的参数量，并且在一定的程度上提升网络的性能。</p><h4 id="quantization-and-encoding">Quantization and Encoding</h4><p>k-means算法可以将权重量化，将权重量化为几个值，这样的操作可以减少网络的参数量。在实际的操作中，可以将权重量化为8位，这样的操作可以减少网络的参数量。</p><p>编码操作，如Huffman编码，可以减少网络的参数量。 <ahref="https://arxiv.org/abs/1510.00149">[1510.00149] Deep Compression:Compressing Deep Neural Networks with Pruning, Trained Quantization andHuffman Coding</a></p><p>神经网络一般是在训练的时候使用较大的网络，然后再裁剪为较小的网络，反之效果不一定会好。</p><p>我们相信在裁剪的过程中，保留下来的参数是重要的参数，这样的操作可以提升网络的性能。在实验中</p><p><a href="https://arxiv.org/abs/1803.03635">[1803.03635] The LotteryTicket Hypothesis: Finding Sparse, Trainable Neural Networks</a></p><p>先设计一个较小的网络，之后推广到较大的网络。在实际的操作中，可以使用较小的网络，然后再增加网络的深度。这种设计是硬件友好的，由于这样的设计是计算对齐的。</p><h4 id="group-convolution">Group Convolution</h4><p>标准的卷积层有这样的不足：对于不同的输入通道，后面的输出都使用到了所有的输入通道。在GroupConvolution中，将输入通道分为几个组，然后对于每一个组使用一个卷积核。这样的操作可以减少网络的参数量，减少计算量。</p><p>但是通道之间不交流，这样的操作可能会导致网络的性能下降。</p><h4 id="depthwise-separable-convolution">Depthwise SeparableConvolution</h4><ul><li>引入了<spanclass="math inline">1 × 1</span>卷积核<em>pointwise</em>，这样的操作可以减少参数量</li><li>令通道数等于分组数目<em>channelwise</em> or <em>depthwise</em></li></ul><p>上述两个算子是轻量化网络的基础。</p><figure><img src="Pasted%20image%2020250316132626.png"alt="Pasted image 20250316132626" /><figcaption aria-hidden="true">Pasted image 20250316132626</figcaption></figure><p><a href="https://arxiv.org/abs/2201.03545">[2201.03545] A ConvNet forthe 2020s</a></p><figure><img src="Pasted%20image%2020250316134751.png"alt="Pasted image 20250316134751" /><figcaption aria-hidden="true">Pasted image 20250316134751</figcaption></figure><p>宏观设计：<strong>减少空间尺寸的衰减有利于学习不同的特征</strong>。</p><h2 id="advanced-modules">Advanced Modules</h2><h3 id="d-modeling">3D Modeling</h3><p>普通的二维卷积网络在处理视频时，会丢失时间信息。在3D卷积网络中，引入了时间维度，这样的操作可以保留时间信息。</p><p>直接使用3D卷积可以进行直接的对应。</p><h4 id="deforamble-convolution">Deforamble Convolution</h4><p>在CNN中，形变较难进行建模，对于形变的物体效果会变差。在识别的过程中，在识别的过程中可能引入噪音。在SpatialTransformerNetwork中，引入了形变的概念，类似于视觉中进行防抖的操作。</p><p>在CNN中引入偏置的概念，在对应的特征图上进行坐标的偏置操作 <spanclass="math display"><em>y</em>(<em>p</em><sub>0</sub>) = ∑<sub><em>p</em><sub><em>i</em></sub> ∈ <em>Ω</em></sub><em>w</em><sub><em>i</em></sub><em>x</em>(<em>p</em><sub><em>i</em></sub>+<em>p</em><sub>0</sub>+<em>Δ</em><em>p</em><sub>0</sub>)</span>#### Attention</p><p>要建模大范围的特征范围，就是high-level的特征，但是在使用CNN的过程中，有效感受野并没有那么大。</p><p><span class="math display">$$y_i = \frac{1}{\mathcal{C}(x)}\sum_{\forall j} f(x_i,x_j)g(x_j)$$</span> 对于注意力函数<spanclass="math inline"><em>f</em>(<em>x</em><sub><em>i</em></sub>,<em>x</em><sub><em>j</em></sub>)</span>可以计算为两个参数的内积。上述操作实际上是一种全局建模，可以在CNN的最后几步使用。</p><h4 id="cam">CAM</h4><p>作为一种可解释性的工作，CAM可以将CNN的输出映射到输入图像上，这样的操作可以直观地看到CNN的输出。计算不同部分的权重，可以得到不同部分的重要性。</p>]]></content>
    
    
    
    <tags>
      
      <tag>DeepLearning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Learning Lecture-4</title>
    <link href="/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-4/"/>
    <url>/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-4/</url>
    
    <content type="html"><![CDATA[<h2 id="optimization">Optimization</h2><p><strong>Objective Function</strong> <span class="math display">$$\arg \min \mathcal{O(D,\theta)}=  \sum_{i=1}^{N} L(y_i, f(x_i,\theta)) +\Omega(\theta)$$</span> 上述目标可以可视化为以<spanclass="math inline"><em>θ</em></span>为横坐标、<spanclass="math inline">𝒪</span>为纵坐标的函数图像，我们的目标是找到函数图像的最低点。这是一个<strong>非凸优化</strong>问题，是初值敏感的。“地形图”是否简单是网络训练是否容易的关键。</p><h3 id="first-order-optimization">First-Order Optimization</h3><p>可以将<spanclass="math inline"><em>J</em>(<em>θ</em>)</span>展开为泰勒级数： <spanclass="math display">$$J(\theta) = J(\theta_0) + \nabla J(\theta_0)^T(\theta - \theta_0) +\frac{1}{2}(\theta - \theta_0)^T H(\theta - \theta_0)$$</span> 沿着梯度的方向进行更新： <spanclass="math display"><em>J</em>(<em>θ</em>−<em>η</em><em>g</em>) = <em>J</em>(<em>θ</em>) − <em>η</em><em>g</em><sup><em>T</em></sup><em>g</em> ≤ <em>J</em>(<em>θ</em>)</span></p><p><strong>梯度下降算法的问题在于</strong>： - 容易在鞍点处停滞 -对于较为简单的凸优化问题，学习率的选择不好都会有发散的问题，训练对于学习率是很敏感的</p><p>对于学习率下降的算法，主流使用的是<em>StepStrategy</em>，即损失函数不下降了就减少学习率。</p><h4 id="warm-restarts">Warm Restarts</h4><p>使用的策略为：<em>Cosine Annealing</em>: <spanclass="math display">$$\eta_t = \eta_{min}^i + \frac{1}{2}(\eta_{max}^i - \eta_{min}^i)(1 +\cos(\frac{T_{cur}}{T_{i}}\pi))$$</span></p><p>其中<spanclass="math inline"><em>T</em><sub><em>c</em><em>u</em><em>r</em></sub></span>为当前的迭代次数，<spanclass="math inline"><em>T</em><sub><em>i</em></sub></span>为当前的周期数，<spanclass="math inline"><em>η</em><sub><em>m</em><em>i</em><em>n</em></sub><sup><em>i</em></sup></span>和<spanclass="math inline"><em>η</em><sub><em>m</em><em>a</em><em>x</em></sub><sup><em>i</em></sup></span>分别为第<spanclass="math inline"><em>i</em></span>个周期的最小和最大学习率。学习率的衰减不能是线性的，是先快后慢的。</p><h4 id="convergence-rate">Convergence Rate</h4><ul><li>We assume that <spanclass="math inline"><em>J</em>(<em>θ</em>)</span> is convex,differentiable and Lipchitz by constant <spanclass="math inline"><em>L</em></span>. And domain of <spanclass="math inline"><em>θ</em></span> is bounded by radius <spanclass="math inline"><em>R</em></span>. With gradient descent update:<spanclass="math display"><em>θ</em><sup><em>t</em> + 1</sup> = <em>θ</em><sup><em>t</em></sup> − <em>η</em>∇<em>J</em>(<em>θ</em><sup><em>t</em></sup>)</span></li></ul>$$<p>$$</p><ul><li>From previous computation, we get the following inequality for everystep <span class="math inline"><em>t</em></span> :</li></ul><p><span class="math display">$$J\left(\theta^t\right)-J\left(\theta^*\right) \leq \frac{1}{2\eta}\left(\left\|\theta^t-\theta^*\right\|^2-\left\|\theta^{t+1}-\theta^*\right\|^2\right)+\frac{\eta}{2}L^2$$</span></p><ul><li>Recall <spanclass="math inline">max<sub><em>θ</em>, <em>θ</em><sup>′</sup></sub>(∥<em>θ</em>−<em>θ</em><sup>′</sup>∥) ≤ <em>R</em></span>.Assume we update parameters for <spanclass="math inline"><em>T</em></span> steps. We add all equations forall <spanclass="math inline"><em>t</em> ∈ {0, 1, …, <em>T</em> − 1}</span> :</li></ul><p><span class="math display">$$\begin{aligned}&amp; \sum_t\left(J\left(\theta^t\right)-J\left(\theta^*\right)\right)\leq \frac{1}{2\eta}\left(\left\|\theta^0-\theta_*^*\right\|^2-\left\|\theta^T-\theta^*\right\|^2\right)+\frac{\etaL^2 T}{2} \\&amp; \frac{1}{T} \sum_t J\left(\theta^t\right)-J\left(\theta^*\right)\leq \frac{1}{2 \eta T}\left(R^2+0\right)+\frac{\eta L^2}{2} \\&amp; \frac{1}{T} \sum_t J\left(\theta^t\right)-J\left(\theta^*\right)\leq \frac{R^2}{2 \eta T}+\frac{\eta L^2}{2}\end{aligned}$$</span></p><ul><li>let <span class="math inline">$\eta = \frac{R}{L\sqrt{T}}$</span>:<span class="math display">$$\frac{1}{T} \sum_t J\left(\theta^t\right)-J\left(\theta^*\right) \leq\frac{L}{R} \sqrt{T}$$</span></li></ul><h3 id="second-order-optimization">Second-Order Optimization</h3><p>不仅要关注一次的梯度信息，还要关注二次的信息。二阶优化算法的核心是Hessian矩阵，可以分辨是不是鞍点。函数的展开为： <span class="math display">$$J(\theta) = J(\theta_0) + \nabla J(\theta_0)^T(\theta - \theta_0) +\frac{1}{2}(\theta - \theta_0)^T H(\theta - \theta_0)$$</span> 能感知到“地形图”中的曲率。 对于海森矩阵可以进行特征值分解：<spanclass="math display"><em>H</em> = <em>Q</em><em>Λ</em><em>Q</em><sup><em>T</em></sup>  and  <em>H</em><sup>−1</sup> = <em>Q</em><em>Λ</em><sup>−1</sup><em>Q</em><sup><em>T</em></sup></span>特征值中较大和较小的特征值如果相差较大，称为病态矩阵；如果从最大到最小的变化较为平缓，则较为光滑。如果特征值全为正值，那么就是凸函数；如果有正有负，那么就是鞍点。事实上，使用的梯度方法为局部的方法，下降是相对较慢的。 #### Newton’sMethod 牛顿法的计算方法为： <span class="math display">$$\hat{J}(\theta) = J(\theta_0) + \nabla J(\theta_0)^T(\theta - \theta_0)+ \frac{1}{2}(\theta - \theta_0)^T H(\theta - \theta_0)$$</span> 求导得到： <spanclass="math display">∇<sub><em>θ</em></sub><em>Ĵ</em>(<em>θ</em>) = ∇<sub><em>θ</em></sub><em>J</em>(<em>θ</em><sub>0</sub>) + <em>H</em>(<em>θ</em>−<em>θ</em><sub>0</sub>) = 0</span>求解得到： <spanclass="math display"><em>θ</em><sup><em>t</em> + 1</sup> = <em>θ</em><sup><em>t</em></sup> − <em>H</em><sup>−1</sup>∇<sub><em>t</em><em>h</em><em>e</em><em>t</em><em>a</em></sub><em>J</em>(<em>θ</em><sup><em>t</em></sup>)</span>牛顿法的优点在于收敛速度快，但是缺点在于计算复杂度高，需要计算海森矩阵的逆矩阵。计算复杂度为<spanclass="math inline"><em>O</em>(<em>d</em><sup>3</sup>)</span>，其中<spanclass="math inline"><em>d</em></span>为参数的个数。<strong>在深度学习时代基本上不再使用</strong>。</p><h4 id="quasi-newton-method">Quasi-Newton Method</h4><p>对于海森矩阵的逆矩阵，我们可以使用拟牛顿法进行近似： <spanclass="math display">$$H_{t+1}^{-1} = H_t^{-1} + \frac{y_t y_t^T}{y_t^T s_t} -\frac{H_t^{-1}s_t s_t^T H_t^{-1}}{s_t^T H_t^{-1}s_t}$$</span> 其中<spanclass="math inline"><em>y</em><sub><em>t</em></sub> = ∇<em>J</em>(<em>θ</em><sub><em>t</em> + 1</sub>) − ∇<em>J</em>(<em>θ</em><sub><em>t</em></sub>)</span>，<spanclass="math inline"><em>s</em><sub><em>t</em></sub> = <em>θ</em><sub><em>t</em> + 1</sub> − <em>θ</em><sub><em>t</em></sub></span>。<strong>在矩阵计算的时候要将较小的矩阵先乘，这样可以计算复杂度</strong></p><h2 id="optimization-in-deep-learning">Optimization in DeepLearning</h2><p>[[Deep Learning Lecture-2#Optimization in Practice]]</p><p>是非凸优化问题，优化的目的在于找到一个较好的局部极值。比较好的局部极值是比较低的、比较平缓的局部极值，对于比较陡峭的局部极值泛化能力比较差（对测试数据的微小变化敏感）。</p><p>好的局部极值有一些特性： - 值比较低 -是”盆地“，这样有利于模型的泛化</p><h3 id="mini-batch">mini-batch</h3><p><strong>mini-batchSGD</strong>：在每一轮遍历<em>epoch</em>后，对数据进行随机的打乱<em>Shuffle</em>，然后分成若干个batch，对每一个batch进行参数的更新。这样可以减少计算的时间，同时可以减少过拟合的问题。</p><ul><li>mini-batch的大小对于训练的影响，一般而言较大的mini-batch会有更好的收敛性，但是计算复杂度更高。</li><li>由于不一样的小样本选择会引入一定的随机性，这样是有利于跳出局部极值的。</li><li>由于mini-batch的选择是有随机性的，不同的batch的难度不一样，所以这时候出现Loss的规律性的震荡是很正常的。</li><li>矩阵最大奇异值与最小奇异值的比值称为矩阵的条件数，条件数越大，矩阵越病态。对于病态矩阵，SGD的收敛速度会变慢。</li></ul><h3 id="learning-rate-decay">Learning Rate Decay</h3><p>初始学习率较大，随着迭代次数的增加，学习率逐渐减小。有相对应的衰减策略。<em>Exponential decay</em>: <spanclass="math display"><em>η</em><sub><em>t</em></sub> = <em>η</em><sub>0</sub> ⋅ <em>e</em><sup>−<em>α</em><em>t</em></sup></span><em>Inverse decay</em>: <span class="math display">$$\eta_t = \frac{\eta_0}{1+\alpha t}$$</span> ### SGD Stochastic Gradient Descent #### SGD with Momentum</p><p><strong>SGD with Momentum</strong>:</p><p>对于下面的更新公式：</p><p><spanclass="math display"><em>θ</em><sub><em>i</em><em>j</em></sub> = <em>θ</em><sub><em>i</em><em>j</em></sub> − <em>η</em><em>Δ</em></span>在高维中，地形是相对而言较为崎岖的，这里的学习率一般是比较小的，否则容易发散。在接近于局部极值的时候。较大的学习率学习的是较为粗糙的特征，较小的学习率学习的是较为细致的特征。</p><p><span class="math display">$$\Delta = \beta \Delta - \eta \frac{\partial J(\theta)}{\partial\theta_{ij}}$$</span> <spanclass="math inline"><em>β</em></span>是动量参数，可以理解为之前的梯度的累积。</p><p><strong>Nesterov Momentum:</strong> <span class="math display">$$\begin{aligned}&amp;\tilde{\theta}^{t} = \theta^{t} - \beta \Delta^{t-1} \\&amp;\Delta^{t} = \beta \Delta^{t-1} + (1-\beta)\nabla J^t(\tilde{\theta}^t)\\&amp;\theta^{t+1} = \theta^t - \eta \Delta^t\\\end{aligned}$$</span>在深度学习的实现中使用的一般是这种。走动量的方向可以减少震荡，同时可以加速收敛。当到达了比较好的局部极值时候又会在这个值的附近抖动。超参数：<span class="math inline"><em>β</em></span>，一般而言<spanclass="math inline"><em>β</em></span>取0.9是比较好的，越大的值越容易进行震荡。学习率0.01、0.003、0.001一般按照指数变化。</p><p>是在每次更新完<spanclass="math inline"><em>θ</em></span>之后（进行试探之后才进行计算）才进行梯度的计算，可以避免一些<em>overshoot</em>。核心的思想为多获取一些二次的信息。</p><h3 id="weight-decay"><em>Weight Decay</em></h3><p>加入正则项，对于参数的更新进行限制，控制假设空间的大小，可以防止过拟合。但是在深度学习中并不够。</p><p><em>L1 regularization</em> <span class="math display">$$\Omega(\theta) = \lambda \sum_{l=1}^{L} \sum_{i=1}^{n_l}\sum_{j=1}^{n_{l+1}} |\theta_{ij}^{(l)}|$$</span> <em>L2 regularization</em> <span class="math display">$$\Omega(\theta) = \lambda \sum_{l=1}^{L} \sum_{i=1}^{n_l}\sum_{j=1}^{n_{l+1}} (\theta_{ij}^{(l)})^2$$</span></p><h3 id="adaptive-learning-rate">Adaptive Learning Rate</h3><p>直观理解为在不同的“地形”上需要使用的学习率（步长）是不一样的。对于不同的参数使用不同的学习率。<strong>Adagrad</strong>算法的核心思想为：<span class="math display">$$\begin{aligned}&amp;r^t = r^{t-1} + \nabla J^t(\theta^t) \odot \nabla J^t(\theta^t)\\&amp;h^t = \frac{1}{\sqrt{r^t} + \delta} \\&amp;\Delta^t = h^t \odot \nabla J^t(\theta^t)\\&amp;\theta^{t+1} = \theta^t - \eta \Delta^t\end{aligned}$$</span> <em>上述公式中的第二行为逐元素操作</em> 其中<spanclass="math inline">⊙</span>为对应元素相乘，<spanclass="math inline"><em>δ</em></span>为一个很小的数，防止分母为0。这样可以保证在不同的地形上使用不同的学习率。<strong>本质上为探索”地形图”</strong>。但是Adagrad的问题在于随着迭代次数的增加，分母会变得越来越大，导致学习率会变得越来越小，最终会导致学习率为0，这样就不再更新了。</p><p><strong>RMSprop</strong>算法的核心思想为：对Adagrad的分母进行指数滑动平均：<span class="math display">$$\begin{aligned}&amp;r^t = \rho r^{t-1} + (1-\rho)\nabla J^t(\theta^t) \odot \nablaJ^t(\theta^t)\\&amp;h^t = \frac{1}{\sqrt{r^t} + \delta} \\&amp;\Delta^t = h^t \odot \nabla J^t(\theta^t)\\&amp;\theta^{t+1} = \theta^t - \eta \Delta^t\end{aligned}$$</span></p><p><strong>Adam</strong>算法的核心思想为：结合了SGD withMomentum和RMSprop： <span class="math display">$$\begin{aligned}&amp; r^t = \rho r^{t-1} + (1-\rho)\nabla J^t(\theta^t) \odot \nablaJ^t(\theta^t)\\&amp; h^t = \frac{1}{\sqrt{r^t} + \delta} \\&amp; s^t = \varepsilon s^{t-1} + (1-\epsilon)\nabla J^t(\theta^t)\\&amp; \Delta^t = h^t \odot s^t \\&amp; \theta^{t+1} = \theta^t - \eta \Delta^t\end{aligned}$$</span> 实际使用的参数为<spanclass="math inline"><em>ρ</em> = 0.9</span>，<spanclass="math inline"><em>ε</em> = 0.9</span>，<spanclass="math inline"><em>ρ</em> = 0.999</span>对于学习率的下降，还是要使用对应的算法，对于实际使用的算法，还需要对<spanclass="math inline"><em>r</em></span>、<spanclass="math inline"><em>s</em></span>进行无偏修正。</p><p>Nadam算法为Adam算法的变种，对于SGD withMomentum的更新进行了修正。</p><p>调参一般而言是，对于一个模型找到对于其最好的优化器。</p>]]></content>
    
    
    
    <tags>
      
      <tag>DeepLearning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Learning Lecture-5</title>
    <link href="/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-5/"/>
    <url>/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-5/</url>
    
    <content type="html"><![CDATA[<h2 id="recurrent-network">Recurrent Network</h2><h3 id="sequence-model">Sequence Model</h3><p>序列建模任务是指对一个序列的输入进行建模，比如文本、音频、视频等。序列模型的输入和输出都是序列，比如机器翻译、语音识别、视频分类等任务。重要的是<strong>捕捉序列中的上下文</strong>。</p><h3 id="basic-principle">Basic Principle</h3><h4 id="local-dependency">Local Dependency</h4><p><strong>LocalDependency</strong>：对于一个序列中的每一个元素，它的预测是依赖于它的前面的元素的。这种依赖关系是<strong>局部的</strong>。</p><p><span class="math display">$$P(x_1,x_2,\dots,x_T) = \prod_{t=1}^{T} P(x_t|x_1,\dots,x_{t-1}) =\prod_{t=1}^{T} g(s_{t-2},x_{t-1})$$</span></p><p>如果引入马尔科夫性，那么损失的信息太多了。因此我们引入一个隐藏状态<spanclass="math inline"><em>s</em><sub><em>t</em></sub></span>，<spanclass="math inline"><em>s</em><sub><em>t</em></sub></span>的信息是前面的元素的信息的一个编码。假设第<spanclass="math inline"><em>t</em></span>时间的元素的信息都被编码到了<spanclass="math inline"><em>s</em><sub><em>t</em> − 2</sub></span>和<spanclass="math inline"><em>x</em><sub><em>t</em> − 1</sub></span>中，<spanclass="math inline"><em>s</em><sub><em>t</em> − 2</sub></span>是一个向量，<spanclass="math inline"><em>g</em></span>是一个函数，<spanclass="math inline"><em>s</em><sub><em>t</em> − 2</sub></span>是一个隐藏状态。我们认为时间上也存在一个感受野。这个思考过程和人也是类似的，在处理序列问题时，也保存早些时候的一些信息。</p><p>另外也有时间上的<strong>平稳性假设</strong>，这个假设是人工智能能预测未来的理论基础。本质是时间上的独立同分布假设。</p><h4 id="parametric-sharing">Parametric Sharing</h4><p>不同时刻使用的参数是一样的，这样可以大大降低参数量。这样的模型是<strong>循环神经网络</strong>。</p><h4 id="language-model">Language Model</h4><p>语言中的建模任务为：给定一个句子的前面的单词，预测下一个单词。这个任务被称为语言模型。语言模型的目标是最大化句子的概率。语言模型的输入是一个句子，输出是一个概率分布，表示下一个单词的概率。</p><p><strong>向量化表达</strong>：可以使用one-hot向量表示单词，也可以使用词向量表示单词。每个词的表达大概需要1000维度。如果使用MLP，要将每个词的向量拼接起来，然后输入到MLP中。这样的模型不适合处理长序列，参数是非常可怕的。在MLP中丢失了一部分的信息（由于MLP的输入维度是可交换的），丢失了前后序关系。</p><h4 id="a-better-mlp">A Better MLP</h4><p><strong>n-gram</strong>：使用n-gram模型，可以考虑前n个单词的信息。</p><p><img src="Pasted%20image%2020250320225821.png"alt="Pasted image 20250320225821" />输出的概率分布是一个softmax层，输入是一个向量，这个向量是前n个单词的向量拼接起来的。然后在得到的概率分布上进行采样。<strong>滚动预测</strong>，使用第一个次的预测结果作为第二次的输入，会有<strong>误差累计</strong>的问题。但是上述模型会有一个问题：参数量太大；对于每一个词的预测需要有一个MLP，这样的模型不适合处理长序列。### RNN</p><figure><img src="Pasted%20image%2020250321083321.png"alt="Pasted image 20250321083321" /><figcaption aria-hidden="true">Pasted image 20250321083321</figcaption></figure><p>循环神经网络中最重要的内容是中间的隐藏层，构建学习到的时间程度上的特征。在每个时刻输入的都是向量，称为<em>tokenembedding</em>。 上述模型在纵向方向上，从<spanclass="math inline"><em>x</em><sub><em>t</em></sub></span>到<spanclass="math inline"><em>y</em><sub><em>t</em></sub></span>就是一个前馈网络<em>feedforwardnetwork</em>（包括MLP和CNN）。在横向方向上，从<spanclass="math inline"><em>s</em><sub><em>t</em> − 1</sub></span>到<spanclass="math inline"><em>s</em><sub><em>t</em></sub></span>就是一个循环网络<em>recurrentnetwork</em>。 #### Recurrent Layer <spanclass="math inline"><em>h</em><sub><em>t</em></sub></span>用来编码<spanclass="math inline"><em>t</em></span>时刻之前的所有信息。对于这样的层，接受的输入是<spanclass="math inline"><em>x</em><sub><em>t</em></sub></span>和<spanclass="math inline"><em>h</em><sub><em>t</em> − 1</sub></span>，输出是<spanclass="math inline"><em>h</em><sub><em>t</em></sub></span>。<spanclass="math inline"><em>h</em><sub><em>t</em></sub></span>的计算公式如下：<spanclass="math display"><em>h</em><sub><em>t</em></sub> = <em>f</em><sub><em>W</em></sub>(<em>h</em><sub><em>t</em> − 1</sub>,<em>x</em><sub><em>t</em></sub>)</span><spanclass="math display"><em>h</em><sub><em>t</em></sub> = tanh (<em>W</em><em>h</em><sub><em>t</em> − 1</sub>+<em>U</em><em>x</em><sub><em>t</em></sub>)</span>长期以来使用的是双曲正切作为激活函数，但是使用ReLu可能有更好的梯度性质。<spanclass="math display"><em>y</em><sub><em>t</em></sub> = <em>V</em><em>h</em><sub><em>t</em></sub></span>可以认为<spanclass="math inline"><em>h</em><sub><em>t</em></sub></span>包含了之前的所有信息，所以使用<spanclass="math inline"><em>h</em><sub><em>t</em></sub></span>来预测<spanclass="math inline"><em>y</em><sub><em>t</em></sub></span>。<strong>通过引入状态变量来使得递推公式在形式上是二阶依赖。</strong></p><h4 id="bidirectionaldeep-rnn">Bidirectional&amp;Deep RNN</h4><figure><img src="Pasted%20image%2020250321091923.png"alt="Pasted image 20250321091923" /><figcaption aria-hidden="true">Pasted image 20250321091923</figcaption></figure><figure><img src="Pasted%20image%2020250321091936.png"alt="Pasted image 20250321091936" /><figcaption aria-hidden="true">Pasted image 20250321091936</figcaption></figure><p>这里纵向方向上的前馈网络中的训练难点在前面的MLP与CNN中是一样的，梯度消失和梯度爆炸。上面的图中的<spanclass="math inline"><em>y</em><sub><em>t</em>, <em>c</em></sub></span>是真是标签的独热编码，<spanclass="math inline"><em>C</em></span>是此表中的元素个数。</p><p>在横向方向上，梯度消失是很严重的。因为<spanclass="math inline"><em>h</em><sub><em>t</em></sub></span>包含了<spanclass="math inline"><em>h</em><sub><em>t</em> − 1</sub></span>的信息，所以梯度会在时间上指数级的衰减。解决这个问题的方法是<strong>LSTM</strong>和<strong>GRU</strong>。</p><h4 id="rnn-for-lm">RNN for LM</h4><ul><li>理论上，可以表达没有边界的时间上的依赖，由于将状态变量编码为<spanclass="math inline"><em>h</em><sub><em>t</em></sub></span>，<spanclass="math inline"><em>h</em><sub><em>t</em></sub></span>包含了之前的所有信息。</li><li>将序列编码到一个向量中，这个向量包含了整个序列的信息。</li><li>参数在时间上是共享的</li><li>但是在实际上，很难建模时间上的长时间依赖。对于较早的信息，后面的权重会很小。</li></ul><p><strong>一个模型是否有效，在于<em>assumptions</em>与实际情况是否匹配。</strong></p><h4 id="architecture">Architecture</h4><figure><img src="Pasted%20image%2020250321102900.png"alt="Pasted image 20250321102900" /><figcaption aria-hidden="true">Pasted image 20250321102900</figcaption></figure><h5 id="many-to-one">Many to One</h5><p>主要实现的是情感识别、文本分类等任务。在最后一个时间步的输出是最终的输出。最后一个时刻的状态不一定包含有重要的信息（比如上下文中的情感词）。</p><h5 id="one-to-many">One to Many</h5><p>可能的输入有，比如输入一个图像的特征向量再输入到这个网络中。对于这个输入，应该是输入每个状态还是输入所有的状态。并没有解决每一个词对应图中的哪一个区域的问题。</p><h5 id="many-to-many">Many to Many</h5><p>有两种情况，输入是每个时刻的语音的因素，输出的是对应的symbol，是输入输出平行<em>parallel</em>的，但是输入和输出是异构的。</p><p>LM输入和输出是基本上平行的，但是滞后一个时刻，是自回归<em>autoregressive</em>的。##### Sequence to Sequence</p><p>输入和输出都是序列，输入和输出的长度不一定相同。比如机器翻译、语音识别等任务。这个任务可以分为两个部分：编码器和解码器。编码器将输入序列编码到一个向量中，解码器将这个向量解码到输出序列中。</p><figure><img src="Pasted%20image%2020250321110238.png"alt="Pasted image 20250321110238" /><figcaption aria-hidden="true">Pasted image 20250321110238</figcaption></figure><p><em>为什么上述序列中的参数<spanclass="math inline"><em>W</em><sub>1</sub></span>和<spanclass="math inline"><em>W</em><sub>2</sub></span>是不一样的？</em></p><p>首先将输入变量<spanclass="math inline">{<em>x</em><sub><em>t</em></sub>}</span>编码到状态变量<spanclass="math inline">{<em>h</em><sub><em>t</em></sub>}</span>中，然后再将状态变量<spanclass="math inline">{<em>h</em><sub><em>t</em></sub>}</span>解码到输出变量<spanclass="math inline">{<em>y</em><sub><em>t</em></sub>}</span>中。编码器是没有lossfunction的，因为输入和输出是异构的。解码器接受的输入是编码器的输出，解码器的输出是一个概率分布。解码器的lossfunction是交叉熵损失函数。</p><p><strong>机器翻译任务中的挑战</strong>： - 输入和输出是异构的 -长序列的处理</p><figure><img src="Pasted%20image%2020250321130443.png"alt="Pasted image 20250321130443" /><figcaption aria-hidden="true">Pasted image 20250321130443</figcaption></figure><p><strong>如何从概率中采样</strong>： - 选择概率最大的 -概率较大的有更大的概率被选择 - Beam Search贪心方法进行搜索</p><figure><img src="Pasted%20image%2020250321130842.png"alt="Pasted image 20250321130842" /><figcaption aria-hidden="true">Pasted image 20250321130842</figcaption></figure><p>可以选择概率较大的k个词，然后以这个词为条件计算下一个词的条件概率，类似于构建一个真k叉树，这样的方法是一种贪心的方法。考虑这棵树上所有的路径，选择最大的路径（本质上是一种搜索技术）。</p><h3 id="backpropagation-through-time">Backpropagation Through Time</h3><figure><img src="Pasted%20image%2020250321133148.png"alt="Pasted image 20250321133148" /><figcaption aria-hidden="true">Pasted image 20250321133148</figcaption></figure><p><span class="math display">$$\frac{\partial L}{\partial U}  = \sum_{t=0}^T \frac{\partialL_{t}}{\partial U} = \sum_{t=0}^{T} \sum_{s=0}^t \frac{\partialL_{t}}{\partial y_t} \frac{\partial y_t}{\partial h_t}  \frac{\partialh_t}{\partial h_s}\frac{\partial h_s}{\partial U}$$</span>前一个求和的意义是对于损失函数的各个部分求和，后面的求和式是对于<spanclass="math inline"><em>h</em><sub><em>t</em></sub></span>的前面的每一个可能的链求和。其中： <span class="math display">$$\frac{\partial h_t}{\partial h_s} = \prod_{i=s+1}^t \frac{\partialh_i}{\partial h_{i-1}}$$</span>这个式子是一个矩阵乘法，是一个矩阵的连乘。这个矩阵是一个雅可比矩阵。</p><figure><img src="Pasted%20image%2020250321135457.png"alt="Pasted image 20250321135457" /><figcaption aria-hidden="true">Pasted image 20250321135457</figcaption></figure><p>用<em>Cauchy-Schwarz</em>不等式可以证明： <spanclass="math display">$$\| \frac{\partial h_t}{\partial h_{t-1}} \| \leq \| W^T \| \|diag(f'(h_{t-1}))\| \leq \sigma_{max} \gamma$$</span> 这里<spanclass="math inline"><em>σ</em><sub><em>m</em><em>a</em><em>x</em></sub></span>是矩阵<spanclass="math inline"><em>W</em></span>的最大奇异值，<spanclass="math inline"><em>γ</em></span>是激活函数的导数的最大值。 于是：<span class="math display">$$\| \frac{\partial h_t}{\partial h_{s}} \| =  \prod_{i=s+1}^t \|\frac{\partial h_i}{\partial h_{i-1}} \| \leq (\sigma_{max}\gamma)^{t-s}$$</span>这个式子说明了梯度消失的问题，梯度消失是指梯度在时间上的指数级衰减。或者梯度爆炸的问题，梯度爆炸是指梯度在时间上的指数级增长。</p><h4 id="truncated-bptt">Truncated BPTT</h4><figure><img src="Pasted%20image%2020250321140454.png"alt="Pasted image 20250321140454" /><figcaption aria-hidden="true">Pasted image 20250321140454</figcaption></figure><p>这个方法是将时间上的梯度截断，这样可以减少梯度消失和梯度爆炸的问题。但是这样的方法会导致梯度的估计不准确，因为梯度的估计是基于一个截断的时间窗口的。</p><h4 id="long-short-term-memory">Long Short-Term Memory</h4><blockquote><p>为什么这样就能实现所谓的LSTM</p></blockquote><ul><li>遗忘，将过去“没用”的信息遗忘</li><li>更新，将新的信息更新到状态变量中</li><li>输出，输出门控制一部分信息用来进行预测 <imgsrc="Pasted%20image%2020250321141243.png"alt="Pasted image 20250321141243" /> <spanclass="math inline"><em>t</em></span>时刻的状态变量<spanclass="math inline"><em>h</em><sub><em>t</em></sub></span>储存的是<spanclass="math inline"><em>t</em></span>时刻的信息，<spanclass="math inline"><em>c</em><sub><em>t</em></sub></span>是<spanclass="math inline"><em>t</em></span>时刻的记忆变量，<spanclass="math inline"><em>h</em><sub><em>t</em> − 1</sub></span>和<spanclass="math inline"><em>x</em><sub><em>t</em></sub></span>是<spanclass="math inline"><em>t</em></span>时刻的输入，<spanclass="math inline"><em>f</em><sub><em>t</em></sub></span>是遗忘门，<spanclass="math inline"><em>i</em><sub><em>t</em></sub></span>是输入门，<spanclass="math inline"><em>o</em><sub><em>t</em></sub></span>是输出门，<spanclass="math inline"><em>g</em><sub><em>t</em></sub></span>是更新门。</li></ul><p><img src="Pasted%20image%2020250321141234.png"alt="Pasted image 20250321141234" />上述网络构造了一个信息流高速路径，使得梯度能够进行快速的传播。</p><p>遗忘门和残差网络的思想是类似的，都是将过去的信息和现在的信息进行融合。这样的网络可以更好的处理长序列的问题。[[DeepLearning Lecture-3#ResNet]]</p><h4 id="gradient-clipping">Gradient Clipping</h4><p>梯度的大小是由模长决定的，如果梯度的模长过大，可以将梯度的模长进行截断。这样可以避免梯度爆炸的问题。</p><h4 id="variational-dropout">Variational Dropout</h4><p>在深度网络中，如果是过拟和的，也就是对于一个含有多个参数的网络。也就是说如果输入的参数小于参数的个数，那么相对应的线性方程组是欠定的。</p><p>在RNN中对应的纵向方向上是多层感知机，所以可以采用标准的Dropout方法。但是在横向方向上是一个循环网络，Dropout方法不适用。因为Dropout方法会破坏时间上的连续性，违背了参数共享的原则。采用<strong>步调一致</strong>的方法进行操作，这样可以保持时间上的连续性。这样的方法是<strong>VariationalDropout</strong>。</p><h4 id="layer-normalization">Layer Normalization</h4><figure><img src="Pasted%20image%2020250322202759.png"alt="Pasted image 20250322202759" /><figcaption aria-hidden="true">Pasted image 20250322202759</figcaption></figure><p>在CNN中，对于每一个通道的值进行归一化。在这样的每一个通道中计算均值和方差。还是要加入一个平移变量和伸缩变量。</p><p>在RNN中，主要的原因是门控结构是相对于每一个序列而言的，所以应该引入一种新的归一化方法<em>LayerNormalization</em>，应该在每一条样本（一个序列）在每一个时刻经过之后的值在<spanclass="math inline"><em>C</em></span>个通道上进行归一化操作。最后得到的结果是：将所有的向量放在以原点为球心的单位球面上。</p><h4 id="weight-normalization">Weight Normalization</h4><p>对于每层的参数<spanclass="math inline"><strong>w</strong></span>进行重参数化： <spanclass="math display">$$\mathbf{w} = \frac{g}{\|v\|}v$$</span> <img src="Pasted%20image%2020250322204925.png"alt="Pasted image 20250322204925" /></p><p>对右边的式子<spanclass="math inline">$\frac{v}{\|v\|}$</span>进行优化是更为容易的，重参数化的意思是，在训练和测试的时候使用不同的参数表达形式，这样是更加容易优化的。</p><h4 id="training-inference-shift">Training-Inference Shift</h4><p>滚动预测：在训练的时候，使用真实的标签进行预测；在测试的时候，使用的是推理得到的值进行预测。这是一个自回归任务。</p><h5 id="curriculum-learning">Curriculum Learning</h5><p>在训练的时候，可以先训练一些简单的任务，然后再训练一些复杂的任务。这样可以更好的训练模型。在实际中，可以对所有的样本计算loss，先计算loss较小的样本，然后再计算loss较大的样本。这就是<strong>自步学习</strong>。这里涉及到选择不同的样本顺序的问题。</p><p><em>ScheduledSampling</em>：在学习刚开始的时候，更多地使用真实的标签进行预测；随着学习的进行，更多地使用模型预测的值进行预测。<strong>是RNN中很重要的技术</strong>。</p><h3 id="rnn-with-attention">RNN with Attention</h3><h4 id="human-attention">Human Attention</h4><p>人类的注意力： - 可持续注意力（没有实现） -选择性注意力（人类的选择性注意力复杂得多） - 交替式注意力 -分配式注意力</p><h4 id="attention-in-deep-learning">Attention in Deep Learning</h4><blockquote><p><em>Allowing the model to dynamically pay attention to only certainparts of the input that help in performing the task at handeffectively.</em></p></blockquote><p>存在时间<em>temporal Attention</em>和空间<em>SpatialAttention</em>上的注意力。一般而言指的是时间上的注意力。</p><h4 id="auto-regessive">Auto-Regessive</h4><p>[[#Sequence to Sequence]]</p><p>最重要的问题是编码器和解码器之间的信息沟通太少了，存在有信息瓶颈。并且在翻译任务中，输入和输出的顺序并不是一致的，大部分的语言的语序是不一样的。<strong>希望看到后面的信息</strong>，这和RNN的设计目的是相违背的。<strong>全连接的思想</strong>又回来了，获得全局信息的方法有很多，不只是有MLP的方法。有一种基本思想是<strong><em>Relevance</em></strong>，也就是和当前任务相关的信息。这个思想是在Attention中得到了体现。</p><h4 id="attention">Attention</h4><figure><img src="Pasted%20image%2020250322222251.png"alt="Pasted image 20250322222251" /><figcaption aria-hidden="true">Pasted image 20250322222251</figcaption></figure><p>计算两个东西的相似度有：计算内积、输入<em>relationnetwork</em>。这样的模型在互联网中有很多的应用，比如推荐系统、搜索引擎等。</p><figure><img src="Pasted%20image%2020250323084415.png"alt="Pasted image 20250323084415" /><figcaption aria-hidden="true">Pasted image 20250323084415</figcaption></figure><p>注意力的分配是符合概率分布的，所以可以使用上面计算得到的相关性<spanclass="math inline"><em>e</em><sub><em>i</em><em>j</em></sub></span>使用softmax函数进行归一化。这样得到的分布就是注意力的分布：<span class="math display">$$\alpha_{ij} = \frac{\exp(e_{ij})}{\sum_{k=1}^{T_x} \exp(e_{ik})}$$</span> 上述计算式表达的含义是，在状态<spanclass="math inline"><em>i</em></span>的时刻分配在<spanclass="math inline"><em>j</em></span>上的注意力（对于<spanclass="math inline"><em>j</em></span>的求和为1）。继续计算<spanclass="math inline"><em>c</em><sub><em>i</em></sub></span>： <spanclass="math display">$$c_i = \sum_{j=1}^{T_x} \alpha_{ij} x_j$$</span> 这里<spanclass="math inline"><em>c</em><sub><em>i</em></sub></span>是对于状态<spanclass="math inline"><em>i</em></span>的时刻的注意力向量，是对于<spanclass="math inline"><em>x</em></span>的加权和。 <spanclass="math display"><em>s</em><sub><em>i</em></sub> = <em>f</em>(<em>s</em><sub><em>i</em> − 1</sub>,<em>y</em><sub><em>i</em> − 1</sub>,<em>c</em><sub><em>i</em></sub>)</span>这里<spanclass="math inline"><em>s</em><sub><em>i</em></sub></span>是状态变量，<spanclass="math inline"><em>y</em><sub><em>i</em> − 1</sub></span>是前一个时刻的输出，<spanclass="math inline"><em>c</em><sub><em>i</em></sub></span>是当前时刻的注意力向量。这里的函数<spanclass="math inline"><em>f</em></span>是一个GRU orLSTM。这个模型是一个<strong>Seq2Seq</strong>模型。</p><blockquote><p>这里的<spanclass="math inline"><em>c</em><sub><em>i</em></sub></span>和<spanclass="math inline"><em>s</em><sub><em>i</em></sub></span>的区别是什么，为什么和LSTM有关</p></blockquote><p><img src="Pasted%20image%2020250323084332.png"alt="Pasted image 20250323084332" /> <imgsrc="Pasted%20image%2020250323084535.png"alt="Pasted image 20250323084535" /></p><p>在机器翻译的过程中，使用source的上下文信息比直接使用词典来翻译更好。这样的模型可以更好的处理长序列的问题。只要是序列都会使用<strong>滑动窗口</strong>，一般设置为50~100之间。对于较短的情况，可以使用psdding的方法；对于较长的情况会使用截断的方法。希望找一个与序列的长度线性关系的模型。</p><h4 id="attention-vs.-mlp">Attention vs. MLP</h4><p>相同点： - 都是全局模型，是对于长序关系的建模。</p><p>不同点： - Attention是基于概率的，MLP是基于全连接的。 -Attention引入relevance的思想，能大大减小参数量</p><h4 id="hierarchical-attention">Hierarchical Attention</h4><p>先建模词注意力然后再建模句子注意力。</p><h4 id="global-attention">Global Attention</h4><p><span class="math display">$$\text{score} = \begin{cases}h_t^T \overline{h_s} \\h_t^T W_a \overline{h_s} \\v_a^T \tanh(W_a[h_t;\overline{h_s}])\end{cases}$$</span> 发现上面三种计算方式的效率是差不多的。</p><figure><img src="Pasted%20image%2020250323090740.png"alt="Pasted image 20250323090740" /><figcaption aria-hidden="true">Pasted image 20250323090740</figcaption></figure><h3 id="memory">Memory</h3><h4 id="human-memory">Human Memory</h4><ul><li>Sensory Memory<ul><li>计算机视觉与机器感知</li></ul></li><li>Short-term Memory<ul><li>与计算机中的内存是很相近的，LSTM是一种将短期记忆尽量变长的方法。</li></ul></li><li>Long-term Memory<ul><li>前面的模型中没有实现这个功能</li></ul></li></ul><p>在自然语言中，比较困难的任务是进行对话，这时候需要进行长期记忆。在对话中，需要对话的上下文进行理解。</p><h4 id="neural-turing-machine">Neural Turing Machine</h4><figure><img src="Pasted%20image%2020250323092327.png"alt="Pasted image 20250323092327" /><figcaption aria-hidden="true">Pasted image 20250323092327</figcaption></figure><p>在这个模型中，最重要的是对内存1进行寻址的操作，这个操作是一个注意力的操作。对于读的操作，是按照注意力的大小对地址里面的内容进行加权平均。对于写的操作，类似于LSTM中的Forget Gate，先进行擦除之后才进行写入。</p><p>对于Internal Memory，最大的问题是可能会遗忘，对于ExternalMemory，是一个外部的存储器，这样的存储是比较稳定的。</p>]]></content>
    
    
    
    <tags>
      
      <tag>DeepLearning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Learning Lecture-6</title>
    <link href="/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-6/"/>
    <url>/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-6/</url>
    
    <content type="html"><![CDATA[<h2 id="transformers">Transformers</h2><h3 id="transformers-attention-is-all-you-need">Transformers: Attentionis All You Need</h3><p>[[Deep Learning Lecture-5#Attention]]</p><p>再次理解Attention的概念：类似于”查字典“的操作，对于Query <spanclass="math inline"><em>q</em></span>, Key <spanclass="math inline"><em>k</em></span>和Value <spanclass="math inline"><em>v</em></span>，计算相关性，也就是重要性，对于输出序列中的第<spanclass="math inline"><em>i</em></span>个输出有价值的信息： <spanclass="math display"><em>w</em><sub><em>i</em><em>j</em></sub> = <em>a</em>(<em>q</em><sub><em>i</em></sub>,<em>k</em><sub><em>j</em></sub>)</span>其中<spanclass="math inline"><em>a</em></span>是一个函数，可以是内积、<em>AdditiveAttention</em>等。对于输出序列中的第<spanclass="math inline"><em>i</em></span>个输出，计算当前的输出的<spanclass="math inline"><em>q</em><sub><em>i</em></sub></span>，计算与输入序列中的<spanclass="math inline"><em>k</em><sub><em>j</em></sub></span>的相关性，然后对于<spanclass="math inline"><em>v</em><sub><em>j</em></sub></span>进行加权求和（这是一种寻址操作），得到的<spanclass="math inline"><em>c</em><sub><em>i</em></sub></span>是查字典所得到的信息：<span class="math display">$$c_i = \sum_{j=1}^T w_{ij}v_j$$</span> <strong>希望找到一种更好的计算方法</strong>。</p><p>在[[Deep Learning Lecture-5#RNN with Attention]]中问题在于： -太复杂的模型 - 某种意义上使用的Attention已经足够使用，不再需要循环网络 -循环网络的计算是串行的，不能有效加速 #### Self-Attention</p><p>计算的是同一条序列中的不同位置之间的相关性，也就是自注意力。对于输入序列中的第<spanclass="math inline"><em>i</em></span>个位置，计算与其他位置的相关性，然后对于所有的位置进行加权求和：规定Query <spanclass="math inline"><em>Q</em> = [<em>q</em><sub>1</sub>…<em>q</em><sub><em>n</em></sub>]</span>，Key<spanclass="math inline"><em>K</em> = [<em>k</em><sub>1</sub>…<em>k</em><sub><em>n</em></sub>]</span>，Value<spanclass="math inline"><em>V</em> = [<em>v</em><sub>1</sub>…<em>v</em><sub><em>k</em></sub>]</span>，则：</p><figure><img src="Pasted%20image%2020250323133751.png"alt="Pasted image 20250323133751" /><figcaption aria-hidden="true">Pasted image 20250323133751</figcaption></figure><h4 id="scaled-dot-product-attention">Scaled Dot-Product Attention</h4><p>我们认为使用一个网络来计算相关性太复杂了，当两个向量是相同维度的时候可以直接计算内积。在这里，在计算先引入参数，使得其维度是一样的，从而可以计算内积：</p><p><em>Scaled Dot-Product</em> : <span class="math display">$$a(q,k) = \frac{q^T k}{\sqrt{d_k}}$$</span>使得变换前后的方差是一样的，这样可以使得梯度更加稳定，否则可能进入激活函数的饱和区。<span class="math display">$$Attention(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$</span> 上面的式子将得到的<spanclass="math inline"><em>n</em> × <em>n</em></span>的矩阵进行softmax操作，在归一化的过程中，<strong>是某一个query在所有的key上的注意力分配一定是<spanclass="math inline"><strong>1</strong></span></strong>。后面是对于Value的加权求和。<strong>在上面的公式中，<spanclass="math inline"><em>Q</em></span>、<spanclass="math inline"><em>K</em></span>和<spanclass="math inline"><em>V</em></span>中的向量都是行向量，进行softmax操作时也是在同一行上操作</strong>。</p><figure><img src="Pasted%20image%2020250323141917.png"alt="Pasted image 20250323141917" /><figcaption aria-hidden="true">Pasted image 20250323141917</figcaption></figure><p>对于同一组输入，经过不同的线性变换得到的不同的Query、Key和Value，在样本数量为<spanclass="math inline"><em>m</em></span>的情况下，可以进行计算：</p>$$<p>$$</p><p><strong>维度总结表</strong></p><table><thead><tr class="header"><th>矩阵/操作</th><th>维度</th><th>说明</th></tr></thead><tbody><tr class="odd"><td>输入矩阵 <span class="math inline"><em>X</em></span></td><td><spanclass="math inline"><em>m</em> × <em>d</em><sub>input</sub></span></td><td>包含 <span class="math inline"><em>m</em></span>个样本，每个样本维度为 <spanclass="math inline"><em>d</em><sub>input</sub></span></td></tr><tr class="even"><td>查询矩阵 <span class="math inline"><em>Q</em></span></td><td><spanclass="math inline"><em>m</em> × <em>d</em><sub><em>k</em></sub></span></td><td>每个样本的查询向量维度为 <spanclass="math inline"><em>d</em><sub><em>k</em></sub></span></td></tr><tr class="odd"><td>键矩阵 <span class="math inline"><em>K</em></span></td><td><spanclass="math inline"><em>m</em> × <em>d</em><sub><em>k</em></sub></span></td><td>每个样本的键向量维度为 <spanclass="math inline"><em>d</em><sub><em>k</em></sub></span></td></tr><tr class="even"><td>值矩阵 <span class="math inline"><em>V</em></span></td><td><spanclass="math inline"><em>m</em> × <em>d</em><sub><em>v</em></sub></span></td><td>每个样本的值向量维度为 <spanclass="math inline"><em>d</em><sub><em>v</em></sub></span></td></tr><tr class="odd"><td>注意力得分矩阵 <spanclass="math inline"><em>Q</em><em>K</em><sup><em>T</em></sup></span></td><td><span class="math inline"><em>m</em> × <em>m</em></span></td><td>样本间的注意力强度矩阵</td></tr><tr class="even"><td>最终输出 <spanclass="math inline">Attention(<em>Q</em>,<em>K</em>,<em>V</em>)</span></td><td><spanclass="math inline"><em>m</em> × <em>d</em><sub><em>v</em></sub></span></td><td>聚合所有样本的加权值信息，输出维度为 <spanclass="math inline"><em>d</em><sub><em>v</em></sub></span></td></tr></tbody></table><h4 id="multi-head-attention">Multi-Head Attention</h4><p>注意到上面的注意力的表达能力是相当有限的，在languagemodel同一个词和其他不同的词之间可能有很多种不同的关系，仅仅用一种简单的关系来表示是不够的。所以我们引入多头注意力，希望能在不同的侧面上进行表达。<spanclass="math display">MultiHead(<em>Q</em>,<em>K</em>,<em>V</em>) = Concat(head<sub>1</sub>,…,head<sub><em>h</em></sub>)<em>W</em><sup><em>O</em></sup></span>其中： <spanclass="math display">head<sub><em>i</em></sub> = Attention(<em>Q</em><em>W</em><sub><em>i</em></sub><sup><em>Q</em></sup>,<em>K</em><em>W</em><sub><em>i</em></sub><sup><em>K</em></sup>,<em>V</em><em>W</em><sub><em>i</em></sub><sup><em>V</em></sup>)</span>其中<spanclass="math inline"><em>W</em><sub><em>i</em></sub><sup><em>Q</em></sup>, <em>W</em><sub><em>i</em></sub><sup><em>K</em></sup>, <em>W</em><sub><em>i</em></sub><sup><em>V</em></sup></span>是不同的线性变换，<spanclass="math inline"><em>W</em><sup><em>O</em></sup></span>是最后的线性变换，最后进行的维度的规约操作。与CNN相比，CNN的不同的通道之间与上一层的每一个通道之间都是有连接的；但是在这里，不同的头之间是没有连接的，这样可以使得不同的头可以关注不同的信息。</p><p>不同的头之间是可以并行计算的，这样可以加速计算；但是缺点是内存占用会很大。</p><h4 id="position-wise-feed-forward-networks">Position-wise Feed-ForwardNetworks</h4><p><img src="Pasted%20image%2020250323145847.png"alt="Pasted image 20250323145847" /> 在标准 Transformer Block中，注意力层之后会接一个前馈神经网络（FFN），其结构如下：</p><ol type="1"><li><p>输入张量形状：<br /><spanclass="math display"><em>X</em> ∈ ℝ<sup><em>B</em> × <em>L</em> × <em>H</em> × <em>D</em></sup></span></p><ul><li><span class="math inline"><em>B</em></span>：Batch size<br /></li><li><span class="math inline"><em>L</em></span>：序列长度<br /></li><li><span class="math inline"><em>H</em></span>：Attention 头数<br /></li><li><span class="math inline"><em>D</em></span>：每个头的维度</li></ul></li><li><p>将多头输出合并：<br /><spanclass="math display"><em>X</em>′ = reshape(<em>X</em>, (<em>B</em>, <em>L</em>, <em>H</em>⋅<em>D</em>)) ∈ ℝ<sup><em>B</em> × <em>L</em> × (<em>H</em> <em>D</em>)</sup></span></p></li><li><p>两层“卷积”全连接结构<br />这里所谓“卷积”，实际上等价于在最后一维上对每个位置独立地做 1×1 卷积（与RNN 中在不同时间步共享参数的思想一致），并在卷积核后加入非线性ReLU。<br /><span class="math display">$$\begin{aligned}Z_1 &amp;= \mathrm{ReLU}\bigl(X' W_1 + b_1\bigr),\quadW_1\in\mathbb{R}^{(H\!D)\times d_{ff}},\; b_1\in\mathbb{R}^{d_{ff}}\\Z_2 &amp;= Z_1 W_2 + b_2,\quad W_2\in\mathbb{R}^{d_{ff}\times(H\!D)},\;b_2\in\mathbb{R}^{(H\!D)}\end{aligned}$$</span></p><ul><li>第一层升维到中间维度 <spanclass="math inline"><em>d</em><sub><em>f</em><em>f</em></sub></span>（例如<span class="math inline">2048</span>）<br /></li><li>第二层降维回原始维度 <spanclass="math inline"><em>H</em> <em>D</em></span>（例如 <spanclass="math inline">512</span>）</li></ul></li><li><p>加残差 &amp; LayerNorm<br /><spanclass="math display"><em>Y</em> = LayerNorm(<em>X</em>′ + <em>Z</em><sub>2</sub>) ∈ ℝ<sup><em>B</em> × <em>L</em> × (<em>H</em> <em>D</em>)</sup></span></p></li><li><p>（可选）reshape 回多头排列：<br /><spanclass="math display"><em>Y</em>′ = reshape(<em>Y</em>, (<em>B</em>, <em>L</em>, <em>H</em>, <em>D</em>))</span></p></li></ol><ul><li><strong>线性限制</strong>：除去 Attention 中的SoftMax，若只堆线性层，模型表达能力较弱；引入 ReLU后能够拟合更复杂的非线性函数。<br /></li><li><strong>稀疏权重</strong>：Attention 的 SoftMax本质上生成了一组“稀疏”权重，负责学习不同位置间的依赖；FFN则负责在每个位置上“干净”地抽取该词的内部特征，避免无谓的跨词干扰。<br /></li><li><strong>卷积视角</strong>：将 FFN 看作<strong>对最后一维的 1×1卷积</strong>，等同于对每个位置独立但在所有位置共享参数，这与 RNN在时间步上共享权重的假设一致。<br /></li><li><strong>增强表达</strong>：Attention 解决了上下文依赖，FFN则补强了单位置特征提取，两者协同提升了 Transformer 的整体表达能力。</li></ul><hr /><blockquote><p><strong>注意</strong>：以上操作对每个批次（<spanclass="math inline"><em>B</em></span>）中每个序列位置（<spanclass="math inline"><em>L</em></span>）都独立执行，参数在所有位置间共享。</p></blockquote><h4 id="residual-connection">Residual Connection</h4><p>在上面的操作中，这些操作都是有排列不变性。残差是一个标准的操作，这样可以让网络更好地记录位置编码。</p><h4 id="layer-normalization">Layer Normalization</h4><p>目的是使得每一层经过Attention和Feed-Forward之后的输出的分布是一样的，这样可以使得梯度更加稳定。[[Deep Learning Lecture-5#Layer Normalization]]</p><figure><img src="Pasted%20image%2020250323151056.png"alt="Pasted image 20250323151056" /><figcaption aria-hidden="true">Pasted image 20250323151056</figcaption></figure><h4 id="value-embedding">Value Embedding</h4><ul><li><p><strong>目的</strong>：将原始输入特征（如温度、流量、股价等数值）从低维（通常是1或几个通道）映射到高维向量空间，使模型能在更大维度下学习更丰富的特征表示。</p></li><li><p><strong>做法</strong>：通过一个线性层或 1×1卷积（<code>TokenEmbedding</code>）把每个时间步的原始向量映成长度为<code>d_model</code> 的向量。</p></li><li><p><strong>实现方式</strong>：通过一个线性映射或 <spanclass="math inline">1 × 1</span> 卷积完，对于有<spanclass="math inline"><em>c</em><sub><em>i</em><em>n</em></sub></span>个特征维度的输入，使用卷积核的大小是<spanclass="math inline">[<em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub>,<em>c</em><sub><em>i</em><em>n</em></sub>,1]</span></p></li><li><p><strong>输入维度</strong>：<spanclass="math inline">(batch_size,seq_len,<em>c</em><sub><em>i</em><em>n</em></sub>)</span></p></li><li><p><strong>输出维度</strong>：<spanclass="math inline">(batch_size,seq_len,<em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub>)</span></p></li></ul><h4 id="positional-encoding-position-embedding">Positional Encoding/Position Embedding</h4><p>位置信息是顺序信息的一种泛化的形式。如果采用独热编码，这是一种类别信息而不是一个顺序信息，不同的是不可以比的。所以引入<em>positionembedding</em>，这是一个矩阵，效果类似于一个查找表。查找操作在这里就是一个矩阵乘上一个独热编码的操作，这是因为GPU在矩阵乘法操作上是非常高效的。但是独热编码会带来下面的问题 - <strong>高维稀疏性</strong>：独热编码的维度等于序列最大长度（如512），导致向量稀疏且计算效率低下（尤其对长序列）。- <strong>无法泛化到未见长度</strong>：若训练时序列最大长度为512，模型无法处理更长的序列</p><p><strong>引入归纳偏好</strong>： -每个位置的编码应该是独一无二的且是确定的 -认为两个位置的距离应该是一致的 -应该生成一个有界的值，位置数随着序列长度的增加而增加</p><p>Google的实现是使用的正弦和余弦函数的组合： <spanclass="math display">$$e_i(2j) = \sin\left(\frac{i}{10000^{2j/d_{\text{model}}}}\right)$$</span> <span class="math display">$$e_i(2j+1) = \cos\left(\frac{i}{10000^{2j/d_{\text{model}}}}\right)$$</span> 上述公式中的<spanclass="math inline"><em>i</em></span>指的句子中的第<spanclass="math inline"><em>i</em></span>个位置，<spanclass="math inline"><em>j</em></span>指的是位置编码的维度，<spanclass="math inline"><em>d</em><sub>model</sub></span>是位置编码的维度。这样的编码是满足上面的归纳偏好的。</p><h4 id="temporal-embedding">Temporal Embedding</h4><ul><li><strong>目的</strong>：针对时间序列中特有的“时间属性”——小时、星期几、月份、季节等——进行编码，让模型学到周期性（如日周期、周周期、年周期）和节假日效应等信息。</li><li><strong>做法</strong>：通常把每个时间属性（hour-of-day, day-of-week,month 等）也映射到 <code>d_model</code>维度，然后把这些属性向量加起来或拼接后再降维。<code>TemporalEmbedding</code>类会根据 <code>embed_type</code>（如 <code>'fixed'</code> 或<code>'learned'</code>）和 <code>freq</code>（如<code>'h'</code>、<code>'d'</code>）来决定具体细节。</li></ul><h4 id="encoder">Encoder</h4><p>编码器中使用的是多头注意力、逐位置前馈网络和位置编码。在这个编码器中是一个直筒式的网络，好处是调参较为简单。</p><p>缺点： - 二次复杂度 - 参数量过大 - 很多的头是冗余的</p><p>训练阶段要使用多个头，发现有些头的权重较低，可以在推理阶段去掉这些头。</p><h4 id="decoder">Decoder</h4><h5 id="autoregressive">Autoregressive</h5><figure><img src="Pasted%20image%2020250323161530.png"alt="Pasted image 20250323161530" /><figcaption aria-hidden="true">Pasted image 20250323161530</figcaption></figure><p>预测阶段一定要使用滚动预测，这是一个自回归的状态，但是这是一个串行的操作，会比较慢。但是在训练阶段这样是不能接受的，我希望训练的不同阶段可以并行计算，但是这里要求在一开始输入所有的序列，所以这里需要<strong>遮挡</strong>。在算Attention的时候，对于当前的位置，只能看到之前的位置，不能看到之后的位置。</p><figure><img src="Pasted%20image%2020250323163151.png"alt="Pasted image 20250323163151" /><figcaption aria-hidden="true">Pasted image 20250323163151</figcaption></figure><p>在编码器上是不能用的，因为防止解码器在训练时利用未来的目标序列信息（即“作弊”），确保模型逐步生成的能力与推理阶段一致。训练过程中仍然需要真实标签作为目标输出，但掩码限制了模型在生成当前词时对未来的访问。</p><h4 id="encoder-decoder-attention">Encoder-Decoder Attention</h4><p>计算的是解码器的输出和编码器的输出之间的相关性，这里的Query是解码器的输出，Key和Value是编码器的输出。</p><figure><img src="Pasted%20image%2020250323185530.png"alt="Pasted image 20250323185530" /><figcaption aria-hidden="true">Pasted image 20250323185530</figcaption></figure><figure><img src="Pasted%20image%2020250323185720.png"alt="Pasted image 20250323185720" /><figcaption aria-hidden="true">Pasted image 20250323185720</figcaption></figure><p>注意这里是将编码器的输出输入到解码器中的每一层的Encoder-DecoderAttention中。这里是神经网络中的<strong>特征重用</strong>思想，并且解码器中的网络是直筒式的，所以这些特征是可以重用的。</p><h4 id="rnn-vs.-transformer">RNN vs. Transformer</h4><ul><li>RNN是串行的，Transformer是并行的</li><li>对于有严格偏序关系的序列，RNN可能更适合</li><li>对于长序列，Transformer更适合</li><li>对于较小的数据量，Transformers参数量较大，表现可能不如RNN</li></ul><figure><img src="Pasted%20image%2020250323190623.png"alt="Pasted image 20250323190623" /><figcaption aria-hidden="true">Pasted image 20250323190623</figcaption></figure><p><img src="Pasted%20image%2020250323190856.png"alt="Pasted image 20250323190856" /> ### X-formers Variance withImprovements</p><p><a href="https://arxiv.org/abs/2106.04554">[2106.04554] A Survey ofTransformers</a></p><figure><img src="Pasted%20image%2020250323191632.png"alt="Pasted image 20250323191632" /><figcaption aria-hidden="true">Pasted image 20250323191632</figcaption></figure><figure><img src="Pasted%20image%2020250323191637.png"alt="Pasted image 20250323191637" /><figcaption aria-hidden="true">Pasted image 20250323191637</figcaption></figure><h4 id="lineariezd-attention">Lineariezd Attention</h4><h4 id="flow-attention">Flow Attention</h4><h3 id="gpt-generative-pre-trained-transformer">GPT: GenerativePre-trained Transformer</h3><h4 id="transfer-learning">Transfer Learning</h4><p>先将一个模型预训练好，然后在特定的任务上进行微调。一般而言，预训练的过程是无监督的，优点是可以使用大规模数据。</p><h4 id="pre-training">Pre-Training</h4><figure><img src="Pasted%20image%2020250324190821.png"alt="Pasted image 20250324190821" /><figcaption aria-hidden="true">Pasted image 20250324190821</figcaption></figure><ul><li>直接使用的是Transformers中的block，但是这里使用12层</li><li>只使用decoder没有encoder，因为这不是一个机器翻译的任务</li><li>在计算损失函数的过程中，使用的似然函数是最大似然估计，在实际中使用一个参数化的网络来近似需要的概率。</li></ul><h4 id="supervised-fine-tuning">Supervised Fine-Tuning</h4><p>对于不同的任务，需要更换模型的输出头，并且还要使用新的损失函数。关注上下文建模。<img src="Pasted%20image%2020250324193704.png"alt="Pasted image 20250324193704" /></p><p>最后是使用无监督训练的损失函数和有监督训练的损失函数的加权和，这是一个<strong>多任务学习</strong>。当微调的数据比较少的时候，可以使用无监督训练的损失函数的权重较大。</p><p>对于不同的下游任务，要进行任务适配<em>Task SpecificAdaptation</em>。对于不同的下游任务，可以使用不同的头。 <imgsrc="Pasted%20image%2020250324194137.png"alt="Pasted image 20250324194137" /></p><h4 id="gpt-2-gpt-3">GPT-2 &amp; GPT-3</h4><p>Zero-shotlearning：在没有看到训练数据的情况下，直接在测试集上进行预测。通过在预训练阶段使用大规模的数据，可以使得模型具有更好的泛化能力，这样可以提高在一些常见问题上的表现。</p><h3id="bert-bidirectional-encoder-representations-from-transformers">BERT:Bidirectional Encoder Representations from Transformers</h3><p>与GPT不同的是，BERT是双向的，可以看到上下文的信息。 <imgsrc="Pasted%20image%2020250324195035.png"alt="Pasted image 20250324195035" /></p><p>BERT在encoder阶段就使用了mask，这样可以使得模型在训练的时候不会看到未来的信息。在训练的过程中随机地mask掉一些词，然后预测这些词。如果遮挡的词太少，那么模型得到的训练不够，如果遮挡的词太多，那么得到的上下文就很少。在训练的过程中就使用了102种语言。特征工程：使用了更多的特征，引入了更多的embedding是多个任务的联合训练，这样可以使得模型更加通用。</p><h4 id="roberta-a-robustly-optimized-bert-pretraining-approach">RoBERTa:A Robustly Optimized BERT Pretraining Approach</h4><p>经过充分的调参和更长的训练时间，使得模型的表现更好。证明了BERT中的下句预测是没有用的，因为在RoBERTa中去掉了这个任务。mask的pattern可以动态调整</p><h4id="albert-a-lite-bert-for-self-supervised-learning-of-language-representations">ALBERT:A Lite BERT for Self-supervised Learning of LanguageRepresentations</h4><p>低秩分解，减少参数量 <img src="Pasted%20image%2020250324203227.png"alt="Pasted image 20250324203227" /></p><p>跨层参数共享：可以让模型更加稳定</p><h4 id="t5-text-to-text-transfer-transformer">T5: Text-to-Text TransferTransformer</h4><p>迁移是泛化的高级形式：可以将多种文本任务统一为文本到文本的形式，这样可以使得模型更加通用。</p><p>架构层面的创新： <img src="Pasted%20image%2020250324203639.png"alt="Pasted image 20250324203639" /></p><p>这里使用的是prefix-LM，这样可以使得模型更加通用。</p><h3 id="vision-transformer">Vision Transformer</h3><h4 id="vit">ViT</h4><p>将一个图像变成一个patch 增加一个PositionEmbedding，于是得到各个patch的特征的加权平均。主要的贡献是将图像转换为序列，从而可以使用transformers来进行建模。在这个之前，普遍的观点是transformers只能用于文本数据，而CNN用于图像数据。</p><h4 id="swim-transformer">Swim Transformer</h4><p>将CNN中的一些归纳偏好引入，可以使用局部的注意力，但是在一定程度上能捕捉全局的信息，通过ShiftedWindow Mechanism来实现。 层次化特征： <imgsrc="Pasted%20image%2020250324205304.png"alt="Pasted image 20250324205304" /></p><p>密集预测任务对于层次化特征需求更高，于是这个模型的表现是更好地。</p><h4 id="detr">DETR</h4><figure><img src="Pasted%20image%2020250324205845.png"alt="Pasted image 20250324205845" /><figcaption aria-hidden="true">Pasted image 20250324205845</figcaption></figure><figure><img src="Pasted%20image%2020250324205921.png"alt="Pasted image 20250324205921" /><figcaption aria-hidden="true">Pasted image 20250324205921</figcaption></figure><h3 id="fundation-models">Fundation Models</h3><p><spanclass="math display"><em>e</em><sup><em>α</em> + <em>β</em><em>i</em></sup> = <em>e</em><sup><em>α</em></sup><em>e</em><sup><em>β</em><em>i</em></sup> = <em>e</em><sup><em>α</em></sup>(cos<em>β</em>+<em>i</em>sin<em>β</em>)</span></p>]]></content>
    
    
    
    <tags>
      
      <tag>DeepLearning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Learning Lecture-7</title>
    <link href="/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-7/"/>
    <url>/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-7/</url>
    
    <content type="html"><![CDATA[<h2 id="generative-model">Generative Model</h2><p>数据分布是生成模型的核心。生成模型的目标是学习数据的分布，然后生成新的数据。目标是<strong>学习数据的分布</strong>，然后生成新的数据。对生成模型的评价是通过生成的数据的质量来评价的，生成的数据越接近真实数据，生成模型的质量越好。<spanclass="math display"><em>θ</em><sup>*</sup> = arg max<sub><em>θ</em></sub>𝔼<sub><em>x</em> ∼ <em>p</em><sub><em>d</em><em>a</em><em>t</em><em>a</em></sub></sub>log <em>p</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub>(<em>x</em>|<em>θ</em>)</span><img src="Pasted%20image%2020250330094251.png"alt="Pasted image 20250330094251" /></p><figure><img src="Pasted%20image%2020250330094404.png"alt="Pasted image 20250330094404" /><figcaption aria-hidden="true">Pasted image 20250330094404</figcaption></figure><h3 id="gan-generative-adversarial-network">GAN: Generative AdversarialNetwork</h3><p>对抗机器学习的思想是通过两个网络之间的对抗来学习。生成器和判别器之间的对抗是GAN的核心思想。使用的博弈问题的思想，使用的是最小化最大的思想。</p><p>GAN的思想为：生成器和判别器之间的对抗，生成器生成数据，判别器判断数据的真实性。</p><p>目标函数为： <spanclass="math display">min<sub><em>G</em></sub>max<sub><em>D</em></sub><em>V</em>(<em>D</em>,<em>G</em>) = 𝔼<sub><em>x</em> ∼ <em>p</em><sub><em>d</em><em>a</em><em>t</em><em>a</em></sub>(<em>x</em>)</sub>[log<em>D</em>(<em>x</em>)] + 𝔼<sub><em>z</em> ∼ <em>p</em><sub><em>z</em></sub>(<em>z</em>)</sub>[log(1−<em>D</em>(<em>G</em>(<em>z</em>)))]</span>- 当生成器固定时，判别器的目标是最大化判别器的准确率：<spanclass="math inline">max<sub><em>D</em></sub><em>V</em>(<em>D</em>,<em>G</em>)</span>- 当判别器固定时，生成器的目标是最小化判别器的准确率：<spanclass="math inline">min<sub><em>G</em></sub><em>V</em>(<em>D</em>,<em>G</em>)</span></p><p>生成器 <span class="math inline"><em>G</em></span> 的实质是将噪声分布<spanclass="math inline"><em>p</em><sub><em>z</em></sub>(<em>z</em>)</span>（如高斯分布）映射到数据分布<spanclass="math inline"><em>p</em><sub><em>g</em></sub>(<em>x</em>)</span>。根据概率密度变换定理，若<span class="math inline"><em>G</em></span>是可逆且光滑的函数，则生成数据的分布为：</p><p><span class="math display">$$p_g(x) = p_z(z) \cdot \left| \det \left( \frac{\partialG^{-1}(x)}{\partial x} \right) \right|$$</span></p><p>尽管深度神经网络通常不可逆，但通过足够复杂的函数逼近（如多层非线性变换），生成器可以隐式地学习到从<spanclass="math inline"><em>p</em><sub><em>z</em></sub>(<em>z</em>)</span>到 <spanclass="math inline"><em>p</em><sub><em>g</em></sub>(<em>x</em>)</span>的映射，覆盖真实分布 <spanclass="math inline"><em>p</em><sub><em>d</em><em>a</em><em>t</em><em>a</em></sub>(<em>x</em>)</span>。</p><p><strong>关键点</strong>：<br />- 噪声输入的随机性确保了生成数据分布的多样性。<br />-网络的非线性能力允许从简单分布（如高斯分布）逼近复杂分布（如图像像素分布）。</p><p>但是GAN的<strong>训练过程是非常困难</strong>的，梯度性质是不好的，因为在比较好的样本中，由于梯度性质的问题会进行较大的更新。</p><figure><img src="Pasted%20image%2020250330100434.png"alt="Pasted image 20250330100434" /><figcaption aria-hidden="true">Pasted image 20250330100434</figcaption></figure><p><strong>训练GAN的技巧</strong> <imgsrc="Pasted%20image%2020250330100506.png"alt="Pasted image 20250330100506" /></p><h4 id="dcgan-deep-convolutional-generative-adversarial-networks">DCGAN:Deep Convolutional Generative Adversarial Networks</h4><p>对于生成器和判别器，使用卷积神经网络来进行训练。对于判别器，使用的是较为标准的CNN网络，对于生成器，使用的是转置卷积，先将特征图进行padding，然后进行卷积操作，这样可以获得一个较大的特征图。</p><ul><li><strong>生成器</strong>：使用转置卷积（反卷积）逐步上采样，生成高分辨率图像。</li><li><strong>判别器</strong>：使用标准CNN逐步下采样。</li><li><strong>关键技巧</strong>：批量归一化、Leaky ReLU、全卷积结构。</li></ul><figure><img src="Pasted%20image%2020250330102359.png"alt="Pasted image 20250330102359" /><figcaption aria-hidden="true">Pasted image 20250330102359</figcaption></figure><p>证明了泛化定理：在有限的训练样本之下，可以通过训练得到一个泛化的模型。</p><h4 id="inception-score">Inception Score</h4><p>IS 用于衡量生成模型的性能，重点关注两点：<br />-<strong>类别明确性</strong>：单个生成样本应明确属于某个类别（对应分类概率尖锐）。<br />- <strong>多样性</strong>：生成样本应覆盖多个类别（类别分布均匀）。</p><p><spanclass="math display">IS = exp (𝔼<sub><em>x</em> ∼ <em>p</em><sub><em>g</em></sub></sub>[KL(<em>p</em>(<em>y</em>|<em>x</em>)∥<em>p</em>(<em>y</em>))])</span></p><ul><li>Class Probability Distribution: <spanclass="math inline"><em>p</em>(<em>y</em>|<em>x</em>)</span>，生成样本<span class="math inline"><em>x</em></span>属于各个类别的概率，度量的是生成的数据的类别分布和真实数据的类别分布的相似性。</li><li>Marginal Distribution of Generated Data: <spanclass="math inline"><em>p</em>(<em>y</em>)</span>，度量的是生成的数据的类别分布的多样性，如果生成的数据是单一的称为模式坍塌。</li></ul><h5 id="kl-divergence">KL Divergence</h5><p>使用KL散度来度量两个分布的相似性： <span class="math display">$$KL(p||q) =\mathbb{E}_X \left(  \log \frac{p(x)}{q(x)} \right)=\sum_{x\in \mathcal{X}} p(x) \log \frac{p(x)}{q(x)}$$</span> 需要上面的值尽可能偏大</p><ul><li><strong>KL散度的意义</strong>：<ul><li><strong><spanclass="math inline"><em>p</em>(<em>y</em>|<em>x</em>)</span>尖锐</strong> → 分类概率集中（如某类概率接近 1），此时 <spanclass="math inline">KL(<em>p</em>(<em>y</em>|<em>x</em>)∥<em>p</em>(<em>y</em>))</span>值大。<br /></li><li><strong><span class="math inline"><em>p</em>(<em>y</em>)</span>均匀</strong> → 生成样本覆盖所有类别，<spanclass="math inline">KL</span> 值的期望更大。<br /></li></ul></li><li><strong>取指数的作用</strong>：将对数空间的值转换为正数，放大差异便于比较。</li></ul><h4 id="fid-frechet-inception-distance">FID: Frechet InceptionDistance</h4><p>将生成的数据输入一个网络来提取特征，用得到的特征来拟和两个高斯分布，然后计算两个高斯分布的<em>FrechetInception Distance</em>。这是有显式表达式的。</p><p><spanclass="math display">FID = ∥<em>μ</em><sub><em>r</em></sub> − <em>μ</em><sub><em>g</em></sub>∥<sup>2</sup> + Tr(<em>Σ</em><sub><em>r</em></sub>+<em>Σ</em><sub><em>g</em></sub>−2(<em>Σ</em><sub><em>r</em></sub><em>Σ</em><sub><em>g</em></sub>)<sup>1/2</sup>)</span>- <strong><spanclass="math inline"><em>μ</em><sub><em>r</em></sub>, <em>μ</em><sub><em>g</em></sub></span></strong>：真实数据和生成数据特征的均值向量。<br />- <strong><spanclass="math inline"><em>Σ</em><sub><em>r</em></sub>, <em>Σ</em><sub><em>g</em></sub></span></strong>：真实数据和生成数据特征的协方差矩阵。<br />- <strong><spanclass="math inline">Tr(⋅)</span></strong>：矩阵的迹（对角线元素之和）。</p><h4 id="mode-collapse">Mode Collapse</h4><p>指生成的数据的多样性不够，类别分布是单一的，这是GAN的一个问题。</p><p>原始GAN使用JS散度（<spanclass="math inline"><em>J</em><em>S</em><em>D</em>(<em>p</em><sub><em>d</em><em>a</em><em>t</em><em>a</em></sub>∥<em>p</em><sub><em>g</em></sub>)</span>）衡量分布距离，存在：- <strong>梯度消失</strong>：当 <spanclass="math inline"><em>p</em><sub><em>g</em></sub></span> 和 <spanclass="math inline"><em>p</em><sub><em>d</em><em>a</em><em>t</em><em>a</em></sub></span>无重叠时，<spanclass="math inline"><em>J</em><em>S</em><em>D</em> = log 2</span>，梯度为零。- <strong>模式坍塌</strong>：生成器倾向于生成少数样本。</p><h5 id="wasserstein-distance">Wasserstein Distance</h5><p><ahref="https://zh.wikipedia.org/wiki/%E6%B2%83%E7%91%9F%E6%96%AF%E5%9D%A6%E5%BA%A6%E9%87%8F">沃瑟斯坦度量- 维基百科，自由的百科全书</a></p><p>有可能统计距离是不是一个好的距离度量。Wasserstein距离是一个好的距离度量，用推土机距离来度量两个分布的距离。</p><p><spanclass="math display"><em>c</em>(<em>x</em>,<em>y</em>) ↦ [0, ∞),</span>表示从点<span class="math inline"><em>x</em></span>运输质量到点<spanclass="math inline"><em>y</em></span>的代价。一个从<spanclass="math inline"><em>μ</em></span>到<spanclass="math inline"><em>ν</em></span>的运输方案可以用函数<spanclass="math inline"><em>γ</em>(<em>x</em>,<em>y</em>)</span>来描述，该函数表明从<spanclass="math inline"><em>x</em></span>移动到<spanclass="math inline"><em>y</em></span>的质量。一个运输方案<spanclass="math inline"><em>γ</em>(<em>x</em>,<em>y</em>)</span>必须满足以下性质：<span class="math display">$$\begin{aligned}\int \gamma(x,y) \, \mathrm{d}y = \mu(x), \\\int \gamma(x,y) \, \mathrm{d}x = \nu(y),\end{aligned}$$</span></p><p>前者表示从某一点<spanclass="math inline"><em>x</em></span>移到其他所有点的土堆总质量必须等于最初该点<spanclass="math inline"><em>x</em></span>上的土堆质量，后者则表示从所有点移到某一点<spanclass="math inline"><em>y</em></span>的土堆总质量必须等于最终该点<spanclass="math inline"><em>y</em></span>上的土堆质量。 <spanclass="math display">∬<em>c</em>(<em>x</em>,<em>y</em>)<em>γ</em>(<em>x</em>,<em>y</em>) d<em>x</em> d<em>y</em> = ∫<em>c</em>(<em>x</em>,<em>y</em>) d<em>γ</em>(<em>x</em>,<em>y</em>).</span></p><p>方案<spanclass="math inline"><em>γ</em></span>并不是唯一的，所有可能的运输方案中代价最低的方案即为最优运输方案。最优运输方案的代价为：</p><p><spanclass="math display"><em>C</em> = inf<sub><em>γ</em> ∈ <em>Γ</em>(<em>μ</em>,<em>ν</em>)</sub>∫<em>c</em>(<em>x</em>,<em>y</em>) d<em>γ</em>(<em>x</em>,<em>y</em>).</span>##### Wasserstein GAN</p><figure><img src="Pasted%20image%2020250330141642.png"alt="Pasted image 20250330141642" /><figcaption aria-hidden="true">Pasted image 20250330141642</figcaption></figure><figure><img src="Pasted%20image%2020250330142308.png"alt="Pasted image 20250330142308" /><figcaption aria-hidden="true">Pasted image 20250330142308</figcaption></figure><p>对于模式坍塌进一步的理解，如果空间上有一个较大的利普希茨系数，那么说明发生了模式坍塌。</p><figure><img src="Pasted%20image%2020250330144259.png"alt="Pasted image 20250330144259" /><figcaption aria-hidden="true">Pasted image 20250330144259</figcaption></figure><h5 id="spectral-normalization">Spectral Normalization</h5><figure><img src="Pasted%20image%2020250330144556.png"alt="Pasted image 20250330144556" /><figcaption aria-hidden="true">Pasted image 20250330144556</figcaption></figure><table><thead><tr class="header"><th>指标</th><th>JS散度</th><th>Wasserstein距离</th></tr></thead><tbody><tr class="odd"><td><strong>连续性</strong></td><td>不连续（梯度消失）</td><td>连续</td></tr><tr class="even"><td><strong>对称性</strong></td><td>对称</td><td>对称</td></tr><tr class="odd"><td><strong>计算复杂度</strong></td><td>低</td><td>高（需约束判别器）</td></tr></tbody></table><h4 id="conditional-gan">Conditional GAN</h4><p>给定一个类来进行生成数据，这样可以生成不同类别的数据，这样可以生成更加多样的数据。并且可以在一定程度上避免模式坍塌。除了接受高斯噪声还接受一个标签/图像等等作为输入。</p><h4 id="acgan-auxiliary-classifier-gan">ACGAN: Auxiliary ClassifierGAN</h4><p>是多任务学习的一种方法，除了生成数据，还可以进行分类。在生成数据的过程中还生成标签，所以可以一定程度上避免模式坍塌。</p><h4 id="cycle-gan">Cycle GAN</h4><figure><img src="Pasted%20image%2020250330153629.png"alt="Pasted image 20250330153629" /><figcaption aria-hidden="true">Pasted image 20250330153629</figcaption></figure><p>无配对数据下的图像转换（如马→斑马），通过循环一致性损失<spanclass="math inline"><em>C</em><em>y</em><em>c</em></span>保证生成的图像在两个方向上的转换是一致的。### Self-Attention GAN</p><p>将<em>Self-Attention</em>机制应用到GAN中，这样可以使得生成的数据更加真实。</p><h4 id="adaptive-instance-normalization">Adaptive InstanceNormalization</h4><p><span class="math display">$$AdaIN(u ,v) = \sigma(v) \left(\frac{u - \mu(u)}{\sigma(u)}\right) +\mu(v)$$</span>本质上为重新着色的操作，将一个图像的风格转移到另一个图像上。</p><h4 id="stylegan">StyleGAN</h4><p>通过控制风格来生成数据，这样可以生成更加多样的数据。</p><h3 id="vae">VAE</h3><h4 id="encoder">Encoder</h4><ol type="1"><li><strong>推断潜在变量分布</strong><br />编码器将输入数据（如图像、文本）映射到潜在空间<em>latentspace</em>，输出潜在变量<spanclass="math inline"><em>z</em></span>的概率分布参数（通常是高斯分布的均值和方差）。这一步称为<strong>变分推断</strong>，目的是找到输入数据在低维潜在空间中的概率表示。</li><li><strong>数据压缩与特征提取</strong><br />编码器将高维输入数据压缩到低维潜在变量<spanclass="math inline"><em>z</em></span>，提取数据的关键特征（如形状、颜色等抽象属性），同时去除冗余信息。</li><li><strong>引入不确定性</strong><br />不同于传统自编码器的确定性编码，VAE的编码器输出的是分布的参数，通过随机采样生成 zz，使得潜在空间具有连续性，便于生成新样本。</li></ol><h4 id="decoder">Decoder</h4><ol type="1"><li><strong>数据生成</strong><br />解码器从潜在变量<spanclass="math inline"><em>z</em></span>出发，重构输入数据<spanclass="math inline"><em>x</em></span>的分布（如像素值的伯努利分布或高斯分布），生成与原始数据相似的新样本。</li><li><strong>潜在空间映射到数据空间</strong><br />解码器学习如何将低维潜在变量<spanclass="math inline"><em>z</em></span>解码为高维数据空间中的样本，捕捉数据生成过程的规律（如像素间的依赖关系）。</li><li><strong>生成多样性</strong><br />由于潜在变量<spanclass="math inline"><em>z</em></span>是连续且概率化的，解码器可以在潜在空间中插值或随机采样，生成多样化且合理的新数据。</li></ol><h4 id="why-variational">Why Variational</h4><p>其核心目标是通过学习数据分布<spanclass="math inline"><em>p</em>(<em>x</em>)</span>，生成与训练数据类似的新样本。具体来说，VAE旨在解决以下问题：- <strong>生成新数据</strong>：例如生成图像、文本或音频。 -<strong>学习潜在表示</strong>：将高维数据映射到低维潜在空间，同时保持数据的语义特征。- <strong>概率建模</strong>：显式定义数据的生成过程<spanclass="math inline"><em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)</span>，并引入潜在变量<spanclass="math inline"><em>z</em></span>表示数据的隐含因素</p><p>在VAE中，我们引入一个潜在变量 <spanclass="math inline"><em>z</em></span>，假设数据 <spanclass="math inline"><em>x</em></span> 是由某个先验分布 <spanclass="math inline"><em>p</em><sub><em>θ</em></sub>(<em>z</em>)</span>生成，然后通过条件分布 <spanclass="math inline"><em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)</span>生成可观测数据 <span class="math inline"><em>x</em></span>。 <spanclass="math display"><em>p</em><sub><em>θ</em></sub>(<em>x</em>) = ∫<em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)<em>p</em><sub><em>θ</em></sub>(<em>z</em>) d<em>z</em></span><spanclass="math inline"><em>z</em></span>的分布是一个高斯分布，对于<spanclass="math inline"><em>z</em></span>采样得到的实例，通过一个网络生成<spanclass="math inline"><em>x</em></span>。困难在于上面的反常积分，这是一个高维积分，不可行。可以使用<em>蒙特卡洛</em>。</p><p>对于后验分布： <span class="math display">$$p_\theta(z|x) = \frac{p_\theta(x|z) p_\theta(z)}{p_\theta(x)}$$</span>在积分中是经常使用的，但是计算是NP-hard的，因此引入<strong>变分推断</strong>，通过优化下界（ELBO）间接逼近。直接求后验往往是不可行的。因此，我们用<strong>变分推断</strong>的方式，去学习一个近似后验分布<spanclass="math inline"><em>q</em><sub><em>ϕ</em></sub>(<em>z</em>∣<em>x</em>)</span>，并用它来逼近真正的后验分布<spanclass="math inline"><em>p</em><sub><em>θ</em></sub>(<em>z</em>∣<em>x</em>)</span>，从而得到一个变分下界。</p><p>变分的意思为变量的替换，在概率中为分布率的替换。对于这个问题，可以使用一个神经网络来实现，对于这种显式的分布，需要假设分布率，可以指定为高斯分布，用网络来学习均值和协方差，作为<em>EncoderNetwork</em>。 对于条件分布<spanclass="math inline"><em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)</span>，也可以假定为高斯分布，这样可以计算均值和协方差，作为<em>DecoderNetwork</em>。</p><figure><img src="Pasted%20image%2020250330161028.png"alt="Pasted image 20250330161028" /><figcaption aria-hidden="true">Pasted image 20250330161028</figcaption></figure><p>但是VAE是<em>Intractable</em>的，这个问题是NP-hard的。对于上面的条件概率，是比较困难的。所以采用一个近似的方法来进行求解。比如假设服从一个高斯分布，之后计算这个分布的均值和协方差矩阵。</p><h4 id="elbo-evidence-lower-bound">ELBO: Evidence Lower Bound</h4><p>训练的目的是使得<spanclass="math inline">log <em>p</em><sub><em>θ</em></sub>(<em>x</em><sub><em>i</em></sub>)</span>尽可能大，但是很难计算，这里引入“参考系”，也就是引入一个近似的分布<spanclass="math inline"><em>q</em><sub><em>ϕ</em></sub>(<em>z</em>|<em>x</em><sub><em>i</em></sub>)</span>。</p><figure><img src="Pasted%20image%2020250330164549.png"alt="Pasted image 20250330164549" /><figcaption aria-hidden="true">Pasted image 20250330164549</figcaption></figure><p>这里是将最大化似然的过程简化为最大化ELBO的过程。 <spanclass="math display">log <em>p</em><sub><em>θ</em></sub>(<em>x</em><sub><em>i</em></sub>) = 𝔼<sub><em>q</em><sub><em>ϕ</em></sub>(<em>z</em>|<em>x</em><sub><em>i</em></sub>)</sub>[log<em>p</em><sub><em>θ</em></sub>(<em>x</em><sub><em>i</em></sub>|<em>z</em>)] − <em>K</em><em>L</em>(<em>q</em><sub><em>ϕ</em></sub>(<em>z</em>|<em>x</em><sub><em>i</em></sub>)||<em>p</em><sub><em>θ</em></sub>(<em>z</em>))</span></p><h4 id="reparameterization-trick">Reparameterization Trick</h4><figure><img src="Pasted%20image%2020250403144444.png"alt="Pasted image 20250403144444" /><figcaption aria-hidden="true">Pasted image 20250403144444</figcaption></figure><p>在VAE的训练过程中，通常需要从潜在变量的分布中采样。直接从分布中采样可能导致梯度无法传播到编码器网络，因此引入了重参数化技巧。这是的采样变量是<spanclass="math inline"><em>ϵ</em></span>，这样的话采样的过程就在计算图的旁路上，这样就可以进行梯度的传播。#### VAE Inference</p><p>在训练的时候是从<spanclass="math inline"><em>x</em></span>中采样得到的，然后由后验分布<spanclass="math inline"><em>q</em><sub><em>ϕ</em></sub>(<em>z</em>|<em>x</em>)</span>来进行采样。而在推理过程中，是从潜在变量<spanclass="math inline"><em>z</em></span>中采样得到的，然后由条件分布<spanclass="math inline"><em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)</span>来进行进行推理。上述过程的合理性在于目标函数ELBO中的第二项：<spanclass="math inline"><em>K</em><em>L</em>(<em>q</em><sub><em>ϕ</em></sub>(<em>z</em>|<em>x</em><sub><em>i</em></sub>)||<em>p</em><sub><em>θ</em></sub>(<em>z</em>))</span>在训练中被最小化了。</p><figure><img src="Pasted%20image%2020250403152841.png"alt="Pasted image 20250403152841" /><figcaption aria-hidden="true">Pasted image 20250403152841</figcaption></figure><h4 id="vq-vae">VQ-VAE</h4><p>VQ-VAE是对VAE的一个改进，使用了向量量化的方法来进行训练。通过对潜在变量进行离散化来进行训练，这样可以避免模式坍塌的问题。</p><h3 id="diffusion-probabilistic-models">Diffusion ProbabilisticModels</h3><h4 id="denoising-diffusion-probabilistic-models">Denoising DiffusionProbabilistic Models</h4><p>Diffusion模型是通过对数据进行逐步添加噪声来训练模型的。通过对数据进行逐步添加噪声，然后再通过一个网络来进行去噪声的操作。这样可以生成新的数据。</p><p>Markovian Process: 逐步添加噪声的过程，通常是一个高斯分布的过程。<span class="math display">$$q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}  x_{t-1}, \beta_tI)$$</span> 联合分布： <span class="math display">$$q(x_{1:T} | x_0) = \prod_{t=1}^{T} q(x_t | x_{t-1})$$</span></p><p>重参数化表达： <span class="math display">$$x_t = \sqrt{1-\beta_t} x_{t-1} + \sqrt{\beta_t} \epsilon \quad \epsilon\sim \mathcal{N}(0, I)$$</span></p><h5 id="diffusion-kernel">Diffusion Kernel</h5><p><span class="math display">$$\begin{aligned}x_t &amp; = \sqrt{1-\beta_t} x_{t-1} + \sqrt{\beta_t} \epsilon \\&amp;= \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon \\&amp;= \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_t} \epsilon+ \sqrt{\alpha_t} \sqrt{1-\alpha_{t-1}} \epsilon' \\&amp; = \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1 -  \alpha_t\alpha_{t-1}} \epsilon \\&amp; \dots \\&amp; = \sqrt{\overline{\alpha_t}} x_0 + \sqrt{1 - \overline{\alpha_t}}\epsilon\end{aligned}$$</span> - 其中 <span class="math inline">$\overline{\alpha_t} =\prod_{s=1}^{t} \alpha_s$</span></p><h5 id="generation-by-denoising">Generation by Denoising</h5><ul><li>首先对于<spanclass="math inline"><em>x</em><sub><em>T</em></sub></span>进行采样，得到一个高斯分布的样本。</li><li>然后利用后验分布得到<spanclass="math inline"><em>x</em><sub><em>t</em> − 1</sub></span>，使用Bayes公式：<spanclass="math inline"><em>x</em><sub><em>t</em> − 1</sub> ∼ <em>q</em>(<em>x</em><sub><em>t</em> − 1</sub>|<em>x</em><sub><em>t</em></sub>) ∝ <em>q</em>(<em>x</em><sub><em>t</em> − 1</sub>)<em>q</em>(<em>x</em><sub><em>t</em></sub>|<em>x</em><sub><em>t</em> − 1</sub>)</span></li></ul><p>采用一个变分方法来实现： <spanclass="math display"><em>p</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em> − 1</sub>|<em>x</em><sub><em>t</em></sub>) = 𝒩(<em>x</em><sub><em>t</em> − 1</sub>;<em>μ</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub>,<em>t</em>),<em>σ</em><sub><em>t</em></sub><sup>2</sup><strong>I</strong>)</span><span class="math display">$$p_\theta(x_{0:T}) = p_\theta (x_T)\prod_{t=1}^{T} p_\theta(x_{t-1}|x_t)$$</span></p><p>上述过程可以使用一个网络来实现对于均值和方差的输出。</p><figure><img src="Pasted%20image%2020250403164408.png"alt="Pasted image 20250403164408" /><figcaption aria-hidden="true">Pasted image 20250403164408</figcaption></figure><figure><img src="Pasted%20image%2020250403165731.png"alt="Pasted image 20250403165731" /><figcaption aria-hidden="true">Pasted image 20250403165731</figcaption></figure><p><ahref="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">Whatare Diffusion Models? | Lil’Log</a></p><figure><img src="Pasted%20image%2020250405094553.png"alt="Pasted image 20250405094553" /><figcaption aria-hidden="true">Pasted image 20250405094553</figcaption></figure><h5 id="diffusion-parameters">Diffusion Parameters</h5><figure><img src="Pasted%20image%2020250405161801.png"alt="Pasted image 20250405161801" /><figcaption aria-hidden="true">Pasted image 20250405161801</figcaption></figure><h5 id="acceleration-strategies">Acceleration Strategies</h5><h5 id="re-design-forward-sampling">Re-design forward Sampling</h5><ul><li>Striding Sampling<ul><li>在每个时间步长中跳过多个时间步进行采样，从而减少采样次数。</li><li>问题在于在相邻的时间戳中反向传播的后验分布可以近似为高斯分布，但是在较大的步长下不一定是这样的。</li></ul></li><li>DDIM: Denoising Diffusion Implicit Models<ul><li>通过设计一个新的前向采样过程来加速采样。</li><li>通过引入一个新的参数<spanclass="math inline"><em>α</em><sub><em>t</em></sub></span>来控制前向采样的过程。</li><li>通过设计一个新的后验分布来进行采样。</li><li>通过设计一个新的损失函数来进行训练。</li><li><figure><img src="Pasted%20image%2020250405163042.png"alt="Pasted image 20250405163042" /><figcaption aria-hidden="true">Pasted image 20250405163042</figcaption></figure></li></ul></li><li>Denosing Diffusion Models<ul><li><figure><img src="Pasted%20image%2020250405163350.png"alt="Pasted image 20250405163350" /><figcaption aria-hidden="true">Pasted image 20250405163350</figcaption></figure></li></ul></li><li>Latent Diffusion Models<ul><li><figure><img src="Pasted%20image%2020250405163425.png"alt="Pasted image 20250405163425" /><figcaption aria-hidden="true">Pasted image 20250405163425</figcaption></figure></li></ul></li></ul><h5 id="conditonal-diffusion-models">Conditonal Diffusion Models</h5><figure><img src="Pasted%20image%2020250405163914.png"alt="Pasted image 20250405163914" /><figcaption aria-hidden="true">Pasted image 20250405163914</figcaption></figure><figure><img src="Pasted%20image%2020250405163941.png"alt="Pasted image 20250405163941" /><figcaption aria-hidden="true">Pasted image 20250405163941</figcaption></figure><figure><img src="Pasted%20image%2020250405164110.png"alt="Pasted image 20250405164110" /><figcaption aria-hidden="true">Pasted image 20250405164110</figcaption></figure>]]></content>
    
    
    
    <tags>
      
      <tag>DeepLearning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Learning Lecture-8</title>
    <link href="/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-8/"/>
    <url>/2025/06/21/Deep%20Learning/Deep%20Learning%20Lecture-8/</url>
    
    <content type="html"><![CDATA[<h2 id="transfer-learning">Transfer Learning</h2><p>模型在较大规模中的数据集中得到成功，在较小的数据集中进进行学习。<strong>利用先验知识</strong>是实现强人工智能的一个前提条件。</p><h2 id="pre-training">Pre-Training</h2><p>预训练的结果是一个模型，然后在小数据集上进行微调。预训练提供的是一个先验知识，然后再进行微调。这已经是深度学习中的共识，在小数据集中做微调是一个非常好的方法。</p><h3 id="supervised-pre-training">Supervised Pre-Training</h3><ul><li>BiT: Big Transfer<ul><li>在大规模数据集上做预训练非常重要</li></ul></li><li>DAT: Domain Adaptative Transfer<ul><li>在预训练的数据集上进行筛选对于模型的表现会更好</li></ul></li><li>迁移性受到数据间距离的影响</li><li>在微调的过程中需要对很多层进行调整</li><li>下游的任务和预训练的任务之间的距离越近，迁移的效果越好</li></ul><p>假设空间的解释： - 预训练的模型能在较小的较好的假设空间上寻找</p><h4 id="multi-task-architecture">Multi-Task Architecture</h4><ul><li>Hard Parameter Sharing<ul><li>直接共享参数</li><li>共享的参数是所有任务都需要的</li></ul></li><li>Soft Parameter Sharing<ul><li>每个任务使用一个模型</li></ul></li><li>TASKONOMY<ul><li>首先进行训练，之后构建任务的关系图，在训练的过程中找一些更相近的任务进行共享</li></ul></li></ul><p>多任务学习的损失函数： <span class="math display">$$\min_{\theta} \sum_{i=1}^{T} w_i \mathcal{L}_i(\theta)$$</span> 其中 <spanclass="math inline"><em>w</em><sub><em>i</em></sub></span>是每个任务的权重 - GradNorm：使得每个任务的梯度相同 - Taskuncertainty：每个任务的损失函数的权重是不同的 - Pareto optimalsolution： - Optimize for the worst task - Regularization：</p>]]></content>
    
    
    
    <tags>
      
      <tag>DeepLearning</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
